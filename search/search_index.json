{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About All-In-One AI Background 2022 Gartner Survey revealed a 3.6% year-over-year growth rate, the fastest in more than a decade. In terms of specific technologies driving this surge in expenditure would be artificial intelligence (AI) and machine learning (ML), accounting for a whopping 48% of the whole pie. The survey also highlights the relative immaturity of AI technologies compared to the other innovation areas. Just over half of respondents report significant target customer adoption of their AI-enabled products and services. 41% of respondents cited AI emerging technologies as still being in development or early adoption stages, meaning there is a wave of potential adoption as new or augmented AI products and services enter general availability. Technology immaturity is cited as a top reason among AI-investing organizations leading to failure when integrating an emerging technology. Furthermore, product leaders investing in AI whose implementations are progressing slower than expected reported product complexity and a lack of skills as the main hindrances to their progress. There are a couple of industry AI/ML models built on top of AWS SageMaker as the supplement of AWS managed AI/ML services. Those AI/ML models are scattered, lack of web visualization, and not ready to present to customer directly, especially for the customers\u2019 business staff. The customers may not aware of the existing matured AI/ML models which can solve their complex business problems. It will be nice to allow the customers to get aware of the matured AI/ML models existing in AWS for specific industry AI/ML scenarios and experience the AI/ML models in an intuitive way and adopt directly or after customization. Target customers The customers can be defined as business related (business owner and business operation) and IT related (data scientist and application developer). Business owner is more focused on the business impact in general and usually it is the decision-maker. Business operation is more focused on daily business operation and usually it is the end-user of the business operation system. Data scientist is more focused on the creation, fine-tuning and performance measurement of the AI/ML model which will be used in the business operation system. Application developer is more focused on the engineering implementation of the business operation system. To be simplified, term \u201cBusiness\u201d will represent the business owner and business operation in short and term \u201cIT\u201d will represent the data scientist and application developer in short. Solution overview This solution includes AI/ML models suitable for specific business scenarios, such as object detection, image classification, text recognition, object extraction/generation, text summarization, intent recognition, knowledge graph, time series prediction, etc. which can be commonly used in manufacturing, maintenance, enterprise security production, content production, document recognition, comment recognition, short video content understanding and generation, personalized recommendation, advertisement placement, sales forecast, etc. This solution includes the basic functions of data labelling, model training, deployment and inference in the cloud and device terminals commonly used in the AI/ML process, enabling the entire process to achieve low threshold, full functionality, visualization, and customization. Customer can also complete the entire AI/ML process through a graphical interface to solve business problems in specific business scenarios even they don\u2019t have in-depth knowledge on AI/ML. This solution can further export AI/ML models for these specific business scenarios, providing complete source code, demo web sites, and automated deployment methods that enterprise customers can use directly or further customize. Help enterprise customers accelerate the entire AI/ML implementation process, and promote enterprises to transfer more business loads to AWS. Features Multiple industrial models and visualized demonstrations supported Multiple industrial models are already supported, including track maintenance, PPE detection, image classification, image search, document recognition, receipt recognition, generic object detection, customer sentiment analysis, summary generation, text labeling, entity and relationship extraction from documents, etc., Demonstrate real-time inference or run batch inference tasks in an intuitive way Multiple machine learning algorithms supported A variety of machine learning algorithms have been supported, including object detection, image classification, OCR/table recognition, text summarization, text classification, named entity/relationship recognition, fine-grained sentiment analysis, etc. You can use your own based on the supported algorithms Data on demand to customize industrial models. Complete machine learning process supported Supports multiple machine learning tasks such as labeling, training, cloud/edge deployment, real-time reasoning, batch reasoning, pipeline, etc., provides comprehensive API support to facilitate customized development, provides various sample codes, and provides deployment scripts to realize automatic deployment in global regions. Architecture Use Amazon Application Load Balancer to distribute traffic to backend web servers Use Amazon ECS to host your web server Use Amazon API Gateway to proxy various HTTP/WebSocket requests Use Amazon Lambda to implement backend functions of various web servers Use Amazon SageMaker for AI/ML model training, deployment, and inference Management of IoT core devices/thing groups, components, deployments using Amazon Greegrass Use Amazon IAM to manage access to resources Use Amazon VPC to divide and isolate network usage, put various resources in private subnets as much as possible, and access resources on Amazon cloud technology through VPC endpoint/interface endpoint Use Amazon S3 to save various data, model files, etc. of AI/ML models Use Amazon EFS to expand temporary storage for Amazon Lambda Use Amazon DynamodDB to save various metadata Use Amazon SQS to decouple upstream and downstream asynchronous data processing Use Amazon OpenSearch to save annotation results and implement KNN to search for graphs Use Amazon CloudWatch to monitor resources and applications Use Amazon CloudFormation to create and manage resources using templates Use Amazon Cognito to implement user identity management and authentication Algorithms There are 3 kinds of AI/ML algorithms supported in All-In-One AI: computer vision algorithms for object detection, image classification, search by image, OCR, etc. Yolov5 GluonCV PaddleOCR natural language processing algorithms for text summarization, text classification, keyword extract, named entity and relationship recognition, generative aspect based sentiment analysis, etc. CPT GBASA PaddleNLP DeBERta Keybert T5Pegasus data algorithms for time series data forecast GluonTS Backend Lambda functions Manage industrial scenarios List existing industrial scenarios all_in_one_ai_industrial_scenario (TBD) Create new industrial scenarios all_in_one_ai_industrial_scenario (TBD) Edit specific industrial scenarios Delete specific industrial scenarios Manage algorithms List supported algorithms all_in_one_ai_algorithm Show specific algorithm all_in_one_ai_algorithm Manage industrial models List existing industrial models all_in_one_ai_industrial_model Create new industrial models all_in_one_ai_industrial_model Edit specific industrial model all_in_one_ai_industrial_model Delete specific industrial model all_in_one_ai_industrial_model Manage demonstrations Real-time inference demo with sample data all_in_one_ai_inference all_in_one_ai_invoke_endpoint Real-time inference demo with uploaded data all_in_one_ai_inference all_in_one_ai_invoke_endpoint Manage transform jobs List batch transform jobs all_in_one_ai_transform_job Describe specific transform job all_in_one_ai_describe_transform_job Create new batch transform job all_in_one_ai_create_transform_job Stop specific running batch transform job all_in_one_ai_stop_transform_job Attach existed batch transform job all_in_one_ai_transform_job Detach existed batch transform job all_in_one_ai_transform_job Review transform job\u2019s output all_in_one_ai_transform_job_review Manage training jobs List training jobs all_in_one_ai_training_job Describe specific training job all_in_one_ai_describe_transform_job Create new training job all_in_one_ai_create_training_job Stop specific running training job all_in_one_ai_stop_training_job Attach existed training job all_in_one_ai_training_job Detach existed training job all_in_one_ai_training_job Manage models List models all_in_one_ai_model List model package all_in_one_ai_model_package List model package group all_in_one_ai_model_package_group Describe specific model all_in_one_ai_describe_model Create new model all_in_one_ai_create_model Create new model package all_in_one_ai_model_package Create new model package group all_in_one_ai_model_package_group Delete specific model all_in_one_ai_model Attach existed model all_in_one_ai_model Detach existed model all_in_one_ai_model Manage endpoints List endpoints all_in_one_ai_endpoint Describe specific endpoint all_in_one_ai_describe_endpoint Create new endpoint all_in_one_ai_create_endpoint Delete specific endpoint all_in_one_ai_endpoint Attach existed endpoint all_in_one_ai_endpoint Detach existed endpoint all_in_one_ai_endpoint Manage rest APIs List rest APIs all_in_one_ai_api Describe specific rest API all_in_one_ai_api Create new rest API all_in_one_ai_create_api Manage Greengrass components List Greengrass component versions all_in_one_ai_greengrass_component_version Describe specific Greengrass component version all_in_one_ai_greengrass_component_version Create new specific Greengrass component version all_in_one_ai_greengrass_create_component_version Manage Greengrass deployment List Greengrass deployment all_in_one_ai_greengrass_deployment Describe specific Greengrass deployment all_in_one_ai_greengrass_deployment Create new specific Greengrass deployment all_in_one_ai_greengrass_create_deployment List Greengrass core devices all_in_one_ai_greengrass_core_devices List IoT thing groups all_in_one_ai_greengrass_thing_groups Manage pipeline List pipeline all_in_one_ai_pipeline Describe specific pipeline all_in_one_ai_describe_pipeline_execution Create new specific pipeline all_in_one_ai_create_pipeline all_in_one_ai_create_pipeline_helper all_in_one_ai_finalize_pipeline Manage image search Import images to OpenSearch all_in_one_ai_import_opensearch all_in_one_ai_import_opensearch_helper all_in_one_ai_import_opensearch_handler Search by images via OpenSearch all_in_one_ai_search_by_image Quick start Start train all_in_one_ai_train all_in_one_ai_create_train_huggingface all_in_one_ai_create_train_pytorch all_in_one_ai_create_train_mxnet all_in_one_ai_create_tensorflow Start deploy all_in_one_ai_deploy all_in_one_ai_deploy_train_huggingface all_in_one_ai_deploy_train_pytorch all_in_one_ai_deploy_train_mxnet all_in_one_ai_deploy_train_tensorflow Toolkits S3 toolkit all_in_one_ai_s3 Lambda toolkit all_in_one_ai_function DynamoDB/SSM/OpenSearch function toolkit all_in_one_ai_helper SageMaker toolkit all_in_one_ai_sagemaker Git toolkit all_in_one_ai_tools Video toolkit all_in_one_ai_video_producer all_in_one_ai_video_stream Websocket toolkit all_in_one_ai_websocket_connect all_in_one_ai_websocket_disconnect all_in_one_ai_websocket_login all_in_one_ai_websocket_command all_in_one_ai_websocket_report Rest APIs Overview --- swagger: \"2.0\" info: version: \"2023-01-09T10:02:49Z\" title: \"all-in-one-ai-api\" host: \"a4xh9o0fn1.execute-api.us-west-2.amazonaws.com\" basePath: \"/Prod\" schemes: - \"https\" paths: /annotation: get: responses: {} post: responses: {} delete: responses: {} /api: get: responses: {} post: responses: {} /api/{api_name}: get: parameters: - name: \"api_name\" in: \"path\" required: true type: \"string\" responses: {} /deploy: post: responses: {} /endpoint: get: responses: {} post: responses: {} /endpoint/{endpoint_name}: get: parameters: - name: \"endpoint_name\" in: \"path\" required: true type: \"string\" responses: {} delete: parameters: - name: \"endpoint_name\" in: \"path\" required: true type: \"string\" responses: {} /function/{function_name}: get: parameters: - name: \"function_name\" in: \"path\" required: true type: \"string\" responses: {} /greengrass/component: get: responses: {} /greengrass/component/{component_name}: get: parameters: - name: \"component_name\" in: \"path\" required: true type: \"string\" responses: {} post: parameters: - name: \"component_name\" in: \"path\" required: true type: \"string\" responses: {} /greengrass/component/{component_name}/{component_version_arn}: get: parameters: - name: \"component_name\" in: \"path\" required: true type: \"string\" - name: \"component_version_arn\" in: \"path\" required: true type: \"string\" responses: {} /greengrass/coredevices: get: responses: {} /greengrass/deployment: get: responses: {} post: responses: {} /greengrass/deployment/{deployment_id}: get: parameters: - name: \"deployment_id\" in: \"path\" required: true type: \"string\" responses: {} /greengrass/thinggroups: get: responses: {} /industrialmodel: get: responses: {} post: responses: {} /industrialmodel/{model_id}: get: parameters: - name: \"model_id\" in: \"path\" required: true type: \"string\" responses: {} post: parameters: - name: \"model_id\" in: \"path\" required: true type: \"string\" responses: {} delete: parameters: - name: \"model_id\" in: \"path\" required: true type: \"string\" responses: {} /inference: post: responses: {} /model: get: responses: {} post: responses: {} /model/{model_name}: get: parameters: - name: \"model_name\" in: \"path\" required: true type: \"string\" responses: {} delete: parameters: - name: \"model_name\" in: \"path\" required: true type: \"string\" responses: {} /modelpackage: get: responses: {} /modelpackage/group: get: responses: {} post: responses: {} /modelpackage/{model_package_group_name}: get: parameters: - name: \"model_package_group_name\" in: \"path\" required: true type: \"string\" responses: {} post: parameters: - name: \"model_package_group_name\" in: \"path\" required: true type: \"string\" responses: {} /pipeline: get: responses: {} post: responses: {} /s3: get: responses: {} /sd/hypernetwork: get: responses: {} /sd/industrialmodel: get: responses: {} /sd/models: get: responses: {} post: responses: {} /sd/user: post: responses: {} /search/image: post: responses: {} /search/import: get: responses: {} post: responses: {} /train: post: responses: {} /trainingjob: get: responses: {} post: responses: {} /trainingjob/{training_job_name}: get: parameters: - name: \"training_job_name\" in: \"path\" required: true type: \"string\" responses: {} /transformjob: get: responses: {} post: responses: {} /transformjob/{transform_job_name}: get: parameters: - name: \"transform_job_name\" in: \"path\" required: true type: \"string\" responses: {} /transformjob/{transform_job_name}/review: get: parameters: - name: \"transform_job_name\" in: \"path\" required: true type: \"string\" responses: {} Train API Create SageMaker training job - /train Key Value HTTP Method POST HTTP Content-Type 'application/json' HTTP Request { 'model_algorithm': [name of model algorithm], 'industrial_model': [name of industrial model], 'instance_type': [instance type of SageMaker training job], 'instance_count': [instance count of SageMaker training job], 'model_hyperparameters': [model hyperparameters definitions in json string], 'inputs': [input data channel definitions in json string], 'training_job_name': [name of SageMaker training job] } HTTP Response [Name of SageMaker training job] Deploy API Create SageMaker deployment - /deploy Key Value HTTP Method POST HTTP Content-Type 'application/json' HTTP Request { 'model_algorithm': [name of model algorithm], 'industrial_model': [name of industrial model], 'model_name': [name of SageMaker model], 'model_environment']: [model environment variable definition in json string], 'model_data_url': [S3 URI of model data file in tar.gz format], 'endpoint_name': [name of SageMaker endpoint], 'instance_type': [instance type of SageMaker endpoint], 'instance_count': [initial instance count of endpoint] } HTTP Response { 'model_name': [name of SageMaker model], 'endpoint_name': [name of SageMaker endpoint] } Inference API Invoke SageMaker endpoint to inference - /inference Property Value HTTP Method POST HTTP Request - Content-Type [MIME type of HTTP request body] HTTP Request - querystring endpoint_name : [name of SageMaker endpoint] HTTP Request - body [inference request which is up to model algorithm] HTTP Response [inference response from SageMaker endpoint which is up to model algorithm] Sample data all-in-one-ai-sample-data","title":"About All-In-One AI"},{"location":"#about-all-in-one-ai","text":"","title":"About All-In-One AI"},{"location":"#background","text":"2022 Gartner Survey revealed a 3.6% year-over-year growth rate, the fastest in more than a decade. In terms of specific technologies driving this surge in expenditure would be artificial intelligence (AI) and machine learning (ML), accounting for a whopping 48% of the whole pie. The survey also highlights the relative immaturity of AI technologies compared to the other innovation areas. Just over half of respondents report significant target customer adoption of their AI-enabled products and services. 41% of respondents cited AI emerging technologies as still being in development or early adoption stages, meaning there is a wave of potential adoption as new or augmented AI products and services enter general availability. Technology immaturity is cited as a top reason among AI-investing organizations leading to failure when integrating an emerging technology. Furthermore, product leaders investing in AI whose implementations are progressing slower than expected reported product complexity and a lack of skills as the main hindrances to their progress. There are a couple of industry AI/ML models built on top of AWS SageMaker as the supplement of AWS managed AI/ML services. Those AI/ML models are scattered, lack of web visualization, and not ready to present to customer directly, especially for the customers\u2019 business staff. The customers may not aware of the existing matured AI/ML models which can solve their complex business problems. It will be nice to allow the customers to get aware of the matured AI/ML models existing in AWS for specific industry AI/ML scenarios and experience the AI/ML models in an intuitive way and adopt directly or after customization.","title":"Background"},{"location":"#target-customers","text":"The customers can be defined as business related (business owner and business operation) and IT related (data scientist and application developer). Business owner is more focused on the business impact in general and usually it is the decision-maker. Business operation is more focused on daily business operation and usually it is the end-user of the business operation system. Data scientist is more focused on the creation, fine-tuning and performance measurement of the AI/ML model which will be used in the business operation system. Application developer is more focused on the engineering implementation of the business operation system. To be simplified, term \u201cBusiness\u201d will represent the business owner and business operation in short and term \u201cIT\u201d will represent the data scientist and application developer in short.","title":"Target customers"},{"location":"#solution-overview","text":"This solution includes AI/ML models suitable for specific business scenarios, such as object detection, image classification, text recognition, object extraction/generation, text summarization, intent recognition, knowledge graph, time series prediction, etc. which can be commonly used in manufacturing, maintenance, enterprise security production, content production, document recognition, comment recognition, short video content understanding and generation, personalized recommendation, advertisement placement, sales forecast, etc. This solution includes the basic functions of data labelling, model training, deployment and inference in the cloud and device terminals commonly used in the AI/ML process, enabling the entire process to achieve low threshold, full functionality, visualization, and customization. Customer can also complete the entire AI/ML process through a graphical interface to solve business problems in specific business scenarios even they don\u2019t have in-depth knowledge on AI/ML. This solution can further export AI/ML models for these specific business scenarios, providing complete source code, demo web sites, and automated deployment methods that enterprise customers can use directly or further customize. Help enterprise customers accelerate the entire AI/ML implementation process, and promote enterprises to transfer more business loads to AWS.","title":"Solution overview"},{"location":"#features","text":"Multiple industrial models and visualized demonstrations supported Multiple industrial models are already supported, including track maintenance, PPE detection, image classification, image search, document recognition, receipt recognition, generic object detection, customer sentiment analysis, summary generation, text labeling, entity and relationship extraction from documents, etc., Demonstrate real-time inference or run batch inference tasks in an intuitive way Multiple machine learning algorithms supported A variety of machine learning algorithms have been supported, including object detection, image classification, OCR/table recognition, text summarization, text classification, named entity/relationship recognition, fine-grained sentiment analysis, etc. You can use your own based on the supported algorithms Data on demand to customize industrial models. Complete machine learning process supported Supports multiple machine learning tasks such as labeling, training, cloud/edge deployment, real-time reasoning, batch reasoning, pipeline, etc., provides comprehensive API support to facilitate customized development, provides various sample codes, and provides deployment scripts to realize automatic deployment in global regions.","title":"Features"},{"location":"#architecture","text":"Use Amazon Application Load Balancer to distribute traffic to backend web servers Use Amazon ECS to host your web server Use Amazon API Gateway to proxy various HTTP/WebSocket requests Use Amazon Lambda to implement backend functions of various web servers Use Amazon SageMaker for AI/ML model training, deployment, and inference Management of IoT core devices/thing groups, components, deployments using Amazon Greegrass Use Amazon IAM to manage access to resources Use Amazon VPC to divide and isolate network usage, put various resources in private subnets as much as possible, and access resources on Amazon cloud technology through VPC endpoint/interface endpoint Use Amazon S3 to save various data, model files, etc. of AI/ML models Use Amazon EFS to expand temporary storage for Amazon Lambda Use Amazon DynamodDB to save various metadata Use Amazon SQS to decouple upstream and downstream asynchronous data processing Use Amazon OpenSearch to save annotation results and implement KNN to search for graphs Use Amazon CloudWatch to monitor resources and applications Use Amazon CloudFormation to create and manage resources using templates Use Amazon Cognito to implement user identity management and authentication","title":"Architecture"},{"location":"#algorithms","text":"There are 3 kinds of AI/ML algorithms supported in All-In-One AI: computer vision algorithms for object detection, image classification, search by image, OCR, etc. Yolov5 GluonCV PaddleOCR natural language processing algorithms for text summarization, text classification, keyword extract, named entity and relationship recognition, generative aspect based sentiment analysis, etc. CPT GBASA PaddleNLP DeBERta Keybert T5Pegasus data algorithms for time series data forecast GluonTS","title":"Algorithms"},{"location":"#backend-lambda-functions","text":"","title":"Backend Lambda functions"},{"location":"#manage-industrial-scenarios","text":"List existing industrial scenarios all_in_one_ai_industrial_scenario (TBD) Create new industrial scenarios all_in_one_ai_industrial_scenario (TBD) Edit specific industrial scenarios Delete specific industrial scenarios","title":"Manage industrial scenarios"},{"location":"#manage-algorithms","text":"List supported algorithms all_in_one_ai_algorithm Show specific algorithm all_in_one_ai_algorithm","title":"Manage algorithms"},{"location":"#manage-industrial-models","text":"List existing industrial models all_in_one_ai_industrial_model Create new industrial models all_in_one_ai_industrial_model Edit specific industrial model all_in_one_ai_industrial_model Delete specific industrial model all_in_one_ai_industrial_model","title":"Manage industrial models"},{"location":"#manage-demonstrations","text":"Real-time inference demo with sample data all_in_one_ai_inference all_in_one_ai_invoke_endpoint Real-time inference demo with uploaded data all_in_one_ai_inference all_in_one_ai_invoke_endpoint","title":"Manage demonstrations"},{"location":"#manage-transform-jobs","text":"List batch transform jobs all_in_one_ai_transform_job Describe specific transform job all_in_one_ai_describe_transform_job Create new batch transform job all_in_one_ai_create_transform_job Stop specific running batch transform job all_in_one_ai_stop_transform_job Attach existed batch transform job all_in_one_ai_transform_job Detach existed batch transform job all_in_one_ai_transform_job Review transform job\u2019s output all_in_one_ai_transform_job_review","title":"Manage transform jobs"},{"location":"#manage-training-jobs","text":"List training jobs all_in_one_ai_training_job Describe specific training job all_in_one_ai_describe_transform_job Create new training job all_in_one_ai_create_training_job Stop specific running training job all_in_one_ai_stop_training_job Attach existed training job all_in_one_ai_training_job Detach existed training job all_in_one_ai_training_job","title":"Manage training jobs"},{"location":"#manage-models","text":"List models all_in_one_ai_model List model package all_in_one_ai_model_package List model package group all_in_one_ai_model_package_group Describe specific model all_in_one_ai_describe_model Create new model all_in_one_ai_create_model Create new model package all_in_one_ai_model_package Create new model package group all_in_one_ai_model_package_group Delete specific model all_in_one_ai_model Attach existed model all_in_one_ai_model Detach existed model all_in_one_ai_model","title":"Manage models"},{"location":"#manage-endpoints","text":"List endpoints all_in_one_ai_endpoint Describe specific endpoint all_in_one_ai_describe_endpoint Create new endpoint all_in_one_ai_create_endpoint Delete specific endpoint all_in_one_ai_endpoint Attach existed endpoint all_in_one_ai_endpoint Detach existed endpoint all_in_one_ai_endpoint","title":"Manage endpoints"},{"location":"#manage-rest-apis","text":"List rest APIs all_in_one_ai_api Describe specific rest API all_in_one_ai_api Create new rest API all_in_one_ai_create_api","title":"Manage rest APIs"},{"location":"#manage-greengrass-components","text":"List Greengrass component versions all_in_one_ai_greengrass_component_version Describe specific Greengrass component version all_in_one_ai_greengrass_component_version Create new specific Greengrass component version all_in_one_ai_greengrass_create_component_version","title":"Manage Greengrass components"},{"location":"#manage-greengrass-deployment","text":"List Greengrass deployment all_in_one_ai_greengrass_deployment Describe specific Greengrass deployment all_in_one_ai_greengrass_deployment Create new specific Greengrass deployment all_in_one_ai_greengrass_create_deployment List Greengrass core devices all_in_one_ai_greengrass_core_devices List IoT thing groups all_in_one_ai_greengrass_thing_groups","title":"Manage Greengrass deployment"},{"location":"#manage-pipeline","text":"List pipeline all_in_one_ai_pipeline Describe specific pipeline all_in_one_ai_describe_pipeline_execution Create new specific pipeline all_in_one_ai_create_pipeline all_in_one_ai_create_pipeline_helper all_in_one_ai_finalize_pipeline","title":"Manage pipeline"},{"location":"#manage-image-search","text":"Import images to OpenSearch all_in_one_ai_import_opensearch all_in_one_ai_import_opensearch_helper all_in_one_ai_import_opensearch_handler Search by images via OpenSearch all_in_one_ai_search_by_image","title":"Manage image search"},{"location":"#quick-start","text":"Start train all_in_one_ai_train all_in_one_ai_create_train_huggingface all_in_one_ai_create_train_pytorch all_in_one_ai_create_train_mxnet all_in_one_ai_create_tensorflow Start deploy all_in_one_ai_deploy all_in_one_ai_deploy_train_huggingface all_in_one_ai_deploy_train_pytorch all_in_one_ai_deploy_train_mxnet all_in_one_ai_deploy_train_tensorflow","title":"Quick start"},{"location":"#toolkits","text":"S3 toolkit all_in_one_ai_s3 Lambda toolkit all_in_one_ai_function DynamoDB/SSM/OpenSearch function toolkit all_in_one_ai_helper SageMaker toolkit all_in_one_ai_sagemaker Git toolkit all_in_one_ai_tools Video toolkit all_in_one_ai_video_producer all_in_one_ai_video_stream Websocket toolkit all_in_one_ai_websocket_connect all_in_one_ai_websocket_disconnect all_in_one_ai_websocket_login all_in_one_ai_websocket_command all_in_one_ai_websocket_report","title":"Toolkits"},{"location":"#rest-apis","text":"Overview --- swagger: \"2.0\" info: version: \"2023-01-09T10:02:49Z\" title: \"all-in-one-ai-api\" host: \"a4xh9o0fn1.execute-api.us-west-2.amazonaws.com\" basePath: \"/Prod\" schemes: - \"https\" paths: /annotation: get: responses: {} post: responses: {} delete: responses: {} /api: get: responses: {} post: responses: {} /api/{api_name}: get: parameters: - name: \"api_name\" in: \"path\" required: true type: \"string\" responses: {} /deploy: post: responses: {} /endpoint: get: responses: {} post: responses: {} /endpoint/{endpoint_name}: get: parameters: - name: \"endpoint_name\" in: \"path\" required: true type: \"string\" responses: {} delete: parameters: - name: \"endpoint_name\" in: \"path\" required: true type: \"string\" responses: {} /function/{function_name}: get: parameters: - name: \"function_name\" in: \"path\" required: true type: \"string\" responses: {} /greengrass/component: get: responses: {} /greengrass/component/{component_name}: get: parameters: - name: \"component_name\" in: \"path\" required: true type: \"string\" responses: {} post: parameters: - name: \"component_name\" in: \"path\" required: true type: \"string\" responses: {} /greengrass/component/{component_name}/{component_version_arn}: get: parameters: - name: \"component_name\" in: \"path\" required: true type: \"string\" - name: \"component_version_arn\" in: \"path\" required: true type: \"string\" responses: {} /greengrass/coredevices: get: responses: {} /greengrass/deployment: get: responses: {} post: responses: {} /greengrass/deployment/{deployment_id}: get: parameters: - name: \"deployment_id\" in: \"path\" required: true type: \"string\" responses: {} /greengrass/thinggroups: get: responses: {} /industrialmodel: get: responses: {} post: responses: {} /industrialmodel/{model_id}: get: parameters: - name: \"model_id\" in: \"path\" required: true type: \"string\" responses: {} post: parameters: - name: \"model_id\" in: \"path\" required: true type: \"string\" responses: {} delete: parameters: - name: \"model_id\" in: \"path\" required: true type: \"string\" responses: {} /inference: post: responses: {} /model: get: responses: {} post: responses: {} /model/{model_name}: get: parameters: - name: \"model_name\" in: \"path\" required: true type: \"string\" responses: {} delete: parameters: - name: \"model_name\" in: \"path\" required: true type: \"string\" responses: {} /modelpackage: get: responses: {} /modelpackage/group: get: responses: {} post: responses: {} /modelpackage/{model_package_group_name}: get: parameters: - name: \"model_package_group_name\" in: \"path\" required: true type: \"string\" responses: {} post: parameters: - name: \"model_package_group_name\" in: \"path\" required: true type: \"string\" responses: {} /pipeline: get: responses: {} post: responses: {} /s3: get: responses: {} /sd/hypernetwork: get: responses: {} /sd/industrialmodel: get: responses: {} /sd/models: get: responses: {} post: responses: {} /sd/user: post: responses: {} /search/image: post: responses: {} /search/import: get: responses: {} post: responses: {} /train: post: responses: {} /trainingjob: get: responses: {} post: responses: {} /trainingjob/{training_job_name}: get: parameters: - name: \"training_job_name\" in: \"path\" required: true type: \"string\" responses: {} /transformjob: get: responses: {} post: responses: {} /transformjob/{transform_job_name}: get: parameters: - name: \"transform_job_name\" in: \"path\" required: true type: \"string\" responses: {} /transformjob/{transform_job_name}/review: get: parameters: - name: \"transform_job_name\" in: \"path\" required: true type: \"string\" responses: {} Train API Create SageMaker training job - /train Key Value HTTP Method POST HTTP Content-Type 'application/json' HTTP Request { 'model_algorithm': [name of model algorithm], 'industrial_model': [name of industrial model], 'instance_type': [instance type of SageMaker training job], 'instance_count': [instance count of SageMaker training job], 'model_hyperparameters': [model hyperparameters definitions in json string], 'inputs': [input data channel definitions in json string], 'training_job_name': [name of SageMaker training job] } HTTP Response [Name of SageMaker training job] Deploy API Create SageMaker deployment - /deploy Key Value HTTP Method POST HTTP Content-Type 'application/json' HTTP Request { 'model_algorithm': [name of model algorithm], 'industrial_model': [name of industrial model], 'model_name': [name of SageMaker model], 'model_environment']: [model environment variable definition in json string], 'model_data_url': [S3 URI of model data file in tar.gz format], 'endpoint_name': [name of SageMaker endpoint], 'instance_type': [instance type of SageMaker endpoint], 'instance_count': [initial instance count of endpoint] } HTTP Response { 'model_name': [name of SageMaker model], 'endpoint_name': [name of SageMaker endpoint] } Inference API Invoke SageMaker endpoint to inference - /inference Property Value HTTP Method POST HTTP Request - Content-Type [MIME type of HTTP request body] HTTP Request - querystring endpoint_name : [name of SageMaker endpoint] HTTP Request - body [inference request which is up to model algorithm] HTTP Response [inference response from SageMaker endpoint which is up to model algorithm]","title":"Rest APIs"},{"location":"#sample-data","text":"all-in-one-ai-sample-data","title":"Sample data"},{"location":"builder/","text":"Builder Guide Fully update Delete CloudFormation stack from all-in-one-ai main stack Delete the assets uploaded to S3 URI. Start a fresh deployment Please refer to quick deployment section in all-in-one-ai-deployment-guide. Partial update CloudFormation update Upload updated CloudFormation templates to S3 via executing the following command where project_dir is the path of all-in-one-ai source and s3uri is the S3 URI where the assets were uploaded to. aws s3 cp ${project_dir}/deployment/templates ${s3uri}/templates --recursive Update CloudFormation stack from all-in-one-ai main stack in CloudFormation console or update CloudFormation nested stack only when you are very familiar with the whole structure of all-in-one-ai and changes between the existed and new one. If the CloudFormation stack changes can\u2019t be detected by CloudFormation automatically, you have to replace the source manually. Otherwise, you have to perform fully update. Backend source update Upload updated backend source in ZIP format to S3 via executing the following command where project_dir is the path of all-in-one-ai source and s3uri is the S3 URI where the assets were uploaded to. [Optional] aws s3 cp ${project_dir}/backend/build/codes ${s3uri}/codes --recursive Go to AWS Lambda console and upload a new revision of Lambda source code in ZIP format. Web source update Build web docker image and push to AWS ECR with following command where project_dir is the path of all-in-one-ai source and region is the AWS region where you launched your web server in AWS ECS. cd ${project_dir}/web ./build_and_push.sh ${region} Go to AWS ECR console to confirm if the new ECR revision is pushed. Add a new algorithm \u2013 Common Machine learning frameworks supported Apache MXNET HuggingFace PyTorch TensorFlow Machine learning frameworks not supported yet while planned in the near future Chainer Reinforcement Learning Scikit-learn SparkML Serving XGBoost Machine learning frameworks not covered above You may need to use BYOC You may need to build BYOS with supported machine learning frameworks. For example, PaddleOCR uses PaddlePaddle as the underling machine learning framework which is not supported in SageMaker Python SDK. We could reuse a supported machine learning framework. PaddleOCR training \u2013 TensorFlow PaddleOCR inference \u2013 PyTorch. Add a new algorithm \u2013 BYOS SageMaker Add a fold under sagemaker Create your scripts for train and inference Backend Revise backend/src/all_in_one_ai_train/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. if(algorithm == 'yolov5'): default_hyperparameters = { 'data': '/opt/ml/input/data/cfg/data.yaml', 'cfg': 'yolov5s.yaml', 'weight': 'yolov5s.pt', 'project': '/opt/ml/model/', 'name': 'tutorial', 'img': 640, 'batch': 16, 'epochs': 100, 'device': 0 } for key in default_hyperparameters.keys(): if(key not in hyperparameters.keys()): hyperparameters[key] = default_hyperparameters[key] git_config = {'repo': 'https://github.com/ultralytics/yolov5.git', 'branch': 'master'} payload = { 'body': { 'job_name': job_name, 'algorithm': algorithm, 'industrial_model': industrial_model, 'entry_point': 'train.py', 'source_dir': '.', 'git_config': git_config, 'role': role_arn, 'instance_type': instance_type, 'instance_count': instance_count, 'hyperparameters': hyperparameters, 'inputs': inputs, 'py_version': 'py38', 'framework_version': '1.10.2' } } response = lambda_client.invoke( FunctionName = 'all_in_one_ai_create_train_pytorch', InvocationType = 'Event', Payload=json.dumps(payload) ) Revise backend/src/all_in_one_ai_deploy/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. if(algorithm == 'yolov5'): source_dir = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/source'.format(algorithm)) payload = { 'body': { 'industrial_model': industrial_model, 'role': role_arn, 'entry_point': 'inference.py', 'source_dir': source_dir, 'py_version': 'py38', 'framework_version': '1.10.2', 'model_name': model_name, 'model_data': model_data_url, 'model_environment': model_environment, 'endpoint_name': endpoint_name, 'instance_type': instance_type, 'instance_count': instance_count, } } response = lambda_client.invoke( FunctionName = 'all_in_one_ai_create_deploy_pytorch', InvocationType = 'Event', Payload = json.dumps(payload) ) Revise backend/src/all_in_one_ai_create_pipeline/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. if(script_mode): if(model_algorithm == 'yolov5'): default_hyperparameters = { 'data': '/opt/ml/input/data/cfg/data.yaml', 'cfg': 'yolov5s.yaml', 'weight': 'yolov5s.pt', 'project': '/opt/ml/model/', 'name': 'tutorial', 'img': 640, 'batch': 16, 'epochs': 10 } training_job_hyperparameters = training_job_hyperparameters for key in default_hyperparameters.keys(): if(key not in training_job_hyperparameters.keys()): training_job_hyperparameters[key] = default_hyperparameters[key] git_config = {'repo': 'https://github.com/ultralytics/yolov5.git', 'branch': 'master'} entry_point = 'train.py' source_dir = '.' framework_version = '1.10.2' py_version = 'py38' estimator = PyTorch( entry_point = entry_point, source_dir = source_dir, git_config = git_config, role = role, hyperparameters = training_job_hyperparameters, framework_version = framework_version, py_version = py_version, instance_type = training_job_instance_type, instance_count = training_job_instance_count ) Web Create a tsx file under web/src/components/Form/Demo/Single for demostration of new algorithm. Revise web/src/components/Data/data.ts to add a new entry in ALGORITHMS. export const ALGORITHMS = [ {label: 'Yolov5', value: 'yolov5', reference: 'https://github.com/ultralytics/yolov5/blob/master/README.md', type: 'single', trainable: true}, {label: 'GluonCV', value:'gluoncv', reference: 'https://github.com/dmlc/gluon-cv/blob/master/README.md', type: 'single', trainable: true}, {label: 'GluonTS', value:'gluonts', reference: 'https://github.com/awslabs/gluonts/blob/dev/README.md', type: 'single', trainable: true}, {label: 'PaddleOCR', value: 'paddleocr', reference: 'https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/README.md',type: 'single', trainable: true}, {label: 'CPT', value: 'cpt', reference:'https://github.com/fastnlp/CPT/blob/master/README.md', type: 'single', trainable: true}, {label: 'GABSA', value: 'gabsa', reference: 'https://github.com/IsakZhang/Generative-ABSA/blob/main/readme.md', type: 'single', trainable: true}, {label: 'PaddleNLP', value: 'paddlenlp', reference: 'https://github.com/PaddlePaddle/PaddleNLP/blob/develop/README_en.md', type: 'single', trainable: true}, {label: 'mDeBERTa', value: 'mdeberta', reference: 'https://github.com/microsoft/DeBERTa/blob/master/README.md', type: 'single', trainable: false}, {label: 'KeyBERT', value: 'keybert', reference: 'https://github.com/MaartenGr/KeyBERT/blob/master/README.md', type: 'single', trainable: false}, {label: 'Yolov5PaddleOCR', value: 'yolov5paddleocr', type: 'mixed'} ] Revise web/src/components/Data/data.ts to add a new entry in TRAININGINPUTDATA. export const TRAININGINPUTDATA = { 'yolov5': [ { key: 'images', value: '' }, { key: 'labels', value: '' }, { key: 'cfg', value: '' }, { key: 'weights', value: '' } ], 'gluoncv': [ { key: 'train', value: '' }, { key: 'val', value: '' }, { key: 'test', value: '' } ], 'cpt': [ { key: 'dataset', value: '' } ], 'gabsa': [ { key: 'dataset', value: '' } ], 'paddlenlp': [ { key: 'dataset', value: '' } ], 'paddleocr': [ { key: 'dataset', value: '' }, { key: 'pretrained_models', value: '' } ], 'gluonts': [ { key: 'dataset', value: '' } ] } Deployment Revise deployment/templates/all-in-one-ai-ssm.yaml to add 3 new entries Parameter15: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/yolov5/industrialmodels Type: String Value: !Sub s3://${S3Bucket}/${S3Key}algorithms/yolov5/industrialmodels/ Parameter16: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/yolov5/source Type: String Value: !Sub s3://${S3Bucket}/${S3Key}algorithms/yolov5/source/sourcedir.tar.gz Parameter17: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/yolov5/artifact Type: String Value: !Sub s3://${S3Bucket}/${S3Key}algorithms/yolov5/artifact/model.tar.gz Add a new algorithm \u2013 BYOC SageMaker Add a folder under sagemaker Create your Dockerfile for training FROM nvcr.io/nvidia/pytorch:20.12-py3 ENV PYTHONDONTWRITEBYTECODE 1 ENV PYTHONUNBUFFERED 1 RUN pip install imageio-ffmpeg==0.4.3 pyspng==0.1.0 # Install sagemaker-training toolkit that contains the common functionality necessary to create a container compatible with SageMaker and the Python SDK. RUN pip3 install sagemaker-training ENV PATH=\"/opt/ml/code:${PATH}\" # /opt/ml and all subdirectories are utilized by SageMaker, we use the /code subdirectory to store our user code. COPY stylegan2/ /opt/ml/code/ # this environment variable is used by the SageMaker PyTorch container to determine our user code directory. ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code # this environment variable is used by the SageMaker PyTorch container to determine our program entry point # for training and serving. # For more information: https://github.com/aws/sagemaker-pytorch-container ENV SAGEMAKER_PROGRAM train.py Create your Dockerfile for inference FROM nvcr.io/nvidia/pytorch:20.12-py3 # Set a docker label to advertise multi-model support on the container LABEL com.amazonaws.sagemaker.capabilities.multi-models=true # Set a docker label to enable container to use SAGEMAKER_BIND_TO_PORT environment variable if present LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true ENV PYTHONDONTWRITEBYTECODE 1 ENV PYTHONUNBUFFERED 1 RUN pip install imageio-ffmpeg==0.4.3 pyspng==0.1.0 # Upgrade installed packages RUN apt-get update && apt-get upgrade -y && apt-get clean # Install necessary dependencies for MMS and SageMaker Inference Toolkit RUN apt-get -y install --no-install-recommends \\ build-essential \\ ca-certificates \\ openjdk-8-jdk-headless \\ curl \\ vim \\ && rm -rf /var/lib/apt/lists/ # Install MXNet, MMS, and SageMaker Inference Toolkit to set up MMS RUN pip3 --no-cache-dir install mxnet \\ multi-model-server \\ sagemaker-inference \\ retrying \\ sagemaker \\ smdebug ENV PATH=\"/opt/ml/code:${PATH}\" RUN mkdir -p /opt/ml/code # /opt/ml and all subdirectories are utilized by SageMaker, we use the /code subdirectory to store our user code. COPY stylegan2/ /opt/ml/code/ # Copy entrypoint script to the image COPY dockerd-entrypoint.py /usr/local/bin/dockerd-entrypoint.py RUN chmod +x /usr/local/bin/dockerd-entrypoint.py # Define an entrypoint script for the docker image ENTRYPOINT [\"python\", \"/usr/local/bin/dockerd-entrypoint.py\"] # Define command to be passed to the entrypoint CMD [\"serve\"] Create your build_and_push.sh and change the image default name #!/bin/bash set -v set -e # This script shows how to build the Docker image and push it to ECR to be ready for use # by SageMaker. # The argument to this script is the region name. if [ \"$#\" -ne 1 ]; then echo \"usage: $0 [region-name]\" exit 1 fi region=$1 # Get the account number associated with the current IAM credentials account=$(aws sts get-caller-identity --query Account --output text) if [ $? -ne 0 ] then exit 255 fi training_image=all-in-one-ai-stylegan-training training_fullname=${account}.dkr.ecr.${region}.amazonaws.com/${training_image}:latest # If the repository doesn't exist in ECR, create it. aws ecr describe-repositories --repository-names \"${training_image}\" --region ${region} || aws ecr create-repository --repository-name \"${training_image}\" --region ${region} if [ $? -ne 0 ] then aws ecr create-repository --repository-name \"${training_image}\" --region ${region} fi # Get the login command from ECR and execute it directly aws ecr get-login-password --region $region | docker login --username AWS --password-stdin $account.dkr.ecr.$region.amazonaws.com aws ecr set-repository-policy \\ --repository-name \"${training_image}\" \\ --policy-text \"file://ecr-policy.json\" \\ --region ${region} # Build the docker image locally with the image name and then push it to ECR # with the full name. docker build -t ${training_image} -f Dockerfile.training . docker tag ${training_image} ${training_fullname} docker push ${training_fullname} inference_image=all-in-one-ai-stylegan-inference inference_fullname=${account}.dkr.ecr.${region}.amazonaws.com/${inference_image}:latest # If the repository doesn't exist in ECR, create it. aws ecr describe-repositories --repository-names \"${inference_image}\" --region ${region} || aws ecr create-repository --repository-name \"${inference_image}\" --region ${region} if [ $? -ne 0 ] then aws ecr create-repository --repository-name \"${inference_image}\" --region ${region} fi # Get the login command from ECR and execute it directly aws ecr get-login-password --region $region | docker login --username AWS --password-stdin $account.dkr.ecr.$region.amazonaws.com aws ecr set-repository-policy \\ --repository-name \"${inference_image}\" \\ --policy-text \"file://ecr-policy.json\" \\ --region ${region} # Build the docker image locally with the image name and then push it to ECR # with the full name. docker build -t ${inference_image} -f Dockerfile.inference . docker tag ${inference_image} ${inference_fullname} docker push ${inference_fullname} Backend Please refer to backend/src/all_in_one_ai_training_job/lambda_function.py. No changes needed as long as the default training_image was put in SSM parameter store. if(training_image == ''): try: training_image = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/training_image'.format(algorithm)) except Exception as e: print(e) Please refer to backend/src/all_in_one_ai_model/lambda_function. No changes needed as long as the default infernece_image and artifact was put in SSM parameter store. if(training_image == ''): try: training_image = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/training_image'.format(algorithm)) except Exception as e: rint(e) if(model_data_url == ''): try: model_data_url = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/artifact'.format(algorithm)) except Exception as e: print(e) default model_data_url is only valid for the model which doesn\u2019t need to download the model data. Revise backend/src/all_in_one_ai_train/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. elif(algorithm == 'stylegan'): image_uri = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/training_image'.format(algorithm)) default_hyperparameters = { 'outdir': '/opt/ml/model', 'gpus': 1, 'kimg': 1000 } for key in default_hyperparameters.keys(): if(key not in hyperparameters.keys()): hyperparameters[key] = default_hyperparameters[key] payload = { 'body': { 'job_name': job_name, 'industrial_model': industrial_model, 'role': role_arn, 'image_uri': image_uri, 'instance_type': instance_type, 'instance_count': instance_count, 'hyperparameters': hyperparameters, 'inputs': inputs } } response = lambda_client.invoke( FunctionName = 'all_in_one_ai_create_train_generic', InvocationType = 'Event', Payload=json.dumps(payload) ) Revise backend/src/all_in_one_ai_deploy/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. elif(algorithm == 'stylegan'): image_uri = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/inference_image'.format(algorithm)) payload = { 'body': { 'industrial_model': industrial_model, 'role': role_arn, 'model_name': model_name, 'image_uri': image_uri, 'model_data': model_data_url, 'model_environment': model_environment, 'endpoint_name': endpoint_name, 'instance_type': instance_type, 'instance_count': instance_count, } } response = lambda_client.invoke( FunctionName = 'all_in_one_ai_create_deploy_generic', InvocationType = 'Event', Payload = json.dumps(payload) ) Revise backend/src/all_in_one_ai_create_pipeline/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. elif(model_algorithm == 'stylegan'): image_uri = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/training_image'.format(model_algorithm)) default_hyperparameters = { 'outdir': '/opt/ml/model', 'gpus': 1, 'kimg': 1000 } for key in default_hyperparameters.keys(): if(key not in training_job_hyperparameters.keys()): training_job_hyperparameters[key] = default_hyperparameters[key] estimator = Estimator( role = role, instance_count = training_job_instance_count, instance_type = training_job_instance_type, image_uri = image_uri, hyperparameters=training_job_hyperparameters ) Web Create a tsx file under web/src/components/Form/Demo/Single for demostration of new algorithm. Revise web/src/components/Data/data.ts to add a new entry in ALGORITHMS. export const ALGORITHMS = [ {label: 'Yolov5', value: 'yolov5', reference: 'https://github.com/ultralytics/yolov5/blob/master/README.md', type: 'single', trainable: true, inferable: true, batchannotation: true}, {label: 'GluonCV', value:'gluoncv', reference: 'https://github.com/dmlc/gluon-cv/blob/master/README.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'GluonTS', value:'gluonts', reference: 'https://github.com/awslabs/gluonts/blob/dev/README.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'PaddleOCR', value: 'paddleocr', reference: 'https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/README.md',type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'CPT', value: 'cpt', reference:'https://github.com/fastnlp/CPT/blob/master/README.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'GABSA', value: 'gabsa', reference: 'https://github.com/IsakZhang/Generative-ABSA/blob/main/readme.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'PaddleNLP', value: 'paddlenlp', reference: 'https://github.com/PaddlePaddle/PaddleNLP/blob/develop/README_en.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'mDeBERTa', value: 'mdeberta', reference: 'https://github.com/microsoft/DeBERTa/blob/master/README.md', type: 'single', trainable: false, inferable: true, batchannotation: false}, {label: 'KeyBERT', value: 'keybert', reference: 'https://github.com/MaartenGr/KeyBERT/blob/master/README.md', type: 'single', trainable: false, inferable: true, batchannotation: false}, {label: 'StyleGAN2', value: 'stylegan', reference: 'https://github.com/NVlabs/stylegan2-ada-pytorch/blob/main/README.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'Generic', value: 'generic', type: 'single', trainable: false, inferable: false, batchannotation: true}, {label: 'Yolov5PaddleOCR', value: 'yolov5paddleocr', type: 'mixed', trainable: false, inferable: false, batchannotation: false} Revise web/src/components/Data/data.ts to add a new entry in TRAININGINPUTDATA. export const TRAININGINPUTDATA = { 'yolov5': [ { key: 'images', value: '' }, { key: 'labels', value: '' }, { key: 'cfg', value: '' }, { key: 'weights', value: '' } ], 'gluoncv': [ { key: 'train', value: '' }, { key: 'val', value: '' }, { key: 'test', value: '' } ], 'cpt': [ { key: 'dataset', value: '' } ], 'gabsa': [ { key: 'dataset', value: '' } ], 'paddlenlp': [ { key: 'dataset', value: '' } ], 'paddleocr': [ { key: 'dataset', value: '' }, { key: 'pretrained_models', value: '' } ], 'gluonts': [ { key: 'dataset', value: '' } ], 'stylegan': [ { key: 'data', value: '' }, { key: 'gpus', value: '' }, { key: 'kimg', value: '' } ] } Deployment It will be done automatically as long as it is put under sagemaker subdirectory with Dockerfile and build_and_push.sh dirlist=$(find ${project_dir}/sagemaker -mindepth 1 -maxdepth 1 -type d) for subdir in $dirlist do if [ -f \"./build_and_push.sh\" ]; then ./build_and_push.sh ${region} touch dummy tar czvf model.tar.gz dummy aws s3 cp model.tar.gz ${s3uri}/algorithms/${algorithm}/artifact/ rm dummy rm model.tar.gz else cd ${subdir} array=($(echo ${subdir} | tr \"/\" \"\\n\")) size=${#array[@]} index=$((size - 1)) algorithm=${array[$index]} touch dummy tar czvf model.tar.gz dummy aws s3 cp model.tar.gz ${s3uri}/algorithms/${algorithm}/artifact/ rm dummy rm model.tar.gz tar czvf sourcedir.tar.gz * aws s3 cp sourcedir.tar.gz ${s3uri}/algorithms/${algorithm}/source/ rm sourcedir.tar.gz fi done Revise deployment/templates/all-in-one-ai-ssm.yaml to add new entries for your default training image and inference image Parameter40: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/stylegan/industrialmodels Type: String Value: !Sub s3://${S3Bucket}/${S3Key}algorithms/stylegan/industrialmodels/ Parameter41: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/stylegan/training_image Type: String Value: !If - Globally - !Sub ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/all-in-one-ai-stylegan-training:latest - !Sub ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com.cn/all-in-one-ai-stylegan-training:latest Parameter42: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/stylegan/inference_image Type: String Value: !If - Globally - !Sub ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/all-in-one-ai-stylegan-inference:latest - !Sub ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com.cn/all-in-one-ai-stylegan-inference:latest","title":"Builder Guide"},{"location":"builder/#builder-guide","text":"","title":"Builder Guide"},{"location":"builder/#fully-update","text":"Delete CloudFormation stack from all-in-one-ai main stack Delete the assets uploaded to S3 URI. Start a fresh deployment Please refer to quick deployment section in all-in-one-ai-deployment-guide.","title":"Fully update"},{"location":"builder/#partial-update","text":"","title":"Partial update"},{"location":"builder/#cloudformation-update","text":"Upload updated CloudFormation templates to S3 via executing the following command where project_dir is the path of all-in-one-ai source and s3uri is the S3 URI where the assets were uploaded to. aws s3 cp ${project_dir}/deployment/templates ${s3uri}/templates --recursive Update CloudFormation stack from all-in-one-ai main stack in CloudFormation console or update CloudFormation nested stack only when you are very familiar with the whole structure of all-in-one-ai and changes between the existed and new one. If the CloudFormation stack changes can\u2019t be detected by CloudFormation automatically, you have to replace the source manually. Otherwise, you have to perform fully update.","title":"CloudFormation update"},{"location":"builder/#backend-source-update","text":"Upload updated backend source in ZIP format to S3 via executing the following command where project_dir is the path of all-in-one-ai source and s3uri is the S3 URI where the assets were uploaded to. [Optional] aws s3 cp ${project_dir}/backend/build/codes ${s3uri}/codes --recursive Go to AWS Lambda console and upload a new revision of Lambda source code in ZIP format.","title":"Backend source update"},{"location":"builder/#web-source-update","text":"Build web docker image and push to AWS ECR with following command where project_dir is the path of all-in-one-ai source and region is the AWS region where you launched your web server in AWS ECS. cd ${project_dir}/web ./build_and_push.sh ${region} Go to AWS ECR console to confirm if the new ECR revision is pushed.","title":"Web source update"},{"location":"builder/#add-a-new-algorithm-common","text":"","title":"Add a new algorithm \u2013 Common"},{"location":"builder/#machine-learning-frameworks-supported","text":"Apache MXNET HuggingFace PyTorch TensorFlow","title":"Machine learning frameworks supported"},{"location":"builder/#machine-learning-frameworks-not-supported-yet-while-planned-in-the-near-future","text":"Chainer Reinforcement Learning Scikit-learn SparkML Serving XGBoost","title":"Machine learning frameworks not supported yet while planned in the near future"},{"location":"builder/#machine-learning-frameworks-not-covered-above","text":"You may need to use BYOC You may need to build BYOS with supported machine learning frameworks. For example, PaddleOCR uses PaddlePaddle as the underling machine learning framework which is not supported in SageMaker Python SDK. We could reuse a supported machine learning framework. PaddleOCR training \u2013 TensorFlow PaddleOCR inference \u2013 PyTorch.","title":"Machine learning frameworks not covered above"},{"location":"builder/#add-a-new-algorithm-byos","text":"","title":"Add a new algorithm \u2013 BYOS"},{"location":"builder/#sagemaker","text":"Add a fold under sagemaker Create your scripts for train and inference","title":"SageMaker"},{"location":"builder/#backend","text":"Revise backend/src/all_in_one_ai_train/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. if(algorithm == 'yolov5'): default_hyperparameters = { 'data': '/opt/ml/input/data/cfg/data.yaml', 'cfg': 'yolov5s.yaml', 'weight': 'yolov5s.pt', 'project': '/opt/ml/model/', 'name': 'tutorial', 'img': 640, 'batch': 16, 'epochs': 100, 'device': 0 } for key in default_hyperparameters.keys(): if(key not in hyperparameters.keys()): hyperparameters[key] = default_hyperparameters[key] git_config = {'repo': 'https://github.com/ultralytics/yolov5.git', 'branch': 'master'} payload = { 'body': { 'job_name': job_name, 'algorithm': algorithm, 'industrial_model': industrial_model, 'entry_point': 'train.py', 'source_dir': '.', 'git_config': git_config, 'role': role_arn, 'instance_type': instance_type, 'instance_count': instance_count, 'hyperparameters': hyperparameters, 'inputs': inputs, 'py_version': 'py38', 'framework_version': '1.10.2' } } response = lambda_client.invoke( FunctionName = 'all_in_one_ai_create_train_pytorch', InvocationType = 'Event', Payload=json.dumps(payload) ) Revise backend/src/all_in_one_ai_deploy/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. if(algorithm == 'yolov5'): source_dir = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/source'.format(algorithm)) payload = { 'body': { 'industrial_model': industrial_model, 'role': role_arn, 'entry_point': 'inference.py', 'source_dir': source_dir, 'py_version': 'py38', 'framework_version': '1.10.2', 'model_name': model_name, 'model_data': model_data_url, 'model_environment': model_environment, 'endpoint_name': endpoint_name, 'instance_type': instance_type, 'instance_count': instance_count, } } response = lambda_client.invoke( FunctionName = 'all_in_one_ai_create_deploy_pytorch', InvocationType = 'Event', Payload = json.dumps(payload) ) Revise backend/src/all_in_one_ai_create_pipeline/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. if(script_mode): if(model_algorithm == 'yolov5'): default_hyperparameters = { 'data': '/opt/ml/input/data/cfg/data.yaml', 'cfg': 'yolov5s.yaml', 'weight': 'yolov5s.pt', 'project': '/opt/ml/model/', 'name': 'tutorial', 'img': 640, 'batch': 16, 'epochs': 10 } training_job_hyperparameters = training_job_hyperparameters for key in default_hyperparameters.keys(): if(key not in training_job_hyperparameters.keys()): training_job_hyperparameters[key] = default_hyperparameters[key] git_config = {'repo': 'https://github.com/ultralytics/yolov5.git', 'branch': 'master'} entry_point = 'train.py' source_dir = '.' framework_version = '1.10.2' py_version = 'py38' estimator = PyTorch( entry_point = entry_point, source_dir = source_dir, git_config = git_config, role = role, hyperparameters = training_job_hyperparameters, framework_version = framework_version, py_version = py_version, instance_type = training_job_instance_type, instance_count = training_job_instance_count )","title":"Backend"},{"location":"builder/#web","text":"Create a tsx file under web/src/components/Form/Demo/Single for demostration of new algorithm. Revise web/src/components/Data/data.ts to add a new entry in ALGORITHMS. export const ALGORITHMS = [ {label: 'Yolov5', value: 'yolov5', reference: 'https://github.com/ultralytics/yolov5/blob/master/README.md', type: 'single', trainable: true}, {label: 'GluonCV', value:'gluoncv', reference: 'https://github.com/dmlc/gluon-cv/blob/master/README.md', type: 'single', trainable: true}, {label: 'GluonTS', value:'gluonts', reference: 'https://github.com/awslabs/gluonts/blob/dev/README.md', type: 'single', trainable: true}, {label: 'PaddleOCR', value: 'paddleocr', reference: 'https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/README.md',type: 'single', trainable: true}, {label: 'CPT', value: 'cpt', reference:'https://github.com/fastnlp/CPT/blob/master/README.md', type: 'single', trainable: true}, {label: 'GABSA', value: 'gabsa', reference: 'https://github.com/IsakZhang/Generative-ABSA/blob/main/readme.md', type: 'single', trainable: true}, {label: 'PaddleNLP', value: 'paddlenlp', reference: 'https://github.com/PaddlePaddle/PaddleNLP/blob/develop/README_en.md', type: 'single', trainable: true}, {label: 'mDeBERTa', value: 'mdeberta', reference: 'https://github.com/microsoft/DeBERTa/blob/master/README.md', type: 'single', trainable: false}, {label: 'KeyBERT', value: 'keybert', reference: 'https://github.com/MaartenGr/KeyBERT/blob/master/README.md', type: 'single', trainable: false}, {label: 'Yolov5PaddleOCR', value: 'yolov5paddleocr', type: 'mixed'} ] Revise web/src/components/Data/data.ts to add a new entry in TRAININGINPUTDATA. export const TRAININGINPUTDATA = { 'yolov5': [ { key: 'images', value: '' }, { key: 'labels', value: '' }, { key: 'cfg', value: '' }, { key: 'weights', value: '' } ], 'gluoncv': [ { key: 'train', value: '' }, { key: 'val', value: '' }, { key: 'test', value: '' } ], 'cpt': [ { key: 'dataset', value: '' } ], 'gabsa': [ { key: 'dataset', value: '' } ], 'paddlenlp': [ { key: 'dataset', value: '' } ], 'paddleocr': [ { key: 'dataset', value: '' }, { key: 'pretrained_models', value: '' } ], 'gluonts': [ { key: 'dataset', value: '' } ] }","title":"Web"},{"location":"builder/#deployment","text":"Revise deployment/templates/all-in-one-ai-ssm.yaml to add 3 new entries Parameter15: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/yolov5/industrialmodels Type: String Value: !Sub s3://${S3Bucket}/${S3Key}algorithms/yolov5/industrialmodels/ Parameter16: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/yolov5/source Type: String Value: !Sub s3://${S3Bucket}/${S3Key}algorithms/yolov5/source/sourcedir.tar.gz Parameter17: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/yolov5/artifact Type: String Value: !Sub s3://${S3Bucket}/${S3Key}algorithms/yolov5/artifact/model.tar.gz","title":"Deployment"},{"location":"builder/#add-a-new-algorithm-byoc","text":"","title":"Add a new algorithm \u2013 BYOC"},{"location":"builder/#sagemaker_1","text":"Add a folder under sagemaker Create your Dockerfile for training FROM nvcr.io/nvidia/pytorch:20.12-py3 ENV PYTHONDONTWRITEBYTECODE 1 ENV PYTHONUNBUFFERED 1 RUN pip install imageio-ffmpeg==0.4.3 pyspng==0.1.0 # Install sagemaker-training toolkit that contains the common functionality necessary to create a container compatible with SageMaker and the Python SDK. RUN pip3 install sagemaker-training ENV PATH=\"/opt/ml/code:${PATH}\" # /opt/ml and all subdirectories are utilized by SageMaker, we use the /code subdirectory to store our user code. COPY stylegan2/ /opt/ml/code/ # this environment variable is used by the SageMaker PyTorch container to determine our user code directory. ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code # this environment variable is used by the SageMaker PyTorch container to determine our program entry point # for training and serving. # For more information: https://github.com/aws/sagemaker-pytorch-container ENV SAGEMAKER_PROGRAM train.py Create your Dockerfile for inference FROM nvcr.io/nvidia/pytorch:20.12-py3 # Set a docker label to advertise multi-model support on the container LABEL com.amazonaws.sagemaker.capabilities.multi-models=true # Set a docker label to enable container to use SAGEMAKER_BIND_TO_PORT environment variable if present LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true ENV PYTHONDONTWRITEBYTECODE 1 ENV PYTHONUNBUFFERED 1 RUN pip install imageio-ffmpeg==0.4.3 pyspng==0.1.0 # Upgrade installed packages RUN apt-get update && apt-get upgrade -y && apt-get clean # Install necessary dependencies for MMS and SageMaker Inference Toolkit RUN apt-get -y install --no-install-recommends \\ build-essential \\ ca-certificates \\ openjdk-8-jdk-headless \\ curl \\ vim \\ && rm -rf /var/lib/apt/lists/ # Install MXNet, MMS, and SageMaker Inference Toolkit to set up MMS RUN pip3 --no-cache-dir install mxnet \\ multi-model-server \\ sagemaker-inference \\ retrying \\ sagemaker \\ smdebug ENV PATH=\"/opt/ml/code:${PATH}\" RUN mkdir -p /opt/ml/code # /opt/ml and all subdirectories are utilized by SageMaker, we use the /code subdirectory to store our user code. COPY stylegan2/ /opt/ml/code/ # Copy entrypoint script to the image COPY dockerd-entrypoint.py /usr/local/bin/dockerd-entrypoint.py RUN chmod +x /usr/local/bin/dockerd-entrypoint.py # Define an entrypoint script for the docker image ENTRYPOINT [\"python\", \"/usr/local/bin/dockerd-entrypoint.py\"] # Define command to be passed to the entrypoint CMD [\"serve\"] Create your build_and_push.sh and change the image default name #!/bin/bash set -v set -e # This script shows how to build the Docker image and push it to ECR to be ready for use # by SageMaker. # The argument to this script is the region name. if [ \"$#\" -ne 1 ]; then echo \"usage: $0 [region-name]\" exit 1 fi region=$1 # Get the account number associated with the current IAM credentials account=$(aws sts get-caller-identity --query Account --output text) if [ $? -ne 0 ] then exit 255 fi training_image=all-in-one-ai-stylegan-training training_fullname=${account}.dkr.ecr.${region}.amazonaws.com/${training_image}:latest # If the repository doesn't exist in ECR, create it. aws ecr describe-repositories --repository-names \"${training_image}\" --region ${region} || aws ecr create-repository --repository-name \"${training_image}\" --region ${region} if [ $? -ne 0 ] then aws ecr create-repository --repository-name \"${training_image}\" --region ${region} fi # Get the login command from ECR and execute it directly aws ecr get-login-password --region $region | docker login --username AWS --password-stdin $account.dkr.ecr.$region.amazonaws.com aws ecr set-repository-policy \\ --repository-name \"${training_image}\" \\ --policy-text \"file://ecr-policy.json\" \\ --region ${region} # Build the docker image locally with the image name and then push it to ECR # with the full name. docker build -t ${training_image} -f Dockerfile.training . docker tag ${training_image} ${training_fullname} docker push ${training_fullname} inference_image=all-in-one-ai-stylegan-inference inference_fullname=${account}.dkr.ecr.${region}.amazonaws.com/${inference_image}:latest # If the repository doesn't exist in ECR, create it. aws ecr describe-repositories --repository-names \"${inference_image}\" --region ${region} || aws ecr create-repository --repository-name \"${inference_image}\" --region ${region} if [ $? -ne 0 ] then aws ecr create-repository --repository-name \"${inference_image}\" --region ${region} fi # Get the login command from ECR and execute it directly aws ecr get-login-password --region $region | docker login --username AWS --password-stdin $account.dkr.ecr.$region.amazonaws.com aws ecr set-repository-policy \\ --repository-name \"${inference_image}\" \\ --policy-text \"file://ecr-policy.json\" \\ --region ${region} # Build the docker image locally with the image name and then push it to ECR # with the full name. docker build -t ${inference_image} -f Dockerfile.inference . docker tag ${inference_image} ${inference_fullname} docker push ${inference_fullname}","title":"SageMaker"},{"location":"builder/#backend_1","text":"Please refer to backend/src/all_in_one_ai_training_job/lambda_function.py. No changes needed as long as the default training_image was put in SSM parameter store. if(training_image == ''): try: training_image = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/training_image'.format(algorithm)) except Exception as e: print(e) Please refer to backend/src/all_in_one_ai_model/lambda_function. No changes needed as long as the default infernece_image and artifact was put in SSM parameter store. if(training_image == ''): try: training_image = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/training_image'.format(algorithm)) except Exception as e: rint(e) if(model_data_url == ''): try: model_data_url = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/artifact'.format(algorithm)) except Exception as e: print(e) default model_data_url is only valid for the model which doesn\u2019t need to download the model data. Revise backend/src/all_in_one_ai_train/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. elif(algorithm == 'stylegan'): image_uri = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/training_image'.format(algorithm)) default_hyperparameters = { 'outdir': '/opt/ml/model', 'gpus': 1, 'kimg': 1000 } for key in default_hyperparameters.keys(): if(key not in hyperparameters.keys()): hyperparameters[key] = default_hyperparameters[key] payload = { 'body': { 'job_name': job_name, 'industrial_model': industrial_model, 'role': role_arn, 'image_uri': image_uri, 'instance_type': instance_type, 'instance_count': instance_count, 'hyperparameters': hyperparameters, 'inputs': inputs } } response = lambda_client.invoke( FunctionName = 'all_in_one_ai_create_train_generic', InvocationType = 'Event', Payload=json.dumps(payload) ) Revise backend/src/all_in_one_ai_deploy/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. elif(algorithm == 'stylegan'): image_uri = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/inference_image'.format(algorithm)) payload = { 'body': { 'industrial_model': industrial_model, 'role': role_arn, 'model_name': model_name, 'image_uri': image_uri, 'model_data': model_data_url, 'model_environment': model_environment, 'endpoint_name': endpoint_name, 'instance_type': instance_type, 'instance_count': instance_count, } } response = lambda_client.invoke( FunctionName = 'all_in_one_ai_create_deploy_generic', InvocationType = 'Event', Payload = json.dumps(payload) ) Revise backend/src/all_in_one_ai_create_pipeline/lambda_function.py and add an entry for new algorithm training and choose corresponding machine learning framework. elif(model_algorithm == 'stylegan'): image_uri = ssmh.get_parameter('/all_in_one_ai/config/meta/algorithms/{0}/training_image'.format(model_algorithm)) default_hyperparameters = { 'outdir': '/opt/ml/model', 'gpus': 1, 'kimg': 1000 } for key in default_hyperparameters.keys(): if(key not in training_job_hyperparameters.keys()): training_job_hyperparameters[key] = default_hyperparameters[key] estimator = Estimator( role = role, instance_count = training_job_instance_count, instance_type = training_job_instance_type, image_uri = image_uri, hyperparameters=training_job_hyperparameters )","title":"Backend"},{"location":"builder/#web_1","text":"Create a tsx file under web/src/components/Form/Demo/Single for demostration of new algorithm. Revise web/src/components/Data/data.ts to add a new entry in ALGORITHMS. export const ALGORITHMS = [ {label: 'Yolov5', value: 'yolov5', reference: 'https://github.com/ultralytics/yolov5/blob/master/README.md', type: 'single', trainable: true, inferable: true, batchannotation: true}, {label: 'GluonCV', value:'gluoncv', reference: 'https://github.com/dmlc/gluon-cv/blob/master/README.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'GluonTS', value:'gluonts', reference: 'https://github.com/awslabs/gluonts/blob/dev/README.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'PaddleOCR', value: 'paddleocr', reference: 'https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/README.md',type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'CPT', value: 'cpt', reference:'https://github.com/fastnlp/CPT/blob/master/README.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'GABSA', value: 'gabsa', reference: 'https://github.com/IsakZhang/Generative-ABSA/blob/main/readme.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'PaddleNLP', value: 'paddlenlp', reference: 'https://github.com/PaddlePaddle/PaddleNLP/blob/develop/README_en.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'mDeBERTa', value: 'mdeberta', reference: 'https://github.com/microsoft/DeBERTa/blob/master/README.md', type: 'single', trainable: false, inferable: true, batchannotation: false}, {label: 'KeyBERT', value: 'keybert', reference: 'https://github.com/MaartenGr/KeyBERT/blob/master/README.md', type: 'single', trainable: false, inferable: true, batchannotation: false}, {label: 'StyleGAN2', value: 'stylegan', reference: 'https://github.com/NVlabs/stylegan2-ada-pytorch/blob/main/README.md', type: 'single', trainable: true, inferable: true, batchannotation: false}, {label: 'Generic', value: 'generic', type: 'single', trainable: false, inferable: false, batchannotation: true}, {label: 'Yolov5PaddleOCR', value: 'yolov5paddleocr', type: 'mixed', trainable: false, inferable: false, batchannotation: false} Revise web/src/components/Data/data.ts to add a new entry in TRAININGINPUTDATA. export const TRAININGINPUTDATA = { 'yolov5': [ { key: 'images', value: '' }, { key: 'labels', value: '' }, { key: 'cfg', value: '' }, { key: 'weights', value: '' } ], 'gluoncv': [ { key: 'train', value: '' }, { key: 'val', value: '' }, { key: 'test', value: '' } ], 'cpt': [ { key: 'dataset', value: '' } ], 'gabsa': [ { key: 'dataset', value: '' } ], 'paddlenlp': [ { key: 'dataset', value: '' } ], 'paddleocr': [ { key: 'dataset', value: '' }, { key: 'pretrained_models', value: '' } ], 'gluonts': [ { key: 'dataset', value: '' } ], 'stylegan': [ { key: 'data', value: '' }, { key: 'gpus', value: '' }, { key: 'kimg', value: '' } ] }","title":"Web"},{"location":"builder/#deployment_1","text":"It will be done automatically as long as it is put under sagemaker subdirectory with Dockerfile and build_and_push.sh dirlist=$(find ${project_dir}/sagemaker -mindepth 1 -maxdepth 1 -type d) for subdir in $dirlist do if [ -f \"./build_and_push.sh\" ]; then ./build_and_push.sh ${region} touch dummy tar czvf model.tar.gz dummy aws s3 cp model.tar.gz ${s3uri}/algorithms/${algorithm}/artifact/ rm dummy rm model.tar.gz else cd ${subdir} array=($(echo ${subdir} | tr \"/\" \"\\n\")) size=${#array[@]} index=$((size - 1)) algorithm=${array[$index]} touch dummy tar czvf model.tar.gz dummy aws s3 cp model.tar.gz ${s3uri}/algorithms/${algorithm}/artifact/ rm dummy rm model.tar.gz tar czvf sourcedir.tar.gz * aws s3 cp sourcedir.tar.gz ${s3uri}/algorithms/${algorithm}/source/ rm sourcedir.tar.gz fi done Revise deployment/templates/all-in-one-ai-ssm.yaml to add new entries for your default training image and inference image Parameter40: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/stylegan/industrialmodels Type: String Value: !Sub s3://${S3Bucket}/${S3Key}algorithms/stylegan/industrialmodels/ Parameter41: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/stylegan/training_image Type: String Value: !If - Globally - !Sub ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/all-in-one-ai-stylegan-training:latest - !Sub ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com.cn/all-in-one-ai-stylegan-training:latest Parameter42: Type: AWS::SSM::Parameter Properties: Name: /all_in_one_ai/config/meta/algorithms/stylegan/inference_image Type: String Value: !If - Globally - !Sub ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/all-in-one-ai-stylegan-inference:latest - !Sub ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com.cn/all-in-one-ai-stylegan-inference:latest","title":"Deployment"},{"location":"deployment/","text":"Deployment Guide Prerequisites Resources to be created prior to deployment. Make sure the following resouces existed. In case they are not existed, please create them manually prior to deployment. Service-linked role AmazonOpenSearchServiceRolePolicy Resources to be deleted prior to deployment. Make sure the following resources not existed. In case they are existed, please delete them manually prior to deployment. DynamoDB tables all-in-one-ai-industrial-model all-in-one-ai-training-job all-in-one-ai-model all-in-one-ai-endpoint all-in-one-ai-transform-job all-in-one-ai-pipeline all-in-one-ai-api Lambda functions all_in_one_ai_annotation all_in_one_ai_api all_in_one_ai_create_api all_in_one_ai_create_deploy_huggingface all_in_one_ai_create_deploy_mxnet all_in_one_ai_create_deploy_pytorch all_in_one_ai_create_endpoint all_in_one_ai_create_model all_in_one_ai_create_pipeline all_in_one_ai_create_pipeline_helper all_in_one_ai_create_train_huggingface all_in_one_ai_create_train_mxnet all_in_one_ai_create_training_job all_in_one_ai_create_transform_job all_in_one_ai_delete_endpoint all_in_one_ai_delete_model all_in_one_ai_deploy all_in_one_ai_describe_endpoint all_in_one_ai_describe_pipeline_execution all_in_one_ai_describe_training_job all_in_one_ai_describe_transform_job all_in_one_ai_endpoint all_in_one_ai_finalize_pipeline all_in_one_ai_function all_in_one_ai_greengrass_component_version all_in_one_ai_coredevices all_in_one_ai_greengrass_create_component_version all_in_one_ai_greengrass_create_deployment all_in_one_ai_greengrass_deployment all_in_one_ai_greengrass_thing_groups all_in_one_ai_import_opensearch all_in_one_ai_import_opensearch_handler all_in_one_ai_import_opensearch_helper all_in_one_ai_industrial_model all_in_one_ai_inference all_in_one_ai_invoke_endpoint all_in_one_ai_list_endpoints all_in_one_ai_list_models all_in_one_ai_list_training_jobs all_in_one_ai_list_transform_jobs all_in_one_ai_model all_in_one_ai_model_package all_in_one_ai_model_package_group all_in_one_ai_pipeline all_in_one_ai_s3 all_in_one_ai_search_by_image all_in_one_ai_stop_training_job all_in_one_ai_stop_transform_job all_in_one_ai_train all_in_one_ai_training_job all_in_one_ai_transform_job all_in_one_ai_transform_job_review OpenSearch Domain all-in-one-ai Simple Queue Service all-in-one-ai System Store Parameters parameters starting with /all_in_one_ai/* VPCs all-in-one-ai Resources to be prepared prior to deployment S3 bucket - in the same region as the stack to be launched. Domain Name of web portal (Optional) - Needed only when connections protocol to web portal is HTTPS. ACM SSL certificate of web portal (Optional) - Needed only when connections protocol to web portal is HTTPS Toolkits to be prepared prior to deployment git awscli zip python3 pip3 docker Service quotas and limits Amazon VPC \u2013 1 Amazon VPC subnet \u2013 4 Amazon VPC Internet Gateway - 1 Amazon VPC NAT gateway \u2013 2 Amazon VPC EIP \u2013 2 Amazon VPC endpoint \u2013 5 Amazon VPC route table - 3 Amazon VPC Security group - 10 Amazon VPC interface endpoint - 5 Amazon IAM roles - 60 Amazon SSM - 40 Amazon Cognito user pool - 1 Amazon DynamoDB table - 10 Amazon EFS \u2013 1 Amazon EFS access point - 1 Amazon Lambda - 60 Amazon Rest API Gateway - 1 Amazon OpenSearch domain - 1 Amazon SQS queue - 1 Amazon ECS service \u2013 1 Amazon ECS task - 1 Amazon ECR private repository \u2013 1 Amazon S3 bucket \u2013 1 Amazon ACM public certificate - 1 Quick Deployment Get source code Contact your corresponding Amazon AWS Account BD/SA or email to yonglxie@amazon.com to get the source code. Build and deploy Run the following commands to package python codes and build docker image for web portal and then upload assets to S3 and push docker image to ECR which region is the same AWS region as where CloudFormation stack. It will may take 30-60 minutes. ./build_and_deploy.sh [s3uri] [aws-region] Various deployment options Option 1 \u2013 web portal with HTTP access It will be applicable only when you want to quickly experience this solution. You can leave Certificate field as blank in All-In-One AI main stack parameters to indicate it is option 1 \u2013 HTTP access only. Cautions: It is not recommended since there is no HTTPS encryption during network communication and there is no user authentication mechanism. Option 2 \u2013 web portal with HTTPS access It will be applicable only when you want use your own user authentication mechanism. You can leave CognitoRegion field as blank in All-In-One AI main stack parameters to indicate it is option 2 \u2013 HTTPS access only. Cautions: you need to integrate your own user authentication mechanism into this solution guidance. You can refer to the Cognito integration. Option 3 \u2013 web portal with HTTPS access + Cognito. You need to provide CognitoRegion, UserPool, UserPoolClient, UserPoolDomain in All-In-One AI main stack parameters to indicate it is option 3 \u2013 HTTPS access + Cognito. It is recommended since there is HTTPs encryption during network communication and user authentication enabled. Cognito user pool and user authentication The quick deployment process contains 2 steps: Cognito deployment (Optional) and All-In-One AI deployment via CloudFormation where these 2 CloudFormation stacks could be launched in different region. Cognito is optional used to authenticate with Cognito for All-In-One AI web portal. If Cognito authentication is enabled, Cognito deployment should be done prior to All-In-One AI deployment with parameters \u2013 ClientName, Domain, DomainName, Email, and Username. After Cognito CloudFormation stack is launched, outputs \u2013 UserPool, UserPoolClient, UserPoolDomain can be found at the Outputs of Cognito stack. Those outputs variable will be used as the input parameter of All-In-One AI. After All-In-One AI CloudFormation stack is launched, when accessing All-In-One AI web portal, there is a first-time redirection to Cognito Login page to authenticate with Cognito if the Cognito session is not existed yet. If Cognito authentication is disabled, please launch All-in-One AI CloudFormation Stack directly and leave parameters \u2013 CognitoRegion, UserPool, UserPoolClient, UserPoolDomain blank. When accessing All-In-One AI web portal, there is no first-time redirection to Cognito Login page. Cognito deployment (Optional) Launch CloudFormation stack template by clicking , and input Amazon S3 URL with HTTP URI of all-in-one-ai-cognito.yaml. Specify stack details. Please input DomainName, Email information of your stack template, and customize other parameters if needed. Choose Next Configure stack options. Keep everything as default and choose Next. Review stack all-in-one-ai. Check the 2 check boxes in the bottom. Choose Create Stack. Wait for around 5 minutes to get the stack launched. Check the Stack Outputs. All-In-One AI deployment Launch CloudFormation stack template by clicking , and input Amazon S3 URL with HTTP URI of all-in-one-ai-main.yaml. Specify stack details. Please select at least 2 availability zone, Certificate, DomainName, input S3 bucket/key information of your stack template, input CognitoRegion, UserPool, UserPoolClient, UserPoolDomain if Cognito authentication is enabled and customize other parameters if needed. Choose Next. Configure stack options. Keep everything as default. Review stack all-in-one-ai. Check the 2 check boxes in the bottom. Choose Create Stack. Wait for around 30-60 minutes to get the stack launched. Check the WebPortalURL, WebPortalDNS in the Stack Outputs and bind the WebPortalDNS to DomainName Open the Web Portal URL in the Stack Outputs. If Cognito authentication is enabled, Cognito Login window will be prompt to input Username/Password. If Cognito authentication successes, the web portal of All-In-One AI will be shown. If Cognito authentication is disabled, the web portal of All-In-One AI will be shown directly. Build stable-diffusion-webui Build and push to ECR Go to sagemaker/stable-diffusion-webui and run ./build_and_push.sh [region-name] Note: It is a partial step of build_and_deploy.sh stable-diffusion-webui deployment Launch CloudFormation stack template by clicking , and input Amazon S3 URL with HTTP URI of all-in-one-ai-cognito.yaml. Specify stack details. Please input API Gateway endpoint and select your private subnets, public subnets, vpc, and customize other parameters if needed. If you want to use HTTP, please leave the rest as blank. If you want to use HTTPS, please input ACM certifacate ARN and your domain name.Choose Next. For API Gateway endpoint, you can check it from the stack outputs of all-in-one-lambda.yaml. Configure stack options. Keep everything as default and choose Next. Review stack all-in-one-ai. Check the 1 check boxes in the bottom. Choose Create Stack. Wait for around 10 minutes to get the stack launched and check the stack outpus. Prepare SD models SD v2.0 768-v-ema.ckpt stable-diffusion/v2-inference-v.yaml SD v1.5 v1-5-pruned-emaonly.ckpt v1-5-pruned.ckpt SD v1.4 sd-v1-4-full-ema.ckpt sd-v1-4.ckpt You could pick up all your interested SD models and download them into one directory and then run python3 prepare.py [path-to-sd-models-directory] This script will help to generate model.tar.gz and push s3://[sagemaker-default-bucket]/assets/, push the whole model directory to s3://[sagemaker-default-bucket]/models/, and generate meta-data and save in DynamoDB. For instance, the following diagram shows the contents at the model files at s3://[sagemaker-default-bucket]/models/. Note: For SD v2.0, please keep the filename consistent, e.g. 768-v-ema.ckpt and 768-v-ema.yaml. Only English versions of SD 2.x and SD 1.x are supported. Chinese versions (e.g. Taiyi) are not supported yet. Launch stable-diffusion-webui Wait 10 minutes until the stable-diffusion-webui server pass the health check and then check the stack outputs of all-in-one-ai-webui and then launch the stable-diffusion-webui. Resource Cleanup The resource created by CloudFormation will be deleted automatically when you delete CloudFormation stack. Before you delete CloudFormation stack, please make sure the following resources created dynamically are deleted. Go to AWS SageMaker Console , make sure all of model, endpoint config, and endpoint which were dynamically created are deleted. CloudFormation Stack Parameters Reference Name Description Type Default S3Bucket S3 bucket of assets String S3Key S3 key of assets String CustomIdentifier AWS Resource Custom Identifier String all-in-one-ai AvailabilityZones The list of Availability Zones to use for the subnets in the VPC. Please select two AvailabilityZones. List DomainName Domain Name of Web Portal String Certificate Certificate of Domain Name String CognitoRegion Cognito Region String CIDR CIDR block for VPC string 10.0.0.0/16 PublicSubnet1CIDR CIDR block for the public subnet in Availability Zone A String 10.0.0.0/24 PublicSubnet2CIDR CIDR block for the public subnet in Availability Zone B String 10.0.1.0/24 PrivateSubnet1CIDR CIDR block for the private subnet in Availability Zone A String 10.0.2.0/24 PrivateSubnet2CIDR CIDR block for the private subnet in Availability Zone B String 10.0.3.0/24 EfsEncrpytedBoolean Create an encrypted Amazon EFS file system. String True EfsGrowth Amount of dummy data (GiB) to add to the file system (max 6144 GiB) Number 0 EfsPerformanceMode Select the performance mode of the file system. String generalPurpose OpenSearchDomainName OpenSearch Domain String all-in-one-ai OpenSearchInstanceType OpenSearchInstanceType String m5.4xlarge.search UserPool UserPool Id String UserPoolClient UserPoolClient Id String UserPoolDomain Endpoint of UserPoolDomain String ChinaRegion Check if the stack to be in CN Region String False","title":"Deployment Guide"},{"location":"deployment/#deployment-guide","text":"","title":"Deployment Guide"},{"location":"deployment/#prerequisites","text":"","title":"Prerequisites"},{"location":"deployment/#resources-to-be-created-prior-to-deployment","text":"Make sure the following resouces existed. In case they are not existed, please create them manually prior to deployment. Service-linked role AmazonOpenSearchServiceRolePolicy","title":"Resources to be created prior to deployment."},{"location":"deployment/#resources-to-be-deleted-prior-to-deployment","text":"Make sure the following resources not existed. In case they are existed, please delete them manually prior to deployment. DynamoDB tables all-in-one-ai-industrial-model all-in-one-ai-training-job all-in-one-ai-model all-in-one-ai-endpoint all-in-one-ai-transform-job all-in-one-ai-pipeline all-in-one-ai-api Lambda functions all_in_one_ai_annotation all_in_one_ai_api all_in_one_ai_create_api all_in_one_ai_create_deploy_huggingface all_in_one_ai_create_deploy_mxnet all_in_one_ai_create_deploy_pytorch all_in_one_ai_create_endpoint all_in_one_ai_create_model all_in_one_ai_create_pipeline all_in_one_ai_create_pipeline_helper all_in_one_ai_create_train_huggingface all_in_one_ai_create_train_mxnet all_in_one_ai_create_training_job all_in_one_ai_create_transform_job all_in_one_ai_delete_endpoint all_in_one_ai_delete_model all_in_one_ai_deploy all_in_one_ai_describe_endpoint all_in_one_ai_describe_pipeline_execution all_in_one_ai_describe_training_job all_in_one_ai_describe_transform_job all_in_one_ai_endpoint all_in_one_ai_finalize_pipeline all_in_one_ai_function all_in_one_ai_greengrass_component_version all_in_one_ai_coredevices all_in_one_ai_greengrass_create_component_version all_in_one_ai_greengrass_create_deployment all_in_one_ai_greengrass_deployment all_in_one_ai_greengrass_thing_groups all_in_one_ai_import_opensearch all_in_one_ai_import_opensearch_handler all_in_one_ai_import_opensearch_helper all_in_one_ai_industrial_model all_in_one_ai_inference all_in_one_ai_invoke_endpoint all_in_one_ai_list_endpoints all_in_one_ai_list_models all_in_one_ai_list_training_jobs all_in_one_ai_list_transform_jobs all_in_one_ai_model all_in_one_ai_model_package all_in_one_ai_model_package_group all_in_one_ai_pipeline all_in_one_ai_s3 all_in_one_ai_search_by_image all_in_one_ai_stop_training_job all_in_one_ai_stop_transform_job all_in_one_ai_train all_in_one_ai_training_job all_in_one_ai_transform_job all_in_one_ai_transform_job_review OpenSearch Domain all-in-one-ai Simple Queue Service all-in-one-ai System Store Parameters parameters starting with /all_in_one_ai/* VPCs all-in-one-ai","title":"Resources to be deleted prior to deployment."},{"location":"deployment/#resources-to-be-prepared-prior-to-deployment","text":"S3 bucket - in the same region as the stack to be launched. Domain Name of web portal (Optional) - Needed only when connections protocol to web portal is HTTPS. ACM SSL certificate of web portal (Optional) - Needed only when connections protocol to web portal is HTTPS","title":"Resources to be prepared prior to deployment"},{"location":"deployment/#toolkits-to-be-prepared-prior-to-deployment","text":"git awscli zip python3 pip3 docker","title":"Toolkits to be prepared prior to deployment"},{"location":"deployment/#service-quotas-and-limits","text":"Amazon VPC \u2013 1 Amazon VPC subnet \u2013 4 Amazon VPC Internet Gateway - 1 Amazon VPC NAT gateway \u2013 2 Amazon VPC EIP \u2013 2 Amazon VPC endpoint \u2013 5 Amazon VPC route table - 3 Amazon VPC Security group - 10 Amazon VPC interface endpoint - 5 Amazon IAM roles - 60 Amazon SSM - 40 Amazon Cognito user pool - 1 Amazon DynamoDB table - 10 Amazon EFS \u2013 1 Amazon EFS access point - 1 Amazon Lambda - 60 Amazon Rest API Gateway - 1 Amazon OpenSearch domain - 1 Amazon SQS queue - 1 Amazon ECS service \u2013 1 Amazon ECS task - 1 Amazon ECR private repository \u2013 1 Amazon S3 bucket \u2013 1 Amazon ACM public certificate - 1","title":"Service quotas and limits"},{"location":"deployment/#quick-deployment","text":"","title":"Quick Deployment"},{"location":"deployment/#get-source-code","text":"Contact your corresponding Amazon AWS Account BD/SA or email to yonglxie@amazon.com to get the source code.","title":"Get source code"},{"location":"deployment/#build-and-deploy","text":"Run the following commands to package python codes and build docker image for web portal and then upload assets to S3 and push docker image to ECR which region is the same AWS region as where CloudFormation stack. It will may take 30-60 minutes. ./build_and_deploy.sh [s3uri] [aws-region]","title":"Build and deploy"},{"location":"deployment/#various-deployment-options","text":"Option 1 \u2013 web portal with HTTP access It will be applicable only when you want to quickly experience this solution. You can leave Certificate field as blank in All-In-One AI main stack parameters to indicate it is option 1 \u2013 HTTP access only. Cautions: It is not recommended since there is no HTTPS encryption during network communication and there is no user authentication mechanism. Option 2 \u2013 web portal with HTTPS access It will be applicable only when you want use your own user authentication mechanism. You can leave CognitoRegion field as blank in All-In-One AI main stack parameters to indicate it is option 2 \u2013 HTTPS access only. Cautions: you need to integrate your own user authentication mechanism into this solution guidance. You can refer to the Cognito integration. Option 3 \u2013 web portal with HTTPS access + Cognito. You need to provide CognitoRegion, UserPool, UserPoolClient, UserPoolDomain in All-In-One AI main stack parameters to indicate it is option 3 \u2013 HTTPS access + Cognito. It is recommended since there is HTTPs encryption during network communication and user authentication enabled.","title":"Various deployment options"},{"location":"deployment/#cognito-user-pool-and-user-authentication","text":"The quick deployment process contains 2 steps: Cognito deployment (Optional) and All-In-One AI deployment via CloudFormation where these 2 CloudFormation stacks could be launched in different region. Cognito is optional used to authenticate with Cognito for All-In-One AI web portal. If Cognito authentication is enabled, Cognito deployment should be done prior to All-In-One AI deployment with parameters \u2013 ClientName, Domain, DomainName, Email, and Username. After Cognito CloudFormation stack is launched, outputs \u2013 UserPool, UserPoolClient, UserPoolDomain can be found at the Outputs of Cognito stack. Those outputs variable will be used as the input parameter of All-In-One AI. After All-In-One AI CloudFormation stack is launched, when accessing All-In-One AI web portal, there is a first-time redirection to Cognito Login page to authenticate with Cognito if the Cognito session is not existed yet. If Cognito authentication is disabled, please launch All-in-One AI CloudFormation Stack directly and leave parameters \u2013 CognitoRegion, UserPool, UserPoolClient, UserPoolDomain blank. When accessing All-In-One AI web portal, there is no first-time redirection to Cognito Login page.","title":"Cognito user pool and user authentication"},{"location":"deployment/#cognito-deployment-optional","text":"Launch CloudFormation stack template by clicking , and input Amazon S3 URL with HTTP URI of all-in-one-ai-cognito.yaml. Specify stack details. Please input DomainName, Email information of your stack template, and customize other parameters if needed. Choose Next Configure stack options. Keep everything as default and choose Next. Review stack all-in-one-ai. Check the 2 check boxes in the bottom. Choose Create Stack. Wait for around 5 minutes to get the stack launched. Check the Stack Outputs.","title":"Cognito deployment (Optional)"},{"location":"deployment/#all-in-one-ai-deployment","text":"Launch CloudFormation stack template by clicking , and input Amazon S3 URL with HTTP URI of all-in-one-ai-main.yaml. Specify stack details. Please select at least 2 availability zone, Certificate, DomainName, input S3 bucket/key information of your stack template, input CognitoRegion, UserPool, UserPoolClient, UserPoolDomain if Cognito authentication is enabled and customize other parameters if needed. Choose Next. Configure stack options. Keep everything as default. Review stack all-in-one-ai. Check the 2 check boxes in the bottom. Choose Create Stack. Wait for around 30-60 minutes to get the stack launched. Check the WebPortalURL, WebPortalDNS in the Stack Outputs and bind the WebPortalDNS to DomainName Open the Web Portal URL in the Stack Outputs. If Cognito authentication is enabled, Cognito Login window will be prompt to input Username/Password. If Cognito authentication successes, the web portal of All-In-One AI will be shown. If Cognito authentication is disabled, the web portal of All-In-One AI will be shown directly.","title":"All-In-One AI deployment"},{"location":"deployment/#build-stable-diffusion-webui","text":"","title":"Build stable-diffusion-webui"},{"location":"deployment/#build-and-push-to-ecr","text":"Go to sagemaker/stable-diffusion-webui and run ./build_and_push.sh [region-name] Note: It is a partial step of build_and_deploy.sh","title":"Build and push to ECR"},{"location":"deployment/#stable-diffusion-webui-deployment","text":"Launch CloudFormation stack template by clicking , and input Amazon S3 URL with HTTP URI of all-in-one-ai-cognito.yaml. Specify stack details. Please input API Gateway endpoint and select your private subnets, public subnets, vpc, and customize other parameters if needed. If you want to use HTTP, please leave the rest as blank. If you want to use HTTPS, please input ACM certifacate ARN and your domain name.Choose Next. For API Gateway endpoint, you can check it from the stack outputs of all-in-one-lambda.yaml. Configure stack options. Keep everything as default and choose Next. Review stack all-in-one-ai. Check the 1 check boxes in the bottom. Choose Create Stack. Wait for around 10 minutes to get the stack launched and check the stack outpus.","title":"stable-diffusion-webui deployment"},{"location":"deployment/#prepare-sd-models","text":"SD v2.0 768-v-ema.ckpt stable-diffusion/v2-inference-v.yaml SD v1.5 v1-5-pruned-emaonly.ckpt v1-5-pruned.ckpt SD v1.4 sd-v1-4-full-ema.ckpt sd-v1-4.ckpt You could pick up all your interested SD models and download them into one directory and then run python3 prepare.py [path-to-sd-models-directory] This script will help to generate model.tar.gz and push s3://[sagemaker-default-bucket]/assets/, push the whole model directory to s3://[sagemaker-default-bucket]/models/, and generate meta-data and save in DynamoDB. For instance, the following diagram shows the contents at the model files at s3://[sagemaker-default-bucket]/models/. Note: For SD v2.0, please keep the filename consistent, e.g. 768-v-ema.ckpt and 768-v-ema.yaml. Only English versions of SD 2.x and SD 1.x are supported. Chinese versions (e.g. Taiyi) are not supported yet.","title":"Prepare SD models"},{"location":"deployment/#launch-stable-diffusion-webui","text":"Wait 10 minutes until the stable-diffusion-webui server pass the health check and then check the stack outputs of all-in-one-ai-webui and then launch the stable-diffusion-webui.","title":"Launch stable-diffusion-webui"},{"location":"deployment/#resource-cleanup","text":"The resource created by CloudFormation will be deleted automatically when you delete CloudFormation stack. Before you delete CloudFormation stack, please make sure the following resources created dynamically are deleted. Go to AWS SageMaker Console , make sure all of model, endpoint config, and endpoint which were dynamically created are deleted.","title":"Resource Cleanup"},{"location":"deployment/#cloudformation-stack-parameters-reference","text":"Name Description Type Default S3Bucket S3 bucket of assets String S3Key S3 key of assets String CustomIdentifier AWS Resource Custom Identifier String all-in-one-ai AvailabilityZones The list of Availability Zones to use for the subnets in the VPC. Please select two AvailabilityZones. List DomainName Domain Name of Web Portal String Certificate Certificate of Domain Name String CognitoRegion Cognito Region String CIDR CIDR block for VPC string 10.0.0.0/16 PublicSubnet1CIDR CIDR block for the public subnet in Availability Zone A String 10.0.0.0/24 PublicSubnet2CIDR CIDR block for the public subnet in Availability Zone B String 10.0.1.0/24 PrivateSubnet1CIDR CIDR block for the private subnet in Availability Zone A String 10.0.2.0/24 PrivateSubnet2CIDR CIDR block for the private subnet in Availability Zone B String 10.0.3.0/24 EfsEncrpytedBoolean Create an encrypted Amazon EFS file system. String True EfsGrowth Amount of dummy data (GiB) to add to the file system (max 6144 GiB) Number 0 EfsPerformanceMode Select the performance mode of the file system. String generalPurpose OpenSearchDomainName OpenSearch Domain String all-in-one-ai OpenSearchInstanceType OpenSearchInstanceType String m5.4xlarge.search UserPool UserPool Id String UserPoolClient UserPoolClient Id String UserPoolDomain Endpoint of UserPoolDomain String ChinaRegion Check if the stack to be in CN Region String False","title":"CloudFormation Stack Parameters Reference"},{"location":"developer/","text":"Developer Guide Algorithms Yolov5 Create industrial model Model extra information { \"labels\": [ \"license-plate\", \"vehicle\" ] } Quickstart - train Hyperparameters Hyperparameter Default value Comment data /opt/ml/input/data/cfg/data.yaml Data configuration file cfg yolov5s.yaml Model configuration file weight yolov5s Model weight file (if it is not existed yet and it is standard weight file, it will download automatically project /opt/ml/model/ Model project directory name tutorial Model name img 640 Image size batch 16 Batch size epochs 10 Number of epochs Input data configuration Channel name Mandatory Comment images Yes S3 URI of images which contains train, validation images labels Yes S3 URI of labels which contains train, validation labels cfg Yes S3 URI of cfg which contains data.yaml weights No S3 URI of weights which contains model file Sample data configuration file train: /opt/ml/input/data/images/train/ val: /opt/ml/input/data/images/valid/ # number of classes nc: 2 # class names names: ['license-plate','vehicle'] Quickstart - deploy Environment variables Environment variable Default value Comment model_name custom Indicate if it is a custom model or pre-trained model. In case it is a custom model, the best.pt will be loaded from the specific location. Otherwise, pre-trained model file will be loaded. size 415 Chunk image size to be passed to model Quickstart - inference HTTP request Inference approach HTTP Body Comment Raw image data Bytes of image file ContentType: image/png, image/jpg, image/jpeg S3 image data { \u201cbucket\u201d: [s3-bucket], \u201cimage_uri\u201d: [s3-key] } ContentType: application/json HTTP response One row per object Each row is class x_center y_center width height format. Box coordinates must be normalized by the dimensions of the image (i.e. have values between 0 and 1) Class numbers are zero-indexed (start from 0). For example: 1 0.511271 0.571540 0.936967 0.631636 0 0.887925 0.714687 0.072043 0.101056 GluonCV Create industrial model Model extra information Image search { \"task\": \"search\" } Image classification { \"task\": \"classification\", \"classes\": [ \"tench\", \"goldfish\", ... ] } Quickstart - train Hyperparameters Hyperparameter Default value Comment classes 10 Number of classes batch_size 8 Batch size epochs 20 Number of epochs learning_rate 0.001 Learning rate momentum 0.9 Momentum wd 0.0001 wd num_workers 8 Number of workers model_name ResNet50_v2 Pretrained model name Input data configuration Channel name Mandatory Comment train Yes S3 URI of train images val Yes S3 URI of val images test Yes S3 URI of test images Quickstart - deploy Image search Image classification Environment variables Environment variable Default value Comment task search Indicate if the task is search or classification classes 1000 Number of classes model_name ResNet50_v2 Pretrained model name Quickstart - inference HTTP request Inference approach HTTP Body Comment Raw image data Bytes of image file ContentType: image/png, image/jpg, image/jpeg S3 image data { \u201cbucket\u201d: [s3-bucket], \u201cimage_uri\u201d: [s3-key] } ContentType: application/json HTTP response If task is search, return 2048 dimension embedding vector. If task is classification, return top-k matched class id array. PaddleOCR Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment classes 10 Number of classes batch_size 8 Batch size epochs 20 Number of epochs learning_rate 0.001 Learning rate momentum 0.9 Momentum wd 0.0001 wd num_workers 8 Number of workers model_name ResNet50_v2 Pretrained model name Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train dataset pretrained_models Yes S3 URI of pretrained models Quickstart - deploy Environment variables Environment variable Default value Comment task ocr Indicate if it is an OCR task or structure task device cpu CPU or GPU device det_model_dir None det model directory when it is an OCR task rec_model_dir None Rec model directory when it is an OCR task table_model_dir None table model directory when it is an OCR task rec_char_dict_path None rec custom dictionary path when it is an structure task table_char_dict_path None table custom dictionary path when it is an structure task lang ch language table True Indicate if table recognition is enabled when it is a structure task layout True Indicate if layout recognition is enabled when it is a structure task ocr True Indicate if ocr recognition is enabled when it is a structure task Quickstart - inference HTTP request Inference approach HTTP Body Comment Raw image data Bytes of image file ContentType: image/png, image/jpg, image/jpeg S3 image data { \u201cbucket\u201d: [s3-bucket], \u201cimage_uri\u201d: [s3-key] } ContentType: application/json HTTP response One row per text box Each row is in x_left_top, y_left_top, x_right_top, y_right_top, x_right_bottom, y_right_bottom, x_left_bottom, y_left_bottom format, for example: 479,138,1871,138,1871,198,479,198,\u82f1\u5f00\u66fc\u7fa4\u5c9b\u5546\u53f2\u6cf0\u535a\u80a1\u4efd\u6709\u9650\u516c\u53f8\u53f0\u7063\u5206\u516c\u53f8 972,212,1386,219,1385,283,971,275,\u96fb\u5b50\u767c\u7968\u8b49\u660e\u8068 1021,304,1336,304,1336,353,1021,353,2022-01-06 57,371,496,371,496,417,57,417,\u767c\u7968\u53f7\u78bc:WP79071184 1625,364,1771,364,1771,413,1625,413,\u683c\u5f0f:25 61,424,646,424,646,470,61,470,\u5be6\u65b9\u540d\uff1a\u7db2\u8d44\u8baf\u80a1\u4efd\u6709\u9650\u516c\u53f8 54,477,429,477,429,523,54,523,\u7d71\u4e00\u7f16\u53f7:24549210 57,530,157,530,157,576,57,576,\u5730\u5740: 54,576,150,576,150,629,54,629,\u5099: 2029,629,2293,629,2293,668,2029,668,\u7b2c1\u771f/\u51711\u771f 921,678,1432,678,1432,724,921,724,\u8996\u540c\u6b63\u672c,\u51e1\u7d93\u6539\u5373\u7121\u6548 1318,731,1400,731,1400,774,1318,774,\u8ecd\u50f9 1579,731,1671,731,1671,774,1579,774,\u91d1\u989d 486,735,568,735,568,777,486,777,\u54c1\u540d 1064,735,1154,735,1154,774,1064,774,\u6578\u91cf 1986,728,2075,728,2075,781,1986,781,\u5099 1379,781,1493,781,1493,834,1379,834,11.43 57,788,864,788,864,834,57,834,\u96c4\u72eeSIMBALION\u7ec6\u5b57\u5947\u7ffc\u7b46600/\u9ed1/1.0mm 1196,788,1225,788,1225,837,1196,837,5 1650,781,1761,781,1761,834,1650,834,57.14 1196,834,1225,834,1225,897,1196,897,3 1357,837,1489,837,1489,887,1357,887,100.00 61,841,807,841,807,887,61,887,\u7acb\u5f3aREGINA\u7121\u8033\u4e09\u5b54D\u578b\u00b1/R8603D/\u9ed1 1629,834,1761,834,1761,887,1629,887,300.00 1196,887,1225,887,1225,950,1196,950,5 1379,887,1489,887,1489,940,1379,940,56.19 57,894,893,894,893,940,57,940,11\u5b54\u900f\u660e\u842c\u80fd\u888b/A4/\u4eae\u9762/0.04mm/100\u5f20/\u5305 1620,888,1758,879,1762,932,1624,941,280.95 1377,941,1489,931,1494,988,1382,997,15.24 57,947,836,947,836,993,57,993,SDI\u5c0f\u4e09\u89d2\u8fe5\u94880731B/25.4mm/70\u652f/\u76d2 1196,947,1225,947,1225,989,1196,989,2 1650,940,1761,940,1761,993,1650,993,30.48 1379,996,1493,996,1493,1046,1379,1046,61.90 54,1000,989,1000,989,1046,54,1046,3M\u5c0f\u7ba1\u82af\u9690\u5f62\u81a0\u5e26810/19mmx32.9M/\u7eb8\u76d2-3/4\u65f6 1196,1000,1225,1000,1225,1042,1196,1042,1 1650,996,1761,996,1761,1046,1650,1046,61.90 57,1053,118,1053,118,1099,57,1099,/\u5377 1379,1102,1489,1102,1489,1152,1379,1152,57.14 54,1106,986,1106,986,1152,54,1152,3M\u5927\u7ba1\u82afOPP\u900f\u660e\u6587\u5177\u81a0\u5e26502/18mmx36M/8\u5377 1196,1109,1225,1109,1225,1144,1196,1144,1 1650,1102,1761,1102,1761,1152,1650,1152,57.14 61,1159,118,1159,118,1201,61,1201,/\u675f 1379,1201,1489,1201,1489,1254,1379,1254,85.72 53,1208,996,1201,997,1250,54,1258,3M\u5927\u7ba1\u82afOPP\u900f\u660e\u5c01\u7bb1\u81a0\u5e26/3036-6PK/48mmx36 1629,1201,1761,1201,1761,1250,1629,1250,171.43 1200,1215,1221,1215,1221,1247,1200,1247,2 64,1265,236,1265,236,1303,64,1303,M/6\u5377/\u675f 1379,1303,1493,1303,1493,1356,1379,1356,10.48 61,1311,857,1303,857,1353,61,1360,\u5f97\u529bDeli\u5f69\u8272\u8fe5\u7eb9\u91dd/E39716/33mm/100\u652f 1650,1303,1761,1303,1761,1353,1650,1353,10.48 51,2769,265,2777,263,2830,49,2822,\u92b7\u552e\u989d\u5408\u8ba1 1678,2776,2278,2773,2279,2822,1679,2826,970\u71df\u696d\u4eba\u7528\u7edf\u4e00\u767c\u7968\u5c02\u7528\u7ae0 125,2829,264,2829,264,2879,125,2879,\u71df\u696d\u7a0e 450,2833,536,2833,536,2875,450,2875,\u9e70\u7a0e 832,2833,957,2833,957,2872,832,2872,\u96f6\u7a0e\u7387 1218,2833,1307,2833,1307,2875,1218,2875,\u514d\u7a0e 1707,2829,2261,2829,2261,2875,1707,2875,48\u82f1\u66fc\u7fa4\u5c9b\u5546\u53f2\u6cf0\u535a\u80a1\u4efd 50,2879,136,2879,136,2932,50,2932,\u7e3d\u8a08 1654,2879,2132,2879,2132,2925,1654,2925,1,018\u6709\u9650\u516c\u53f8\u53f0\u7063\u5206\u516c\u53f8 361,2928,954,2936,953,3010,360,3002,\u58f9\u4edf\u96f6\u58f9\u62fe\u634c\u5143\u6574 1753,2928,2128,2925,2129,2974,1754,2978,\u7d71\u4e00\u7f16\u53f7:27946944 54,2939,393,2939,393,2999,54,2999,\u7e3d\u8a08\u65b0\u53f0 1764,2985,1971,2985,1971,3024,1764,3024,\u8d1f\u8d35\u4eba\uff1a\u5434 1754,3027,2279,3031,2278,3080,1753,3077,\u5730\u5740:\u65b0\u5317\u5e02\u65b0\u838a\u5340\u601d\u6e90\u8def60 1752,3076,1912,3084,1909,3134,1749,3125,1\u53f715\u697c CPT Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment model_name_or_path fnlp/cpt-large Pretrained model name num_train_epochs 10 Number of epochs per_device_train_batch_size 4 Batch size per device text_column text Label of text column summary_column summary Label of summary column output_dir /opt/ml/model Output directory train_file /opt/ml/input/data/dataset/train.json Path of train file validation_file /opt/ml/input/data/dataset/val.json Path of validation file test_file /opt/ml/input/data/dataset/test.json Path of test file val_max_target_length 80 Max target length path json Extension name Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train dataset Content format of train/validation/test file { \u201ctext\u201d: <text>, \u201csummary\u201d: <summary> } Quickstart - deploy Environment variables Environment variable Default value Comment input_max_length 512 Maximum effective input length output_max_length 512 Maximum effective output length top_p 0.95 Top probability of output summary Quickstart - inference HTTP request { \u201cinputs\u201d: \u201c\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5b89\u8fdc\u53bf\u652f\u884c\u4e0e\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u7b49\u501f\u6b3e\u5408\u540c\u7ea0\u7eb7\u4e00\u5ba1\u6c11\u4e8b\u5224\u51b3\u4e66 \u6c5f\u897f\u7701\u5b89\u8fdc\u53bf\u4eba\u6c11\u6cd5\u9662 \u6c11 \u4e8b \u5224 \u51b3 \u4e66 \uff082017\uff09\u8d630726\u6c11\u521d928\u53f7\u539f\u544a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5b89\u8fdc\u53bf\u652f\u884c\u3002 \u4f4f\u6240\u5730\uff1a\u5b89\u8fdc\u53bf\u6b23\u5c71\u9547\u9f99\u6cc9\u8def12\u53f7\u3002 \u6cd5\u5b9a\u4ee3\u8868\u4eba\u5510\u6587\u4e2d\uff0c\u7cfb\u8be5\u884c\u884c\u957f\u3002 \u59d4\u6258\u4ee3\u7406\u4eba\u4e25\u6d77\uff0c\u7cfb\u8be5\u884c\u5de5\u4f5c\u4eba\u5458\u3002 \u4ee3\u7406\u6743\u9650\uff1a\u4ee3\u4e3a\u627f\u8ba4\u3001\u653e\u5f03\u6216\u8005\u53d8\u66f4\u8bc9\u8bbc\u8bf7\u6c42\uff0c\u8fdb\u884c\u548c\u89e3\u3001\u63d0\u8d77\u53cd\u8bc9\u6216\u8005\u4e0a\u8bc9\u3002 \u88ab\u544a\u9b4f\u5764\u5143\uff0c\u7537\uff0c1957\u5e749\u67089\u65e5\u751f\uff0c\u6c49\u65cf\uff0c\u6c5f\u897f\u7701\u5b89\u8fdc\u53bf\u4eba\uff0c\u4f4f\u5b89\u8fdc\u53bf\u3002 \u88ab\u544a\u9b4f\u677e\u5170\uff0c\u7537\uff0c1971\u5e7412\u670816\u65e5\u751f\uff0c\u6c49\u65cf\uff0c\u6c5f\u897f\u7701\u5b89\u8fdc\u53bf\u4eba\uff0c\u4f4f\u5b89\u8fdc\u53bf\u3002 \u88ab\u544a\u9b4f\u78a7\u661f\uff0c\u7537\uff0c1982\u5e741\u670820\u65e5\u751f\uff0c\u6c49\u65cf\uff0c\u6c5f\u897f\u7701\u5b89\u8fdc\u53bf\u4eba\uff0c\u4f4f\u5b89\u8fdc\u53bf\u3002 \u539f\u544a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5b89\u8fdc\u53bf\u652f\u884c\uff08\u4ee5\u4e0b\u7b80\u79f0\u519c\u884c\u5b89\u8fdc\u652f\u884c\uff09\u8bc9\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u501f\u6b3e\u5408\u540c\u7ea0\u7eb7\u4e00\u6848\uff0c\u672c\u9662\u7acb\u6848\u53d7\u7406\u540e\uff0c\u4f9d\u6cd5\u7531\u5ba1\u5224\u5458\u5f90\u6d77\u5cf0\u9002\u7528\u7b80\u6613\u7a0b\u5e8f\uff0c\u4e8e2017\u5e748\u67088\u65e5\u516c\u5f00\u5f00\u5ead\u8fdb\u884c\u4e86\u5ba1\u7406\u3002 \u539f\u544a\u519c\u884c\u5b89\u8fdc\u652f\u884c\u7684\u59d4\u6258\u4ee3\u7406\u4eba\u4e25\u6d77\u5230\u5ead\u53c2\u52a0\u4e86\u8bc9\u8bbc\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u7ecf\u672c\u9662\u4f20\u7968\u4f20\u5524\u65e0\u6b63\u5f53\u7406\u7531\u672a\u5230\u5ead\u53c2\u52a0\u8bc9\u8bbc\u3002 \u672c\u6848\u73b0\u5df2\u5ba1\u7406\u7ec8\u7ed3\u3002 \u539f\u544a\u519c\u884c\u5b89\u8fdc\u652f\u884c\u8bc9\u79f0\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u4e8e2013\u5e7412\u670819\u65e5\u5411\u539f\u544a\u7533\u8bf7\u519c\u6237\u5c0f\u989d\u6700\u9ad8\u989d\u53ef\u5faa\u73af\u8d37\u6b3e\u4e00\u7b14\uff0c\u91d1\u989d50000\u5143\uff0c\u5e76\u7531\u88ab\u544a\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u63d0\u4f9b\u4fdd\u8bc1\u62c5\u4fdd\uff0c\u5408\u540c\u5230\u671f\u65e5\u4e3a2016\u5e7412\u670818\u65e5\uff0c\u5408\u540c\u7ea6\u5b9a\u5728\u6700\u9ad8\u989d\u5ea6\u548c\u671f\u9650\u5185\uff0c\u501f\u6b3e\u4eba\u968f\u501f\u968f\u8fd8\uff0c\u81ea\u52a9\u653e\u6b3e\u8fd8\u6b3e\uff0c\u5355\u7b14\u501f\u6b3e\u671f\u9650\u6700\u957f\u4e0d\u8d85\u8fc7\u4e00\u5e74\u3002 \u5408\u540c\u671f\u9650\u5185\uff0c\u501f\u6b3e\u4eba\u9b4f\u5764\u5143\u4e8e2015\u5e7412\u670823\u65e5\u901a\u8fc7\u539f\u544a\u81ea\u52a9\u7535\u5b50\u6e20\u9053\u7533\u8bf7\u8d37\u6b3e\u4e00\u7b14\u3001\u91d1\u989d50000\u5143\uff0c\u5230\u671f\u65e5\u4e3a2016\u5e7411\u670822\u65e5\uff0c\u81f3\u4eca\u4ecd\u7ed3\u6b20\u539f\u544a\u8d37\u6b3e\u672c\u91d150000\u5143\u53ca827.95\u5143\uff08\u5229\u606f\u8ba1\u7b97\u81f32016\u5e7412\u670820\u65e5\u6b62\uff09\u3002 \u8be5\u7b14\u8d37\u6b3e\u5df2\u903e\u671f\uff0c\u4e3a\u6b64\uff0c\u539f\u544a\u8bc9\u81f3\u6cd5\u9662\uff0c\u8bf7\u6c42\u4f9d\u6cd5\u5224\u4ee4\uff1a1\u3001\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u5f52\u8fd8\u539f\u544a\u8d37\u6b3e\u672c\u91d150000\u5143\u53ca\u5229\u606f827.95\u5143\uff08\u5229\u606f\u8ba1\u7b97\u81f32016\u5e7412\u670820\u65e5\u6b62\uff09\uff0c\u4e4b\u540e\u7684\u5229\u606f\u6309\u5408\u540c\u7ea6\u5b9a\u7684\u7f5a\u606f\u5229\u7387\u8ba1\u7b97\uff1b 2\u3001\u672c\u6848\u8bc9\u8bbc\u8d39\u7528\u7531\u88ab\u544a\u627f\u62c5\u3002 \u88ab\u544a\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u672a\u4f5c\u7b54\u8fa9\u3002 \u88ab\u544a\u9b4f\u5764\u5143\u672a\u5230\u5ead\u7b54\u8fa9\uff0c\u5176\u5728\u672c\u9662\u7684\u300a\u8be2\u95ee\u7b14\u5f55\u300b\u4e2d\u8fa9\u79f0\uff0c\u5bf9\u539f\u544a\u8d77\u8bc9\u6ca1\u6709\u5f02\u8bae\uff0c\u786e\u5b9e\u662f\u548c\u88ab\u544a\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u7ec4\u6210\u8054\u4fdd\u5c0f\u7ec4\uff0c\u76f8\u4e92\u62c5\u4fdd\uff0c\u88ab\u544a\u9b4f\u78a7\u661f\u662f\u88ab\u544a\u9b4f\u5764\u5143\u7684\u513f\u5b50\uff0c\u88ab\u544a\u9b4f\u677e\u5170\u662f\u88ab\u544a\u9b4f\u5764\u5143\u7684\u5802\u5f1f\u3002 \u4e09\u88ab\u544a\u5404\u5411\u539f\u544a\u501f\u6b3e5\u4e07\u5143\uff0c\u62d6\u6b20\u4e86\u672c\u606f\u81f3\u4eca\u3002 \u7ecf\u5ba1\u7406\u67e5\u660e\uff0c2013\u5e7411\u670825\u65e5\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u4e09\u4eba\u7ec4\u6210\u8054\u4fdd\u5c0f\u7ec4\uff0c\u76f8\u4e92\u627f\u62c5\u8fde\u5e26\u4fdd\u8bc1\u8d23\u4efb\u5411\u539f\u544a\u519c\u884c\u5b89\u8fdc\u652f\u884c\u7533\u8bf7\u501f\u6b3e\u3002 \u4e09\u88ab\u544a\u7ec4\u6210\u8054\u4fdd\u5c0f\u7ec4\u540e\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u5411\u539f\u544a\u501f\u6b3e50000\u5143\uff0c\u5e76\u7b7e\u8ba2\u4e86\u300a\u519c\u6237\u8d37\u6b3e\u501f\u6b3e\u5408\u540c\u300b\uff08\u4ee5\u4e0b\u7b80\u79f0\u300a\u501f\u6b3e\u5408\u540c\u300b\uff09\uff0c\u5408\u540c\u5185\u5bb9\uff1a\u201c\u7b2c\u4e00\u6761\u501f\u6b3e\u91d1\u989d/\u53ef\u5faa\u73af\u501f\u6b3e\u989d\u5ea6\uff08\u4eba\u6c11\u5e01\u5927\u5199\uff09\uff1a\u4f0d\u4e07\u5143\u3002 \u7528\u6b3e\u65b9\u5f0f\uff1a\u81ea\u52a9\u53ef\u5faa\u73af\u65b9\u5f0f\u3002 \u81ea2013\u5e7412\u670819\u65e5\u8d77\u81f32016\u5e7412\u670818\u65e5\uff08\u989d\u5ea6\u6709\u6548\u671f\uff09\uff0c\u501f\u6b3e\u4eba\u53ef\u5728\u4f0d\u4e07\u5143\u7684\u53ef\u5faa\u73af\u501f\u6b3e\u989d\u5ea6\u5185\u5411\u8d37\u6b3e\u4eba\u7533\u8bf7\u501f\u6b3e\uff0c\u5355\u7b14\u501f\u6b3e\u671f\u9650\u6700\u957f\u4e0d\u8d85\u8fc7\u58f9\u5e74\u4e14\u5230\u671f\u65e5\u6700\u8fdf\u4e0d\u5f97\u8d85\u8fc7\u989d\u5ea6\u6709\u6548\u671f\u3002 \u501f\u6b3e\u7528\u9014\uff1a\u751f\u4ea7\u7ecf\u8425\u3002 \u7b2c\u4e8c\u6761\u672c\u5408\u540c\u9879\u4e0b\uff0c\u501f\u6b3e\u6267\u884c\u5229\u7387\u4ee5\u501f\u6b3e\u53d1\u653e\u5f53\u65e5\u4e2d\u56fd\u4eba\u6c11\u94f6\u884c\u540c\u671f\u540c\u6863\u6b21\u4eba\u6c11\u5e01\u8d37\u6b3e\u57fa\u51c6\u5229\u7387\u57fa\u7840\u4e0a\u6d6e30%\u786e\u5b9a\u3002 1\u5e74\u671f\u4ee5\u5185\uff08\u542b\uff09\u7684\u501f\u6b3e\u6267\u884c\u6d6e\u52a8\u5229\u7387\u3002 1\u5e74\u671f\u4ee5\u4e0a\u7684\u501f\u6b3e\u6267\u884c\u6d6e\u52a8\u5229\u7387\u3002 \u6d6e\u52a8\u5229\u7387\u6307\u5982\u9047\u4e2d\u56fd\u4eba\u6c11\u94f6\u884c\u4eba\u6c11\u5e01\u8d37\u6b3e\u57fa\u51c6\u5229\u7387\u8c03\u6574\uff0c\u81ea\u57fa\u51c6\u5229\u7387\u8c03\u6574\u4e4b\u65e5\u8d77\uff0c\u6309\u8c03\u6574\u540e\u76f8\u5e94\u671f\u9650\u6863\u6b21\u7684\u57fa\u51c6\u5229\u7387\u548c\u672c\u5408\u540c\u7ea6\u5b9a\u7684\u501f\u6b3e\u5229\u7387\u6d6e\u52a8\u5e45\u5ea6\u786e\u5b9a\u65b0\u7684\u501f\u6b3e\u6267\u884c\u5229\u7387\uff0c\u4e14\u4e0d\u518d\u53e6\u884c\u901a\u77e5\u501f\u6b3e\u4eba\u548c\u62c5\u4fdd\u4eba\u3002 \u7b2c\u4e94\u6761\u4fdd\u8bc1\u65b9\u5f0f\u4e3a\u8fde\u5e26\u8d23\u4efb\u4fdd\u8bc1\uff0c\u4fdd\u8bc1\u671f\u95f4\u4e3a\u501f\u6b3e\u671f\u9650\u5c4a\u6ee1\u4e4b\u65e5\u8d77\u4e8c\u5e74\u3002 \u7b2c\u516d\u6761\u501f\u6b3e\u4eba\u672a\u6309\u7ea6\u5b9a\u671f\u9650\u5f52\u8fd8\u501f\u6b3e\u672c\u91d1\uff0c\u8d37\u6b3e\u4eba\u5bf9\u903e\u671f\u501f\u6b3e\u4ece\u903e\u671f\u4e4b\u65e5\u8d77\u5728\u501f\u6b3e\u6267\u884c\u5229\u7387\u57fa\u7840\u4e0a\u4e0a\u6d6e\u767e\u5206\u4e4b\u4f0d\u62fe\u8ba1\u6536\u7f5a\u606f\uff0c\u76f4\u81f3\u672c\u606f\u6e05\u507f\u4e3a\u6b62\u3002 \u2026\u2026\u201d \uff0c\u4e09\u88ab\u544a\u5747\u5728\u8be5\u300a\u501f\u6b3e\u5408\u540c\u300b\u4e0a\u7b7e\u540d\u637a\u5370\u3002 \u5408\u540c\u671f\u9650\u5185\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u4e8e2015\u5e7412\u670823\u65e5\u501f\u5230\u539f\u544a\u519c\u884c\u5b89\u8fdc\u652f\u884c\u53d1\u653e\u7684\u501f\u6b3e\u672c\u91d150000\u5143\uff0c\u501f\u6b3e\u51ed\u8bc1\u4e0a\u8f7d\u660e\u501f\u6b3e\u91d1\u989d\u4e3a\u4f0d\u4e07\u5143\u6574\uff0c\u6267\u884c\u5229\u7387\u4e3a5.655\uff05\uff0c\u903e\u671f\u5229\u7387\u4e3a8.4825%\uff0c\u501f\u6b3e\u65e5\u671f\u4e3a2015\u5e7412\u670823\u65e5\uff0c\u5230\u671f\u65e5\u671f\u4e3a2016\u5e7411\u670822\u65e5\u3002 \u88ab\u544a\u9b4f\u5764\u5143\u501f\u6b3e\u540e\uff0c\u7ecf\u539f\u544a\u591a\u6b21\u50ac\u6b3e\uff0c\u622a\u81f32017\u5e746\u670820\u65e5\uff0c\u4ecd\u62d6\u6b20\u539f\u544a\u501f\u6b3e\u672c\u91d150000\u5143\u53ca\u5229\u606f2993.36\u5143\u3002 \u4e0a\u8ff0\u4e8b\u5b9e\uff0c\u6709\u539f\u544a\u7684\u9648\u8ff0\uff0c\u539f\u544a\u63d0\u4ea4\u7684\u300a\u501f\u6b3e\u5408\u540c\u300b\u3001\u300a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u501f\u6b3e\u51ed\u8bc1\u300b\u3001\u300a\u8054\u5408\u4fdd\u8bc1\u62c5\u4fdd\u627f\u8bfa\u4e66\u300b\u3001\u300a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u519c\u6237\u5c0f\u989d\u8d37\u6b3e\u4e1a\u52a1\u7533\u8bf7\u8868\u300b\u3001\u300a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u519c\u6237\u5c0f\u989d\u8d37\u6b3e\u9762\u8c08\u8bb0\u5f55\u300b\u3001\u300a\u672c\u606f\u6e05\u5355\u300b\u7b49\u8bc1\u636e\u4e88\u4ee5\u8bc1\u5b9e\uff0c\u4e0a\u8ff0\u8bc1\u636e\u7ecf\u5ead\u5ba1\u5ba1\u67e5\uff0c\u80fd\u76f8\u4e92\u5370\u8bc1\uff0c\u672c\u9662\u4e88\u4ee5\u786e\u8ba4\u3002 \u672c\u9662\u8ba4\u4e3a\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u5411\u539f\u544a\u519c\u884c\u5b89\u8fdc\u652f\u884c\u501f\u6b3e\uff0c\u53cc\u65b9\u7b7e\u8ba2\u4e86\u501f\u6b3e\u5408\u540c\uff0c\u539f\u544a\u4e5f\u4f9d\u7ea6\u5411\u88ab\u544a\u9b4f\u5764\u5143\u53d1\u653e\u4e86\u501f\u6b3e\uff0c\u7531\u6b64\u5f62\u6210\u7684\u501f\u6b3e\u5408\u540c\u5173\u7cfb\u5408\u6cd5\u6709\u6548\uff0c\u53d7\u6cd5\u5f8b\u4fdd\u62a4\u3002 \u501f\u6b3e\u5230\u671f\u540e\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u5e94\u6e05\u507f\u501f\u6b3e\u672c\u91d1\u5e76\u4f9d\u7ea6\u652f\u4ed8\u5229\u606f\uff0c\u4f46\u5176\u81f3\u4eca\u672a\u8fd8\u6e05\u501f\u6b3e\u672c\u91d1\u53ca\u76f8\u5e94\u5229\u606f\uff0c\u5176\u884c\u4e3a\u663e\u5c5e\u8fdd\u7ea6\u3002 \u7531\u4e8e\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u4e09\u4eba\u7ec4\u6210\u8054\u4fdd\u5c0f\u7ec4\uff0c\u4e09\u88ab\u544a\u4e2d\u4efb\u4e00\u4eba\u501f\u6b3e\u5747\u7531\u5176\u4ed6\u4e8c\u88ab\u544a\u63d0\u4f9b\u8fde\u5e26\u8d23\u4efb\u4fdd\u8bc1\uff0c\u5373\u4e09\u88ab\u544a\u76f8\u4e92\u627f\u62c5\u8fde\u5e26\u4fdd\u8bc1\u8d23\u4efb\u3002 \u56e0\u6b64\uff0c\u88ab\u544a\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u4e8c\u4eba\u5e94\u4e0e\u503a\u52a1\u4eba\u88ab\u544a\u9b4f\u5764\u5143\u627f\u62c5\u8fde\u5e26\u507f\u8fd8\u8d23\u4efb\uff0c\u4f9d\u7ea6\u507f\u8fd8\u539f\u544a\u501f\u6b3e\u672c\u91d1\u53ca\u76f8\u5e94\u5229\u606f\u3002 \u7efc\u4e0a\uff0c\u4f9d\u7167\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u5408\u540c\u6cd5\u300b\u7b2c\u4e00\u767e\u96f6\u4e03\u6761\u3001\u7b2c\u4e8c\u767e\u96f6\u56db\u6761\u3001\u7b2c\u4e8c\u767e\u96f6\u4e94\u6761\u3001\u7b2c\u4e8c\u767e\u96f6\u4e03\u6761\uff0c\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u62c5\u4fdd\u6cd5\u300b\u7b2c\u5341\u4e8c\u6761\u3001\u7b2c\u5341\u516b\u6761\u3001\u7b2c\u4e8c\u5341\u4e00\u6761\uff0c\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u6c11\u4e8b\u8bc9\u8bbc\u6cd5\u300b\u7b2c\u4e00\u767e\u56db\u5341\u56db\u6761\u4e4b\u89c4\u5b9a\uff0c\u5224\u51b3\u5982\u4e0b\uff1a\u4e00\u3001\u88ab\u544a\u9b4f\u5764\u5143\u4e8e\u672c\u5224\u51b3\u751f\u6548\u540e\u4e09\u5341\u65e5\u5185\u507f\u8fd8\u539f\u544a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5b89\u8fdc\u53bf\u652f\u884c\u501f\u6b3e\u672c\u91d150000\u5143\u53ca\u5229\u606f\uff08\u622a\u81f32017\u5e746\u670820\u65e5\u7684\u5229\u606f\u4e3a2993.36\u5143\uff0c2017\u5e746\u670820\u65e5\u4e4b\u540e\u7684\u5229\u606f\u6309\u7167\u5408\u540c\u7ea6\u5b9a\u7684\u7f5a\u606f\u5229\u7387\u8ba1\u7b97\uff09\u3002 \u4e8c\u3001\u88ab\u544a\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u5bf9\u4e0a\u8ff0\u6b3e\u9879\u627f\u62c5\u8fde\u5e26\u507f\u8fd8\u8d23\u4efb\u3002 \u5982\u679c\u672a\u6309\u672c\u5224\u51b3\u6307\u5b9a\u7684\u671f\u95f4\u5c65\u884c\u7ed9\u4ed8\u91d1\u94b1\u4e49\u52a1\uff0c\u5e94\u5f53\u4f9d\u7167\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u6c11\u4e8b\u8bc9\u8bbc\u6cd5\u300b\u7b2c\u4e8c\u767e\u4e94\u5341\u4e09\u6761\u4e4b\u89c4\u5b9a\uff0c\u52a0\u500d\u652f\u4ed8\u8fdf\u5ef6\u5c65\u884c\u671f\u95f4\u7684\u503a\u52a1\u5229\u606f\u3002 \u6848\u4ef6\u53d7\u7406\u8d391070\u5143\uff0c\u51cf\u534a\u6536\u53d6535\u5143\uff0c\u7531\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u5171\u540c\u8d1f\u62c5\u3002 \u5982\u4e0d\u670d\u672c\u5224\u51b3\uff0c\u53ef\u5728\u5224\u51b3\u4e66\u9001\u8fbe\u4e4b\u65e5\u8d77\u5341\u4e94\u65e5\u5185\uff0c\u5411\u672c\u9662\u9012\u4ea4\u4e0a\u8bc9\u72b6\uff0c\u5e76\u6309\u5bf9\u65b9\u5f53\u4e8b\u4eba\u7684\u4eba\u6570\u63d0\u51fa\u526f\u672c\uff08\u5728\u9012\u4ea4\u4e0a\u8bc9\u72b6\u4e4b\u65e5\u8d77\u4e03\u65e5\u5185\u9884\u4ea4\u4e0a\u8bc9\u8d39\uff0c\u7f34\u4ea4\u4e0a\u8bc9\u8d39\u8d26\u53f7\uff1a99\u00d7\u00d7\u00d788\uff0c\u5f00\u6237\u884c\uff1a\u62db\u5546\u94f6\u884c\u8d63\u5dde\u957f\u5f81\u5927\u9053\u652f\u884c\uff0c\u6237\u540d\uff1a\u6c5f\u897f\u7701\u8d63\u5dde\u5e02\u4e2d\u7ea7\u4eba\u6c11\u6cd5\u9662\uff0c\u5907\u6ce8\u680f\u6ce8\u660e\u4e0a\u8bc9\u8d39\uff09\uff0c\u4e0a\u8bc9\u4e8e\u6c5f\u897f\u7701\u8d63\u5dde\u5e02\u4e2d\u7ea7\u4eba\u6c11\u6cd5\u9662\u3002 \uff08\u6cd5\u5f8b\u6587\u4e66\u751f\u6548\u540e\uff0c\u4e00\u65b9\u62d2\u7edd\u5c65\u884c\u7684\uff0c\u5bf9\u65b9\u5f53\u4e8b\u4eba\u5411\u672c\u9662\u7533\u8bf7\u6267\u884c\u7684\u671f\u9650\u662f\u4ece\u5224\u51b3\u4e66\u89c4\u5b9a\u7684\u5c65\u884c\u671f\u9650\u5c4a\u6ee1\u4e8c\u5e74\u5185\uff09\u5ba1\u5224\u5458\u3000\u3000\u5f90\u6d77\u5cf0 \u4e8c\u3007\u4e00\u4e03\u5e74\u4e5d\u6708\u5341\u4e00\u65e5 \u4e66\u8bb0\u5458\u3000\u3000\u674e\u9b41\u9e4f\u201d } HTTP response { \u201cresult\u201d: \u201c[SEP] [CLS] \u539f \u88ab \u544a \u7cfb \u501f \u6b3e \u5408 \u540c \u7ea0 \u7eb7 \u3002 \u539f \u544a \u63d0 \u51fa \u8bc9 \u8bbc \u8bf7 \u6c42 \uff1a \u88ab \u544a \u507f \u8fd8 \u539f \u544a \u8d37 \u6b3e \u53ca \u5229 \u606f \u3001 \u7f5a \u606f \uff1b \u4fdd \u8bc1 \u4eba \u627f \u62c5 \u8fde \u5e26 \u6e05 \u507f \u8d23 \u4efb \u3002 \u88ab \u544a \u672a \u7b54 \u8fa9 \u3002 \u7ecf \u5ba1 \u67e5 \uff0c \u539f \u544a \u4e0e \u88ab \u544a \u7b7e \u8ba2 \u7684 \u519c \u6237 \u8d37 \u6b3e \u501f \u6b3e \u53ca \u62c5 \u4fdd \u5408 \u540c \u5408 \u6cd5 \u6709 \u6548 \uff0c \u88ab \u544a \u5e94 \u5f53 \u6309 \u7167 \u5408 \u540c \u7ea6 \u5b9a \u5c65 \u884c \u507f \u8fd8 \u501f \u6b3e \u4e49 \u52a1 \uff0c \u5426 \u5219 \u539f \u544a \u5bf9 \u88ab \u544a \u62b5 \u62bc \u7269 \u4eab \u6709 \u4f18 \u5148 \u53d7 \u507f \u6743 \u3002 \u7efc \u4e0a \uff0c \u4f9d \u7167 \u300a \u4e2d \u534e \u4eba \u6c11 \u5171 \u548c \u56fd \u5408 \u540c \u6cd5 \u300b \u7b2c \u516d \u5341 \u6761 \u7b2c \u4e00 \u6b3e \u3001 \u7b2c \u4e00 \u767e \u4e5d \u5341 \u516d \u6761 \u3001 \u7b2c \u4e8c \u767e \u96f6 \u4e94 \u6761 \u3001 \u4e8c \u767e \u4e00 \u5341 \u4e00 \u6761 \u3001 \u300a \u62c5 \u4fdd \u6cd5 \u300b \u53ca \u300a \u6700 \u9ad8 \u4eba \u6c11 \u6cd5 \u9662 \u5173 \u4e8e \u9002 \u7528 \u82e5 \u5e72 \u95ee \u9898 \u7684 \u89e3 \u91ca \uff08 \u4e8c \uff09 \u300b \u7b2c \u4e8c \u5341 \u56db \u6761 \u53ca \u300a \u6c11 \u4e8b \u8bc9 \u8bbc \u6cd5 \u300b \u4e4b \u89c4 \u5b9a \uff0c \u5224 \u51b3 \u88ab \u544a \u7ed9 \u4ed8 \u539f \u544a \u519c \u6237 \u6700 \u9ad8 \u989d \u53ef \u5faa \u73af \u8d37 \u6b3e \u903e \u671f \u5229 \u606f \u53ca \u7f5a \u606f \u3002 [SEP]\u201d } GABSA Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment task uabsa The name of the task, selected from: [uabsa, aste, tasd, aope] dataset rest14 The name of the dataset, selected from: [laptop14, rest14, rest15, rest16] model_name_or_path t5-base Pretrained model name paradigm annotation The way to construct target sentence, selected from: [annotation, extraction] do_train True Whether to run training. do_eval False Whether to run eval on the dev/test set. do_batch_predict False Whether to run batch prediction. do_direct_eval False Whether to run direct eval on the dev/test set. do_direct_predict False Whether to run direct eval on the dev/test set. max_seq_length 128 Maximum sequence length train_batch_size 16 Batch train size eval_batch_size 16 Batch eval size gradient_accumulation_steps 1 Number of updates steps to accumulate before performing a backward/update pass. learning_rate 3e-4 Learning rate num_train_epochs 20 Number of train epochs seed 42 seed ckpoint_path /opt/ml/model/cktepoch=1.ckpt Checkpoint path weight_decay 0.0 Weight decay adam_epsilon 1e-8 Adam epsilon warmup_steps 0.0 Warmup steps Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train dataset Content format of train/validation/test file - Each row contains origin string####[(word, aspect, sentiment),\u2026], for example: The wine list is interesting and has many good values .####[('wine list', 'drinks style_options', 'positive'), ('wine list', 'drinks prices', 'positive')] Quickstart - deploy Environment variables Environment variable Default value Comment input_max_length 512 Maximum effective input length output_max_length 512 Maximum effective output length top_p 0.95 Top probability of output summary Quickstart - inference HTTP request { \"inputs\": \"The wine list is wonderful and the food reminds me of my recent trip to Italy .\" } HTTP response { \"result\": \"(wine list, drinks style_options, positive); (food, food quality, positive)\" } PaddleNLP Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment batch_size 16 Batch size learning_rate 1e-5 Learning rate train_path /opt/ml/input/data/dataset/train.txt Path of train file dev_path /opt/ml/input/data/dataset/dev.txt Path of dev file max_seq_len 512 Maximum sequence length num_epochs 100 Number of epochs seed 1000 seed logging_steps 10 Number of logging steps valid_steps 100 Number of validation steps device gpu CPU or GPU model uie-base Pretrained model name Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train dataset Content format of train/validation/test file - Each row contains json string with content, result_list, and prompt, for example: { \"content\": \"5\u67089\u65e5\u4ea4\u901a\u8d3929\u5143\u4ece\u5317\u82d1\u5230\u671b\u4eac\u641c\u540e\", \"result_list\": [{\"text\": \"5\u67089\u65e5\", \"start\": 0, \"end\": 4}], \"prompt\": \"\u65f6\u95f4\" } Quickstart - deploy Environment variables Environment variable Default value Comment device cpu CPU or GPU schema Schema to inference Quickstart - inference HTTP request { \"inputs\":\"\u4e0a\u6d77\u8679\u6865\u9ad8\u94c1\u5230\u676d\u5dde\u65f6\u95f4\u662f9\u670824\u65e5\u8d39\u7528\u662f73\u5143\" } HTTP response { \"result\": [ { \"\u51fa\u53d1\u5730\": [ { \"text\": \"\u4e0a\u6d77\", \"start\": 0, \"end\": 2, \"probability\": \"0.99601215\" } ], \"\u76ee\u7684\u5730\": [ { \"text\": \"\u676d\u5dde\", \"start\": 7, \"end\": 9, \"probability\": \"0.99965054\" } ], \"\u8d39\u7528\": [ { \"text\": \"73\u5143\", \"start\": 20, \"end\": 23, \"probability\": \"0.79425305\" } ], \"\u65f6\u95f4\": [ { \"text\": \"9\u670824\u65e5\", \"start\": 12, \"end\": 17, \"probability\": \"0.9998573\" } ] } ] } DeBERTa Create industrial model Model extra information {} Quickstart - deploy Quickstart - inference HTTP request { \"inputs\": \"\u5982\u4f55\u6709\u6548\u5b66\u4e60\uff1f\", \"parameters\": { \"candidate_labels\": [ \"\u6c11\u751f\", \"\u6587\u5316\", \"\u5a31\u4e50\", \"\u4f53\u80b2\", \"\u8d22\u7ecf\", \"\u623f\u4ea7\", \"\u6c7d\u8f66\", \"\u6559\u80b2\", \"\u79d1\u6280\", \"\u519b\u4e8b\", \"\u65c5\u6e38\", \"\u56fd\u9645\", \"\u8bc1\u5238\", \"\u519c\u4e1a\", \"\u7535\u7ade\" ] } } HTTP response { \"sequence\": \"\u5982\u4f55\u6709\u6548\u5b66\u4e60\uff1f\", \"labels\": [ \"\u6559\u80b2\", \"\u6587\u5316\", \"\u79d1\u6280\", \"\u6c11\u751f\", \"\u56fd\u9645\", \"\u6c7d\u8f66\", \"\u519b\u4e8b\", \"\u7535\u7ade\", \"\u8bc1\u5238\", \"\u8d22\u7ecf\", \"\u519c\u4e1a\", \"\u4f53\u80b2\", \"\u623f\u4ea7\", \"\u5a31\u4e50\", \"\u65c5\u6e38\" ], \"scores\": [ 0.7116793990135193, 0.03544081375002861, 0.0295342355966568, 0.028479689732193947, 0.024489011615514755, 0.023759257048368454, 0.023078029975295067, 0.017534229904413223, 0.01741044595837593, 0.017365973442792892, 0.01681639440357685, 0.01475503295660019, 0.013634421862661839, 0.013062535785138607, 0.012960496358573437 ] } KeyBert Create industrial model Model extra information {} Quickstart - deploy Environment variables Environment variable Default value Comment type default One of [sentence-transformer, huggingface-transformer, flair, spacy, universal-sentence-encoder, gensim, default] model - paraphrase-multilingual-MiniLM-L12-v2 when type is sentence-transformer - en_core_web_trf when type is Spacy - https://tfhub.dev/google/universal-sentence-encoder/4 when type is universal-sentence-encoder - fasttext-wiki-news-subwords-300 when type is gensim Model name huggingface_pipeline feature-extraction when type is huggingface-transformer HuggingFace pipeline mode - doc-embedding when type is flair - transformer when type is spacy - Use document embeddeding model or word embedding model when type is flair - Use non-transformer, transformer, transformer without GPU when type is spacy doc_embedding roberta-base when type is flair Document embedding word_embedding crawl when type is flair Word embedding keyphrase_ngram_start 1 Minimum length in words of generated keywords/keyphrases keyphrase_ngram_end 1 Maximum length in words of generated keywords/keyphrases stop_words english Stopwords to remove from the document top_n 5 Return the top n keywords/keyphrases min_df 1 Minimum document frequency of a word across all documents use_maxsum False Whether to use Max Sum Distance for the selection of keywords/keyphrases use_mmr False Whether to use Maximal Marginal Relevance (MMR) for the selection of keywords/keyphrases diversity 0.5 The diversity of the results between 0 and 1 if use_mmr is set to True nr_candidates 20 The number of candidates to consider if use_maxsum is set to True highlight False Whether to print the document and highlight its keywords/keyphrases Quickstart - inference HTTP request { \"inputs\": \"\u8fd1\u5e74\u6765,\u5d4c\u5165\u5f0f\u6280\u672f\u4e0e\u65e0\u7ebf\u7f51\u7edc\u6280\u672f\u6df1\u5ea6\u7ed3\u5408,\u50ac\u751f\u4e86\u53ef\u8ba1\u7b97RFID\u3001\u5d4c\u5165\u5f0f\u4f20\u611f\u7f51\u7b49\u65b0\u5174\u9886\u57df.\u8fd9\u4e9b\u7cfb\u7edf\u7531\u5927\u91cf\u5ec9\u4ef7\u7684\u8282\u70b9\u7ec4\u6210,\u5e94\u7528\u524d\u666f\u5e7f\u6cdb.\u5728\u4f20\u7edf\u8bbe\u8ba1\u4e2d,\u8fd9\u4e9b\u7cfb\u7edf\u901a\u5e38\u662f\u6839\u636e\u5e94\u7528\u5b9a\u5236\u7684.\u6839\u636e\u5e94\u7528\u5b9a\u5236\u7684\u7cfb\u7edf\u5177\u6709\u5f00\u53d1\u7b80\u4fbf\u3001\u8fd0\u884c\u9ad8\u6548\u7b49\u4f18\u70b9,\u4f46\u4e0d\u9002\u5408\u672a\u6765\u5927\u89c4\u6a21\u90e8\u7f72.\u8fd9\u662f\u56e0\u4e3a\u5982\u679c\u8fd9\u4e9b\u7cfb\u7edf\u8ddf\u5e94\u7528\u5bc6\u5207\u7ed1\u5b9a\u3001\u96be\u4ee5\u66f4\u65b0,\u90a3\u4e48\u7cfb\u7edf\u4e00\u7ecf\u90e8\u7f72\u5c31\u96be\u4ee5\u66f4\u65b0\u5176\u8f6f\u4ef6,\u4ece\u800c\u963b\u788d\u4e86\u8f6f\u4ef6\u521b\u65b0\u7684\u8fdb\u7a0b.\u8f6f\u4ef6\u5b9a\u4e49\u7684\u601d\u60f3\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u8be5\u95ee\u9898.\u5f53\u524d,\u8f6f\u4ef6\u5b9a\u4e49\u7f51\u7edc\u6210\u4e3a\u8ba1\u7b97\u673a\u7f51\u7edc\u4e2d\u4e00\u4e2a\u70ed\u95e8\u7684\u7814\u7a76\u9886\u57df.\u4f20\u611f\u5668\u7f51\u7edc\u7684\u8f6f\u4ef6\u8bbe\u8ba1\u4e0e\u56e0\u7279\u7f51\u7684\u8f6f\u4ef6\u8bbe\u8ba1\u5b58\u5728\u8bf8\u591a\u5dee\u5f02,\u5176\u6700\u5927\u7684\u5dee\u5f02\u5728\u4e8e,\u4f20\u611f\u5668\u7f51\u7edc\u4e3b\u8981\u4ee5\u4fe1\u606f\u7684\u91c7\u96c6\u4e3a\u6838\u5fc3,\u800c\u56e0\u7279\u7f51\u4e3b\u8981\u4ee5\u4fe1\u606f\u7684\u4f20\u8f93\u4e3a\u6838\u5fc3.\u6b64\u5916,\u4f20\u611f\u5668\u8282\u70b9\u8fd8\u5177\u6709\u4f53\u79ef\u5c0f\u3001\u7535\u6c60\u7eed\u822a\u80fd\u529b\u6709\u9650\u3001\u4ef7\u683c\u4f4e\u5ec9\u7b49\u7279\u70b9.\u6587\u4e2d\u4e3b\u8981\u8c03\u7814\u4e86\u8bbe\u8ba1\u8f6f\u4ef6\u5b9a\u4e49\u4f20\u611f\u5668\u7f51\u7edc(Software-DefinedSensorNetworks,SDSNs)\u67b6\u6784\u7684\u76f8\u5173\u5de5\u4f5c,\u5217\u4e3e\u4e86\u5728\u8bbe\u8ba1\u4e00\u4e2a\u901a\u7528\u3001\u9ad8\u6548\u7684\u8f6f\u4ef6\u5b9a\u4e49\u4f20\u611f\u5668\u7f51\u7edc\u67b6\u6784\u65f6\u53ef\u80fd\u9047\u5230\u7684\u6311\u6218,\u5e76\u56de\u987e\u4e86\u4e00\u4e9b\u6709\u7528\u7684\u6280\u672f.\u8fd9\u4e9b\u6280\u672f\u6709\u7684\u6765\u81ea\u4e8e\u73b0\u6709\u65b9\u6848,\u6709\u7684\u80fd\u591f\u76f4\u63a5\u88ab\u7528\u6765\u89e3\u51b3\u4e00\u90e8\u5206\u6311\u6218.\u6b64\u5916,\u6587\u4e2d\u8fd8\u4ece\u8f6f\u4ef6\u5b9a\u4e49\u529f\u80fd\u7684\u89d2\u5ea6,\u8fdb\u4e00\u6b65\u5730\u5bf9\u76ee\u524d\u901a\u7528\u3001\u9ad8\u6548\u7684\u8f6f\u4ef6\u5b9a\u4e49\u4f20\u611f\u5668\u7f51\u7edc\u67b6\u6784\u53ca\u5176\u91c7\u7528\u7684\u6280\u672f\u8fdb\u884c\u4e86\u5206\u7c7b.\u6211\u4eec\u8ba4\u4e3a,\u8f6f\u4ef6\u5b9a\u4e49\u4f20\u611f\u5668\u7f51\u7edc\u67b6\u6784\u5c06\u5728\u5df2\u90e8\u7f72\u7684\u7f51\u7edc\u4e2d\u8d77\u5230\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528,\u5e76\u5e26\u6765\u4e00\u573a\u65b0\u7684\u6280\u672f\u53d8\u9769.\" } HTTP response { \"result\": [ [ \"\u65e0\u7ebf\u7f51\u7edc\", 0.6223 ], [ \"\u8ba1\u7b97\u673a\u7f51\u7edc\", 0.447 ], [ \"definedsensornetworks\", 0.4356 ], [ \"\u6280\u672f\", 0.4297 ], [ \"\u56e0\u7279\u7f51\", 0.4001 ] ] } GluonTS Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment algo-name DeepAR Algorithm name model-dir 8 /opt/ml/model output-dir 20 /opt/ml/output train 0.001 /opt/ml/input/data/dataset test 0.9 /opt/ml/input/data/dataset freq 1D frequence prediction-length 2*14 Prediction length context-length 20*14 Context length batch-size 2048 Batch size epochs 100 Number of epochs num-batches-per-epoc 2 Number of batches per epochs learning-rate 0.001 Learning rate learning-rate-decay-factor 0.5 Learning rate decay factor patience 10 Patience minimum-learning-rate 5e-5 Minimum learning rate clip-gradient 10 Clip gradient weight-decay 1e-8 Weight decay init xavier hybridize False use-feat-dynamic-real False use-feat-static-cat False use-past-feat-dynamic-real False cardinality use-log1p False Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train data Quickstart - deploy Environment variables Environment variable Default value Comment freq 1H target_quantile 0.5 use_log1p False Quickstart - inference HTTP request { \"inputs\": [ { \"target\": [ 12,28,12,0,56,12,8,12,28,4,24,8,12,4,4,8,16,4,24,12,16,16,4,24,12,12,16,24,8,16,12,40,12,32,24,8,8,8,20,20,32,20,16,16,8,24,32,12,16,4,4,28,12,24,20,12,44,32,36,20,24,28,40,84,52,20,20,64,36,44,28,24,32,12,44,72,50,15,35,80,75,24,60,42,12,18,60,54,72,49,72,88,24,88,90,33,22,9,54,88,117,136,99,80,50,110,88,44,44,36,63,72,108,63,60,55,66,33,120,55,12,100,80,117,72,135,55,77,120,66,121,132,72,0,60,77,50,136,40,88,99,77,275,168,26,80,110,130,140,130,187,110,204,220,144,204,60,36,156,220,154,279,297,374,132,192,182,266,140,156,247,228,360,270,209,104,247,364,420,255,240,225,300,338,352,429,273,336,270,390,570,544,765,208,336,405,434,364,416,256,368,493,408,666,1216,221,391,289,812,588,544,320,351,300,660,754,600,432,481,504,650,486,516,480,540,442,572,465,576,130,546,598,640,682,546,546,728,630,616,960,527,585,570,630,825,852,690,770,480,608,1072,1224,720,629,850,1037,988,767,935,900,1110,901,1560,2091,1008,833,1602,1785,1470,1365,1258,1152,1380,1332,2412,2320,1196,1350,1178,1136,117,363,846,595,1488,1691,2508,2992,725,1386,1701,1638,1548,1216,1360,1122,2180,1638,2814,2925,1363,902,1175,1320,1140,1292,1128,1134,1738 ], \"start\": \"1980-01-01 00:00:00\", \"item_id\": \"T234\", \"freq\": \"1M\", \"prediction_length\": 24 }, { \"target\": [ 12,28,12,0,56,12,8,12,28,4,24,8,12,4,4,8,16,4,24,12,16,16,4,24,12,12,16,24,8,16,12,40,12,32,24,8,8,8,20,20,32,20,16,16,8,24,32,12,16,4,4,28,12,24,20,12,44,32,36,20,24,28,40,84,52,20,20,64,36,44,28,24,32,12,44,72,50,15,35,80,75,24,60,42,12,18,60,54,72,49,72,88,24,88,90,33,22,9,54,88,117,136,99,80,50,110,88,44,44,36,63,72,108,63,60,55,66,33,120,55,12,100,80,117,72,135,55,77,120,66,121,132,72,0,60,77,50,136,40,88,99,77,275,168,26,80,110,130,140,130,187,110,204,220,144,204,60,36,156,220,154,279,297,374,132,192,182,266,140,156,247,228,360,270,209,104,247,364,420,255,240,225,300,338,352,429,273,336,270,390,570,544,765,208,336,405,434,364,416,256,368,493,408,666,1216,221,391,289,812,588,544,320,351,300,660,754,600,432,481,504,650,486,516,480,540,442,572,465,576,130,546,598,640,682,546,546,728,630,616,960,527,585,570,630,825,852,690,770,480,608,1072,1224,720,629,850,1037,988,767,935,900,1110,901,1560,2091,1008,833,1602,1785,1470,1365,1258,1152,1380,1332,2412,2320,1196,1350,1178,1136,117,363,846,595,1488,1691,2508,2992,725,1386,1701,1638,1548,1216,1360,1122,2180,1638,2814,2925,1363,902,1175,1320,1140,1292,1128,1134,1738,1564,3427,3325,1482,1584,1449,2222,1836,1332,1584,1680,1869,2002,3190,2652,1568,966,1380,1794,1350,1577,1104,1188,1495 ], \"start\":\"1980-01-01 00:00:00\", \"item_id\": \"T234\", \"freq\": \"1M\", \"prediction_length\": 24 } ] } HTTP response { \"result\": [ [ 1930.8326416015625, 2290.176025390625, 2243.770263671875, 1112.35888671875, 1216.8353271484375, 1300.52587890625, 1319.37451171875, 1104.0013427734375, 1231.51611328125, 1281.2568359375, 1306.0784912109375, 1798.2593994140625, 1773.2158203125, 2148.71142578125, 2055.391357421875, 1097.5042724609375, 1143.5330810546875, 1365.8883056640625, 1335.6077880859375, 1208.5709228515625, 1230.0604248046875, 1293.724853515625, 1298.18798828125, 1691.08056640625 ], [ 1820.448974609375, 2697.013916015625, 2449.663818359375, 1375.6854248046875, 1132.6513671875, 1368.69091796875, 1617.199951171875, 1349.854248046875, 1284.10986328125, 1291.0433349609375, 1288.84130859375, 1595.6607666015625, 1741.90185546875, 2308.14013671875, 2105.67529296875, 1253.835205078125, 1139.4034423828125, 1357.335205078125, 1589.59228515625, 1372.781982421875, 1298.3154296875, 1244.7462158203125, 1267.4632568359375, 1574.6981201171875 ] ] } StyleGAN Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment gpus 1 Num of GPUS snap 50 Number of GPUs to use [default: 1] metrics fid50k_full Comma-separated list or \"none\" [default: fid50k_full] seed 0 Random seed data Training data (directory or zip) cond false Train conditional model based on dataset labels [default: false] subset all 'Train with only N images mirror false Enable dataset x-flips config auto Base config, one of 'auto', 'stylegan2', 'paper256', 'paper512', 'paper1024', 'cifar' gamma Override R1 gamma kimg Override training duration batch Override batch size aug ada Augmentation mode, one of 'noaug', 'ada', 'fixed' p Augmentation probability for --aug=fixed target ADA target value for --aug=ada augpipe bgc Augmentation pipeline resume noresume Resume training freezed 0 Freezed layers fp32 Disable mixed-precision training nhwc Use NHWC memory format with FP16 nobench Disable cuDNN benchmarking allow-tf32 Allow PyTorch to use TF32 internally workers Override number of DataLoader workers Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train data Quickstart - deploy Environment variables Environment variable Default value Comment network Pre-trianed network URL Quickstart - inference HTTP request { \"inputs\": { \"trunc\": \"0.7325021066422363\", \"seeds\": \"9,206,870,370\" } } HTTP response [ \"s3://sagemaker-ap-east-1-034068151705/stylegan/inference/outputseed0370.png\", \"s3://sagemaker-ap-east-1-034068151705/stylegan/inference/outputseed0009.png\", \"s3://sagemaker-ap-east-1-034068151705/stylegan/inference/outputseed0870.png\", \"s3://sagemaker-ap-east-1-034068151705/stylegan/inference/outputseed0206.png\" ] Yolov5PaddleOCR Create industrial model Model extra information {} Quickstart - inference stable-diffusion-webui Create industrial model It will be created by default if you have started stable-diffusion-webui once. Alternative you can create it explicitly. Note industrial model of stable-diffusion-webui is unique within one all-in-one-ai app and with name 'stable-diffusion-webui' by design. Quickstart - train Basically we support 3 train approach instable-diffusion-webui: embedding, hypernetwork, and dreambooth which can be used to train person, object, style. Strongly recommend that you start the training job inside of stable-diffusion-webui since it is already supported with more friendely user interface. Alternative you start the training job explicitly. Hyperparameters Hyperparameter Default value Comment region Current region name AWS region name embeddings-s3uri s3://[sagemaker-default-bucket]/stable-diffusion-webui/embeddings/ S3 URI of embeddings, only applicable for embedding or hypernetwork training hypernetwork-s3uri s3://[sagemaker-default-bucket]/stable-diffusion-webui/hypernetwork/ S3 URI of hypernetwork, only applicable for embedding or hypernetwork training train-task embedding One of embedding, hypernetwork, dreambooth api-endpoint REST API Gateway of all-in-one-ai REST API Gateway db-models-s3uri s3://[sagemaker-default-bucket]/stable-diffusion-webui/dreambooth/ S3 URI of dreambooth model S3 URI, only applicable for dreambooth training sd-models-s3uri s3://[sagemaker-default-bucket]/stable-diffusion-webui/models/ stable diffusion models S3 URI, only applicable for dreambooth training train-args train-args which is up to train-task dreambooth-config-id dreambooth config id which is used to identify the dreambooth config in s3://[sagemaker-default-bucket]/stable-diffusion-webui/dreambooth-config/ train-args example for train dreambooth {\\\"train_dreambooth_settings\\\": {\\\"db_create_new_db_model\\\": true, \\\"db_new_model_name\\\": \\\"my-awsdogtoy-model-002\\\", \\\"db_new_model_src\\\": \\\"768-v-ema.ckpt\\\", \\\"db_new_model_scheduler\\\": \\\"ddim\\\", \\\"db_create_from_hub\\\": false, \\\"db_new_model_url\\\": \\\"\\\", \\\"db_new_model_token\\\": \\\"\\\", \\\"db_new_model_extract_ema\\\": false, \\\"db_model_name\\\": \\\"\\\", \\\"db_lora_model_name\\\": \\\"\\\", \\\"db_lora_weight\\\": 1, \\\"db_lora_txt_weight\\\": 1, \\\"db_train_imagic_only\\\": false, \\\"db_use_subdir\\\": false, \\\"db_custom_model_name\\\": \\\"\\\", \\\"db_train_wizard_person\\\": false, \\\"db_train_wizard_object\\\": true, \\\"db_performance_wizard\\\": true}} dreambooth-config example for train dreambooth \"\"\" model_name: str = \"\", adam_beta1: float = 0.9, adam_beta2: float = 0.999, adam_epsilon: float = 1e-8, adam_weight_decay: float = 0.01, attention: str = \"default\", center_crop: bool = True, concepts_path: str = \"\", custom_model_name: str = \"\", epoch_pause_frequency: int = 0, epoch_pause_time: int = 0, gradient_accumulation_steps: int = 1, gradient_checkpointing: bool = True, half_model: bool = False, has_ema: bool = False, hflip: bool = False, learning_rate: float = 0.00000172, lora_learning_rate: float = 1e-4, lora_txt_learning_rate: float = 5e-5, lr_scheduler: str = 'constant', lr_warmup_steps: int = 0, max_token_length: int = 75, max_train_steps: int = 1000, mixed_precision: str = \"fp16\", model_path: str = \"\", not_cache_latents=False, num_train_epochs: int = 1, pad_tokens: bool = True, pretrained_vae_name_or_path: str = \"\", prior_loss_weight: float = 1.0, resolution: int = 512, revision: int = 0, sample_batch_size: int = 1, save_class_txt: bool = False, save_embedding_every: int = 500, save_preview_every: int = 500, save_use_global_counts: bool = False, save_use_epochs: bool = False, scale_lr: bool = False, scheduler: str = \"ddim\", src: str = \"\", shuffle_tags: bool = False, train_batch_size: int = 1, train_text_encoder: bool = True, use_8bit_adam: bool = True, use_concepts: bool = False, use_cpu: bool = False, use_ema: bool = True, use_lora: bool = False, v2: bool = False, c1_class_data_dir: str = \"\", c1_class_guidance_scale: float = 7.5, c1_class_infer_steps: int = 60, c1_class_negative_prompt: str = \"\", c1_class_prompt: str = \"\", c1_class_token: str = \"\", c1_instance_data_dir: str = \"\", c1_instance_prompt: str = \"\", c1_instance_token: str = \"\", c1_max_steps: int = -1, c1_n_save_sample: int = 1, c1_num_class_images: int = 0, c1_sample_seed: int = -1, c1_save_guidance_scale: float = 7.5, c1_save_infer_steps: int = 60, c1_save_sample_negative_prompt: str = \"\", c1_save_sample_prompt: str = \"\", c1_save_sample_template: str = \"\", c2_class_data_dir: str = \"\", c2_class_guidance_scale: float = 7.5, c2_class_infer_steps: int = 60, c2_class_negative_prompt: str = \"\", c2_class_prompt: str = \"\", c2_class_token: str = \"\", c2_instance_data_dir: str = \"\", c2_instance_prompt: str = \"\", c2_instance_token: str = \"\", c2_max_steps: int = -1, c2_n_save_sample: int = 1, c2_num_class_images: int = 0, c2_sample_seed: int = -1, c2_save_guidance_scale: float = 7.5, c2_save_infer_steps: int = 60, c2_save_sample_negative_prompt: str = \"\", c2_save_sample_prompt: str = \"\", c2_save_sample_template: str = \"\", c3_class_data_dir: str = \"\", c3_class_guidance_scale: float = 7.5, c3_class_infer_steps: int = 60, c3_class_negative_prompt: str = \"\", c3_class_prompt: str = \"\", c3_class_token: str = \"\", c3_instance_data_dir: str = \"\", c3_instance_prompt: str = \"\", c3_instance_token: str = \"\", c3_max_steps: int = -1, c3_n_save_sample: int = 1, c3_num_class_images: int = 0, c3_sample_seed: int = -1, c3_save_guidance_scale: float = 7.5, c3_save_infer_steps: int = 60, c3_save_sample_negative_prompt: str = \"\", c3_save_sample_prompt: str = \"\", c3_save_sample_template: str = \"\", concepts_list=None \"\"\" [ \"\", 0.9, 0.999, 1e-08, 0.01, \"default\", False, \"\", \"\", 0.0, 60.0, 1, True, False, \"\", True, 2e-06, 0.0002, 0.0002, \"constant\", 500, 75, 0, \"no\", \"\", True, 100, True, \"\", 1, 512, \"\", 1, True, 500, 500, True, False, False, \"\", \"\", False, 1, True, False, False, False, False, False, \"\", \"\", 7.5, 40, \"\", \"\", \"photo of dog\", \"/opt/ml/input/data/concepts/images\", \"\", \"photo of awsdogtoy dog\", -1, 1, 0, -1, 7.5, 40, \"\", \"\", \"\", \"\", 7.5, 40, \"\", \"\", \"\", \"\", \"\", \"\", -1, 1, 0, -1, 7.5, 40, \"\", \"\", \"\", \"\", 7.5, 40, \"\", \"\", \"\", \"\", \"\", \"\", -1, 1, 0, -1, 7.5, 40, \"\", \"\", \"\" ] Input data configuration Channel name Mandatory Comment images Yes S3 URI of images models No S3 URI of stable diffusion models embedding No S3 URI of embeddings hypernetwork No S3 URI of hypernetwork lora No S3 URI of lora models dreambooth No S3 URI of dreambooth models Quickstart - deploy Environment variables Environment variable Default value Comment api_endpoint REST API Gateway of all-in-one-ai REST API Gateway endpoint_name Name of SageMaker Endpoint which is be used to host stable diffusion models and generate images Setup stable-diffusion-webui Signin or Signup Choose user tab and then signin or signup firstly. Note you won't be able to perform any GPU related actions unless you are logined via either signin or signup. Configure your SageMaker endpoint and your stable diffusion models Select your SageMaker endpoint firstly from dropdown list of avaiable SageMaker endpoints list. You may refresh the available SageMaker endpoints list by clicking refresh button right after SageMaker endpoints dropdown list. Then refresh stable diffusion models by clicking refresh button right after stable diffusion models and choose your stable diffusion model. Quickstart - Inference - Text to Image HTTP request payload = { 'enable_hr': False, 'denoising_strength': 0.7, 'firstphase_width': 0, 'firstphase_height': 0, 'prompt': \"dog\", 'styles': ['None', 'None'], 'seed': -1, 'subseed': -1, 'subseed_strength': 0.0, 'seed_resize_from_h': 0, 'seed_resize_from_w': 0, 'sampler_name': None, 'batch_size': 1, 'n_iter':1, 'steps': 20, 'cfg_scale': 7.0, 'width': 768, 'height': 768, 'restore_faces': False, 'tiling': False, 'negative_prompt': '', 'eta': 1.0, 's_churn': 0.0, 's_tmax': None, 's_tmin': 0.0, 's_noise': 1.0, 'override_settings': {}, 'script_args': '[0, false, false, false, \"\", 1, \"\", 0, \"\", true, false, false]', 'sampler_index': 'Euler a' } inputs = { 'task': 'text-to-image', 'txt2img_payload': payload, 'username': 'e' } HTTP response { \"images\" : [ [base64 encoded images], ..., [base64 encoded images] ] } Quickstart - Inference - Image to Image HTTP request payload = { 'init_images': [image_encoded_in_base64], 'resize_mode': 0, 'denoising_strength': 0.75, 'mask': None, 'mask_blur': 4, 'inpainting_fill': 1, 'inpaint_full_res': False, 'inpaint_full_res_padding': 32, 'inpainting_mask_invert': 0, 'prompt': 'cat', 'styles': ['None', 'None'], 'seed': -1, 'subseed': -1, 'subseed_strength': 0.0, 'seed_resize_from_h': 0, 'seed_resize_from_w': 0, 'sampler_name': None, 'batch_size': 1, 'n_iter': 1, 'steps': 20, 'cfg_scale': 7.0, 'width': 768, 'height': 768, 'restore_faces': False, 'tiling': False, 'negative_prompt': '', 'eta': 1.0, 's_churn': 0.0, 's_tmax': None, 's_tmin': 0.0, 's_noise': 1.0, 'override_settings': {}, 'script_args': '[0, \"<ul>\\\\n<li><code>CFG Scale</code> should be 2 or lower.</li>\\\\n</ul>\\\\n\", true, true, \"\", \"\", true, 50, true, 1, 0, false, 4, 1, \"<p style=\\\\\"margin-bottom:0.75em\\\\\">Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8</p>\", 128, 8, [\"left\", \"right\", \"up\", \"down\"], 1, 0.05, 128, 4, 0, [\"left\", \"right\", \"up\", \"down\"], false, false, false, \"\", \"<p style=\\\\\"margin-bottom:0.75em\\\\\">Will upscale the image to twice the dimensions; use width and height sliders to set tile size</p>\", 64, 0, 1, \"\", 0, \"\", true, false, false]', 'sampler_index': 'Euler a', 'include_init_images': False } inputs = { 'task': 'image-to-image', 'img2img_payload': payload, 'username': 'e' } HTTP response { \"images\" : [ [base64 encoded images], ..., [base64 encoded images] ] }","title":"Developer Guide"},{"location":"developer/#developer-guide","text":"","title":"Developer Guide"},{"location":"developer/#algorithms","text":"","title":"Algorithms"},{"location":"developer/#yolov5","text":"Create industrial model Model extra information { \"labels\": [ \"license-plate\", \"vehicle\" ] } Quickstart - train Hyperparameters Hyperparameter Default value Comment data /opt/ml/input/data/cfg/data.yaml Data configuration file cfg yolov5s.yaml Model configuration file weight yolov5s Model weight file (if it is not existed yet and it is standard weight file, it will download automatically project /opt/ml/model/ Model project directory name tutorial Model name img 640 Image size batch 16 Batch size epochs 10 Number of epochs Input data configuration Channel name Mandatory Comment images Yes S3 URI of images which contains train, validation images labels Yes S3 URI of labels which contains train, validation labels cfg Yes S3 URI of cfg which contains data.yaml weights No S3 URI of weights which contains model file Sample data configuration file train: /opt/ml/input/data/images/train/ val: /opt/ml/input/data/images/valid/ # number of classes nc: 2 # class names names: ['license-plate','vehicle'] Quickstart - deploy Environment variables Environment variable Default value Comment model_name custom Indicate if it is a custom model or pre-trained model. In case it is a custom model, the best.pt will be loaded from the specific location. Otherwise, pre-trained model file will be loaded. size 415 Chunk image size to be passed to model Quickstart - inference HTTP request Inference approach HTTP Body Comment Raw image data Bytes of image file ContentType: image/png, image/jpg, image/jpeg S3 image data { \u201cbucket\u201d: [s3-bucket], \u201cimage_uri\u201d: [s3-key] } ContentType: application/json HTTP response One row per object Each row is class x_center y_center width height format. Box coordinates must be normalized by the dimensions of the image (i.e. have values between 0 and 1) Class numbers are zero-indexed (start from 0). For example: 1 0.511271 0.571540 0.936967 0.631636 0 0.887925 0.714687 0.072043 0.101056","title":"Yolov5"},{"location":"developer/#gluoncv","text":"Create industrial model Model extra information Image search { \"task\": \"search\" } Image classification { \"task\": \"classification\", \"classes\": [ \"tench\", \"goldfish\", ... ] } Quickstart - train Hyperparameters Hyperparameter Default value Comment classes 10 Number of classes batch_size 8 Batch size epochs 20 Number of epochs learning_rate 0.001 Learning rate momentum 0.9 Momentum wd 0.0001 wd num_workers 8 Number of workers model_name ResNet50_v2 Pretrained model name Input data configuration Channel name Mandatory Comment train Yes S3 URI of train images val Yes S3 URI of val images test Yes S3 URI of test images Quickstart - deploy Image search Image classification Environment variables Environment variable Default value Comment task search Indicate if the task is search or classification classes 1000 Number of classes model_name ResNet50_v2 Pretrained model name Quickstart - inference HTTP request Inference approach HTTP Body Comment Raw image data Bytes of image file ContentType: image/png, image/jpg, image/jpeg S3 image data { \u201cbucket\u201d: [s3-bucket], \u201cimage_uri\u201d: [s3-key] } ContentType: application/json HTTP response If task is search, return 2048 dimension embedding vector. If task is classification, return top-k matched class id array.","title":"GluonCV"},{"location":"developer/#paddleocr","text":"Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment classes 10 Number of classes batch_size 8 Batch size epochs 20 Number of epochs learning_rate 0.001 Learning rate momentum 0.9 Momentum wd 0.0001 wd num_workers 8 Number of workers model_name ResNet50_v2 Pretrained model name Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train dataset pretrained_models Yes S3 URI of pretrained models Quickstart - deploy Environment variables Environment variable Default value Comment task ocr Indicate if it is an OCR task or structure task device cpu CPU or GPU device det_model_dir None det model directory when it is an OCR task rec_model_dir None Rec model directory when it is an OCR task table_model_dir None table model directory when it is an OCR task rec_char_dict_path None rec custom dictionary path when it is an structure task table_char_dict_path None table custom dictionary path when it is an structure task lang ch language table True Indicate if table recognition is enabled when it is a structure task layout True Indicate if layout recognition is enabled when it is a structure task ocr True Indicate if ocr recognition is enabled when it is a structure task Quickstart - inference HTTP request Inference approach HTTP Body Comment Raw image data Bytes of image file ContentType: image/png, image/jpg, image/jpeg S3 image data { \u201cbucket\u201d: [s3-bucket], \u201cimage_uri\u201d: [s3-key] } ContentType: application/json HTTP response One row per text box Each row is in x_left_top, y_left_top, x_right_top, y_right_top, x_right_bottom, y_right_bottom, x_left_bottom, y_left_bottom format, for example: 479,138,1871,138,1871,198,479,198,\u82f1\u5f00\u66fc\u7fa4\u5c9b\u5546\u53f2\u6cf0\u535a\u80a1\u4efd\u6709\u9650\u516c\u53f8\u53f0\u7063\u5206\u516c\u53f8 972,212,1386,219,1385,283,971,275,\u96fb\u5b50\u767c\u7968\u8b49\u660e\u8068 1021,304,1336,304,1336,353,1021,353,2022-01-06 57,371,496,371,496,417,57,417,\u767c\u7968\u53f7\u78bc:WP79071184 1625,364,1771,364,1771,413,1625,413,\u683c\u5f0f:25 61,424,646,424,646,470,61,470,\u5be6\u65b9\u540d\uff1a\u7db2\u8d44\u8baf\u80a1\u4efd\u6709\u9650\u516c\u53f8 54,477,429,477,429,523,54,523,\u7d71\u4e00\u7f16\u53f7:24549210 57,530,157,530,157,576,57,576,\u5730\u5740: 54,576,150,576,150,629,54,629,\u5099: 2029,629,2293,629,2293,668,2029,668,\u7b2c1\u771f/\u51711\u771f 921,678,1432,678,1432,724,921,724,\u8996\u540c\u6b63\u672c,\u51e1\u7d93\u6539\u5373\u7121\u6548 1318,731,1400,731,1400,774,1318,774,\u8ecd\u50f9 1579,731,1671,731,1671,774,1579,774,\u91d1\u989d 486,735,568,735,568,777,486,777,\u54c1\u540d 1064,735,1154,735,1154,774,1064,774,\u6578\u91cf 1986,728,2075,728,2075,781,1986,781,\u5099 1379,781,1493,781,1493,834,1379,834,11.43 57,788,864,788,864,834,57,834,\u96c4\u72eeSIMBALION\u7ec6\u5b57\u5947\u7ffc\u7b46600/\u9ed1/1.0mm 1196,788,1225,788,1225,837,1196,837,5 1650,781,1761,781,1761,834,1650,834,57.14 1196,834,1225,834,1225,897,1196,897,3 1357,837,1489,837,1489,887,1357,887,100.00 61,841,807,841,807,887,61,887,\u7acb\u5f3aREGINA\u7121\u8033\u4e09\u5b54D\u578b\u00b1/R8603D/\u9ed1 1629,834,1761,834,1761,887,1629,887,300.00 1196,887,1225,887,1225,950,1196,950,5 1379,887,1489,887,1489,940,1379,940,56.19 57,894,893,894,893,940,57,940,11\u5b54\u900f\u660e\u842c\u80fd\u888b/A4/\u4eae\u9762/0.04mm/100\u5f20/\u5305 1620,888,1758,879,1762,932,1624,941,280.95 1377,941,1489,931,1494,988,1382,997,15.24 57,947,836,947,836,993,57,993,SDI\u5c0f\u4e09\u89d2\u8fe5\u94880731B/25.4mm/70\u652f/\u76d2 1196,947,1225,947,1225,989,1196,989,2 1650,940,1761,940,1761,993,1650,993,30.48 1379,996,1493,996,1493,1046,1379,1046,61.90 54,1000,989,1000,989,1046,54,1046,3M\u5c0f\u7ba1\u82af\u9690\u5f62\u81a0\u5e26810/19mmx32.9M/\u7eb8\u76d2-3/4\u65f6 1196,1000,1225,1000,1225,1042,1196,1042,1 1650,996,1761,996,1761,1046,1650,1046,61.90 57,1053,118,1053,118,1099,57,1099,/\u5377 1379,1102,1489,1102,1489,1152,1379,1152,57.14 54,1106,986,1106,986,1152,54,1152,3M\u5927\u7ba1\u82afOPP\u900f\u660e\u6587\u5177\u81a0\u5e26502/18mmx36M/8\u5377 1196,1109,1225,1109,1225,1144,1196,1144,1 1650,1102,1761,1102,1761,1152,1650,1152,57.14 61,1159,118,1159,118,1201,61,1201,/\u675f 1379,1201,1489,1201,1489,1254,1379,1254,85.72 53,1208,996,1201,997,1250,54,1258,3M\u5927\u7ba1\u82afOPP\u900f\u660e\u5c01\u7bb1\u81a0\u5e26/3036-6PK/48mmx36 1629,1201,1761,1201,1761,1250,1629,1250,171.43 1200,1215,1221,1215,1221,1247,1200,1247,2 64,1265,236,1265,236,1303,64,1303,M/6\u5377/\u675f 1379,1303,1493,1303,1493,1356,1379,1356,10.48 61,1311,857,1303,857,1353,61,1360,\u5f97\u529bDeli\u5f69\u8272\u8fe5\u7eb9\u91dd/E39716/33mm/100\u652f 1650,1303,1761,1303,1761,1353,1650,1353,10.48 51,2769,265,2777,263,2830,49,2822,\u92b7\u552e\u989d\u5408\u8ba1 1678,2776,2278,2773,2279,2822,1679,2826,970\u71df\u696d\u4eba\u7528\u7edf\u4e00\u767c\u7968\u5c02\u7528\u7ae0 125,2829,264,2829,264,2879,125,2879,\u71df\u696d\u7a0e 450,2833,536,2833,536,2875,450,2875,\u9e70\u7a0e 832,2833,957,2833,957,2872,832,2872,\u96f6\u7a0e\u7387 1218,2833,1307,2833,1307,2875,1218,2875,\u514d\u7a0e 1707,2829,2261,2829,2261,2875,1707,2875,48\u82f1\u66fc\u7fa4\u5c9b\u5546\u53f2\u6cf0\u535a\u80a1\u4efd 50,2879,136,2879,136,2932,50,2932,\u7e3d\u8a08 1654,2879,2132,2879,2132,2925,1654,2925,1,018\u6709\u9650\u516c\u53f8\u53f0\u7063\u5206\u516c\u53f8 361,2928,954,2936,953,3010,360,3002,\u58f9\u4edf\u96f6\u58f9\u62fe\u634c\u5143\u6574 1753,2928,2128,2925,2129,2974,1754,2978,\u7d71\u4e00\u7f16\u53f7:27946944 54,2939,393,2939,393,2999,54,2999,\u7e3d\u8a08\u65b0\u53f0 1764,2985,1971,2985,1971,3024,1764,3024,\u8d1f\u8d35\u4eba\uff1a\u5434 1754,3027,2279,3031,2278,3080,1753,3077,\u5730\u5740:\u65b0\u5317\u5e02\u65b0\u838a\u5340\u601d\u6e90\u8def60 1752,3076,1912,3084,1909,3134,1749,3125,1\u53f715\u697c","title":"PaddleOCR"},{"location":"developer/#cpt","text":"Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment model_name_or_path fnlp/cpt-large Pretrained model name num_train_epochs 10 Number of epochs per_device_train_batch_size 4 Batch size per device text_column text Label of text column summary_column summary Label of summary column output_dir /opt/ml/model Output directory train_file /opt/ml/input/data/dataset/train.json Path of train file validation_file /opt/ml/input/data/dataset/val.json Path of validation file test_file /opt/ml/input/data/dataset/test.json Path of test file val_max_target_length 80 Max target length path json Extension name Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train dataset Content format of train/validation/test file { \u201ctext\u201d: <text>, \u201csummary\u201d: <summary> } Quickstart - deploy Environment variables Environment variable Default value Comment input_max_length 512 Maximum effective input length output_max_length 512 Maximum effective output length top_p 0.95 Top probability of output summary Quickstart - inference HTTP request { \u201cinputs\u201d: \u201c\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5b89\u8fdc\u53bf\u652f\u884c\u4e0e\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u7b49\u501f\u6b3e\u5408\u540c\u7ea0\u7eb7\u4e00\u5ba1\u6c11\u4e8b\u5224\u51b3\u4e66 \u6c5f\u897f\u7701\u5b89\u8fdc\u53bf\u4eba\u6c11\u6cd5\u9662 \u6c11 \u4e8b \u5224 \u51b3 \u4e66 \uff082017\uff09\u8d630726\u6c11\u521d928\u53f7\u539f\u544a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5b89\u8fdc\u53bf\u652f\u884c\u3002 \u4f4f\u6240\u5730\uff1a\u5b89\u8fdc\u53bf\u6b23\u5c71\u9547\u9f99\u6cc9\u8def12\u53f7\u3002 \u6cd5\u5b9a\u4ee3\u8868\u4eba\u5510\u6587\u4e2d\uff0c\u7cfb\u8be5\u884c\u884c\u957f\u3002 \u59d4\u6258\u4ee3\u7406\u4eba\u4e25\u6d77\uff0c\u7cfb\u8be5\u884c\u5de5\u4f5c\u4eba\u5458\u3002 \u4ee3\u7406\u6743\u9650\uff1a\u4ee3\u4e3a\u627f\u8ba4\u3001\u653e\u5f03\u6216\u8005\u53d8\u66f4\u8bc9\u8bbc\u8bf7\u6c42\uff0c\u8fdb\u884c\u548c\u89e3\u3001\u63d0\u8d77\u53cd\u8bc9\u6216\u8005\u4e0a\u8bc9\u3002 \u88ab\u544a\u9b4f\u5764\u5143\uff0c\u7537\uff0c1957\u5e749\u67089\u65e5\u751f\uff0c\u6c49\u65cf\uff0c\u6c5f\u897f\u7701\u5b89\u8fdc\u53bf\u4eba\uff0c\u4f4f\u5b89\u8fdc\u53bf\u3002 \u88ab\u544a\u9b4f\u677e\u5170\uff0c\u7537\uff0c1971\u5e7412\u670816\u65e5\u751f\uff0c\u6c49\u65cf\uff0c\u6c5f\u897f\u7701\u5b89\u8fdc\u53bf\u4eba\uff0c\u4f4f\u5b89\u8fdc\u53bf\u3002 \u88ab\u544a\u9b4f\u78a7\u661f\uff0c\u7537\uff0c1982\u5e741\u670820\u65e5\u751f\uff0c\u6c49\u65cf\uff0c\u6c5f\u897f\u7701\u5b89\u8fdc\u53bf\u4eba\uff0c\u4f4f\u5b89\u8fdc\u53bf\u3002 \u539f\u544a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5b89\u8fdc\u53bf\u652f\u884c\uff08\u4ee5\u4e0b\u7b80\u79f0\u519c\u884c\u5b89\u8fdc\u652f\u884c\uff09\u8bc9\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u501f\u6b3e\u5408\u540c\u7ea0\u7eb7\u4e00\u6848\uff0c\u672c\u9662\u7acb\u6848\u53d7\u7406\u540e\uff0c\u4f9d\u6cd5\u7531\u5ba1\u5224\u5458\u5f90\u6d77\u5cf0\u9002\u7528\u7b80\u6613\u7a0b\u5e8f\uff0c\u4e8e2017\u5e748\u67088\u65e5\u516c\u5f00\u5f00\u5ead\u8fdb\u884c\u4e86\u5ba1\u7406\u3002 \u539f\u544a\u519c\u884c\u5b89\u8fdc\u652f\u884c\u7684\u59d4\u6258\u4ee3\u7406\u4eba\u4e25\u6d77\u5230\u5ead\u53c2\u52a0\u4e86\u8bc9\u8bbc\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u7ecf\u672c\u9662\u4f20\u7968\u4f20\u5524\u65e0\u6b63\u5f53\u7406\u7531\u672a\u5230\u5ead\u53c2\u52a0\u8bc9\u8bbc\u3002 \u672c\u6848\u73b0\u5df2\u5ba1\u7406\u7ec8\u7ed3\u3002 \u539f\u544a\u519c\u884c\u5b89\u8fdc\u652f\u884c\u8bc9\u79f0\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u4e8e2013\u5e7412\u670819\u65e5\u5411\u539f\u544a\u7533\u8bf7\u519c\u6237\u5c0f\u989d\u6700\u9ad8\u989d\u53ef\u5faa\u73af\u8d37\u6b3e\u4e00\u7b14\uff0c\u91d1\u989d50000\u5143\uff0c\u5e76\u7531\u88ab\u544a\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u63d0\u4f9b\u4fdd\u8bc1\u62c5\u4fdd\uff0c\u5408\u540c\u5230\u671f\u65e5\u4e3a2016\u5e7412\u670818\u65e5\uff0c\u5408\u540c\u7ea6\u5b9a\u5728\u6700\u9ad8\u989d\u5ea6\u548c\u671f\u9650\u5185\uff0c\u501f\u6b3e\u4eba\u968f\u501f\u968f\u8fd8\uff0c\u81ea\u52a9\u653e\u6b3e\u8fd8\u6b3e\uff0c\u5355\u7b14\u501f\u6b3e\u671f\u9650\u6700\u957f\u4e0d\u8d85\u8fc7\u4e00\u5e74\u3002 \u5408\u540c\u671f\u9650\u5185\uff0c\u501f\u6b3e\u4eba\u9b4f\u5764\u5143\u4e8e2015\u5e7412\u670823\u65e5\u901a\u8fc7\u539f\u544a\u81ea\u52a9\u7535\u5b50\u6e20\u9053\u7533\u8bf7\u8d37\u6b3e\u4e00\u7b14\u3001\u91d1\u989d50000\u5143\uff0c\u5230\u671f\u65e5\u4e3a2016\u5e7411\u670822\u65e5\uff0c\u81f3\u4eca\u4ecd\u7ed3\u6b20\u539f\u544a\u8d37\u6b3e\u672c\u91d150000\u5143\u53ca827.95\u5143\uff08\u5229\u606f\u8ba1\u7b97\u81f32016\u5e7412\u670820\u65e5\u6b62\uff09\u3002 \u8be5\u7b14\u8d37\u6b3e\u5df2\u903e\u671f\uff0c\u4e3a\u6b64\uff0c\u539f\u544a\u8bc9\u81f3\u6cd5\u9662\uff0c\u8bf7\u6c42\u4f9d\u6cd5\u5224\u4ee4\uff1a1\u3001\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u5f52\u8fd8\u539f\u544a\u8d37\u6b3e\u672c\u91d150000\u5143\u53ca\u5229\u606f827.95\u5143\uff08\u5229\u606f\u8ba1\u7b97\u81f32016\u5e7412\u670820\u65e5\u6b62\uff09\uff0c\u4e4b\u540e\u7684\u5229\u606f\u6309\u5408\u540c\u7ea6\u5b9a\u7684\u7f5a\u606f\u5229\u7387\u8ba1\u7b97\uff1b 2\u3001\u672c\u6848\u8bc9\u8bbc\u8d39\u7528\u7531\u88ab\u544a\u627f\u62c5\u3002 \u88ab\u544a\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u672a\u4f5c\u7b54\u8fa9\u3002 \u88ab\u544a\u9b4f\u5764\u5143\u672a\u5230\u5ead\u7b54\u8fa9\uff0c\u5176\u5728\u672c\u9662\u7684\u300a\u8be2\u95ee\u7b14\u5f55\u300b\u4e2d\u8fa9\u79f0\uff0c\u5bf9\u539f\u544a\u8d77\u8bc9\u6ca1\u6709\u5f02\u8bae\uff0c\u786e\u5b9e\u662f\u548c\u88ab\u544a\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u7ec4\u6210\u8054\u4fdd\u5c0f\u7ec4\uff0c\u76f8\u4e92\u62c5\u4fdd\uff0c\u88ab\u544a\u9b4f\u78a7\u661f\u662f\u88ab\u544a\u9b4f\u5764\u5143\u7684\u513f\u5b50\uff0c\u88ab\u544a\u9b4f\u677e\u5170\u662f\u88ab\u544a\u9b4f\u5764\u5143\u7684\u5802\u5f1f\u3002 \u4e09\u88ab\u544a\u5404\u5411\u539f\u544a\u501f\u6b3e5\u4e07\u5143\uff0c\u62d6\u6b20\u4e86\u672c\u606f\u81f3\u4eca\u3002 \u7ecf\u5ba1\u7406\u67e5\u660e\uff0c2013\u5e7411\u670825\u65e5\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u4e09\u4eba\u7ec4\u6210\u8054\u4fdd\u5c0f\u7ec4\uff0c\u76f8\u4e92\u627f\u62c5\u8fde\u5e26\u4fdd\u8bc1\u8d23\u4efb\u5411\u539f\u544a\u519c\u884c\u5b89\u8fdc\u652f\u884c\u7533\u8bf7\u501f\u6b3e\u3002 \u4e09\u88ab\u544a\u7ec4\u6210\u8054\u4fdd\u5c0f\u7ec4\u540e\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u5411\u539f\u544a\u501f\u6b3e50000\u5143\uff0c\u5e76\u7b7e\u8ba2\u4e86\u300a\u519c\u6237\u8d37\u6b3e\u501f\u6b3e\u5408\u540c\u300b\uff08\u4ee5\u4e0b\u7b80\u79f0\u300a\u501f\u6b3e\u5408\u540c\u300b\uff09\uff0c\u5408\u540c\u5185\u5bb9\uff1a\u201c\u7b2c\u4e00\u6761\u501f\u6b3e\u91d1\u989d/\u53ef\u5faa\u73af\u501f\u6b3e\u989d\u5ea6\uff08\u4eba\u6c11\u5e01\u5927\u5199\uff09\uff1a\u4f0d\u4e07\u5143\u3002 \u7528\u6b3e\u65b9\u5f0f\uff1a\u81ea\u52a9\u53ef\u5faa\u73af\u65b9\u5f0f\u3002 \u81ea2013\u5e7412\u670819\u65e5\u8d77\u81f32016\u5e7412\u670818\u65e5\uff08\u989d\u5ea6\u6709\u6548\u671f\uff09\uff0c\u501f\u6b3e\u4eba\u53ef\u5728\u4f0d\u4e07\u5143\u7684\u53ef\u5faa\u73af\u501f\u6b3e\u989d\u5ea6\u5185\u5411\u8d37\u6b3e\u4eba\u7533\u8bf7\u501f\u6b3e\uff0c\u5355\u7b14\u501f\u6b3e\u671f\u9650\u6700\u957f\u4e0d\u8d85\u8fc7\u58f9\u5e74\u4e14\u5230\u671f\u65e5\u6700\u8fdf\u4e0d\u5f97\u8d85\u8fc7\u989d\u5ea6\u6709\u6548\u671f\u3002 \u501f\u6b3e\u7528\u9014\uff1a\u751f\u4ea7\u7ecf\u8425\u3002 \u7b2c\u4e8c\u6761\u672c\u5408\u540c\u9879\u4e0b\uff0c\u501f\u6b3e\u6267\u884c\u5229\u7387\u4ee5\u501f\u6b3e\u53d1\u653e\u5f53\u65e5\u4e2d\u56fd\u4eba\u6c11\u94f6\u884c\u540c\u671f\u540c\u6863\u6b21\u4eba\u6c11\u5e01\u8d37\u6b3e\u57fa\u51c6\u5229\u7387\u57fa\u7840\u4e0a\u6d6e30%\u786e\u5b9a\u3002 1\u5e74\u671f\u4ee5\u5185\uff08\u542b\uff09\u7684\u501f\u6b3e\u6267\u884c\u6d6e\u52a8\u5229\u7387\u3002 1\u5e74\u671f\u4ee5\u4e0a\u7684\u501f\u6b3e\u6267\u884c\u6d6e\u52a8\u5229\u7387\u3002 \u6d6e\u52a8\u5229\u7387\u6307\u5982\u9047\u4e2d\u56fd\u4eba\u6c11\u94f6\u884c\u4eba\u6c11\u5e01\u8d37\u6b3e\u57fa\u51c6\u5229\u7387\u8c03\u6574\uff0c\u81ea\u57fa\u51c6\u5229\u7387\u8c03\u6574\u4e4b\u65e5\u8d77\uff0c\u6309\u8c03\u6574\u540e\u76f8\u5e94\u671f\u9650\u6863\u6b21\u7684\u57fa\u51c6\u5229\u7387\u548c\u672c\u5408\u540c\u7ea6\u5b9a\u7684\u501f\u6b3e\u5229\u7387\u6d6e\u52a8\u5e45\u5ea6\u786e\u5b9a\u65b0\u7684\u501f\u6b3e\u6267\u884c\u5229\u7387\uff0c\u4e14\u4e0d\u518d\u53e6\u884c\u901a\u77e5\u501f\u6b3e\u4eba\u548c\u62c5\u4fdd\u4eba\u3002 \u7b2c\u4e94\u6761\u4fdd\u8bc1\u65b9\u5f0f\u4e3a\u8fde\u5e26\u8d23\u4efb\u4fdd\u8bc1\uff0c\u4fdd\u8bc1\u671f\u95f4\u4e3a\u501f\u6b3e\u671f\u9650\u5c4a\u6ee1\u4e4b\u65e5\u8d77\u4e8c\u5e74\u3002 \u7b2c\u516d\u6761\u501f\u6b3e\u4eba\u672a\u6309\u7ea6\u5b9a\u671f\u9650\u5f52\u8fd8\u501f\u6b3e\u672c\u91d1\uff0c\u8d37\u6b3e\u4eba\u5bf9\u903e\u671f\u501f\u6b3e\u4ece\u903e\u671f\u4e4b\u65e5\u8d77\u5728\u501f\u6b3e\u6267\u884c\u5229\u7387\u57fa\u7840\u4e0a\u4e0a\u6d6e\u767e\u5206\u4e4b\u4f0d\u62fe\u8ba1\u6536\u7f5a\u606f\uff0c\u76f4\u81f3\u672c\u606f\u6e05\u507f\u4e3a\u6b62\u3002 \u2026\u2026\u201d \uff0c\u4e09\u88ab\u544a\u5747\u5728\u8be5\u300a\u501f\u6b3e\u5408\u540c\u300b\u4e0a\u7b7e\u540d\u637a\u5370\u3002 \u5408\u540c\u671f\u9650\u5185\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u4e8e2015\u5e7412\u670823\u65e5\u501f\u5230\u539f\u544a\u519c\u884c\u5b89\u8fdc\u652f\u884c\u53d1\u653e\u7684\u501f\u6b3e\u672c\u91d150000\u5143\uff0c\u501f\u6b3e\u51ed\u8bc1\u4e0a\u8f7d\u660e\u501f\u6b3e\u91d1\u989d\u4e3a\u4f0d\u4e07\u5143\u6574\uff0c\u6267\u884c\u5229\u7387\u4e3a5.655\uff05\uff0c\u903e\u671f\u5229\u7387\u4e3a8.4825%\uff0c\u501f\u6b3e\u65e5\u671f\u4e3a2015\u5e7412\u670823\u65e5\uff0c\u5230\u671f\u65e5\u671f\u4e3a2016\u5e7411\u670822\u65e5\u3002 \u88ab\u544a\u9b4f\u5764\u5143\u501f\u6b3e\u540e\uff0c\u7ecf\u539f\u544a\u591a\u6b21\u50ac\u6b3e\uff0c\u622a\u81f32017\u5e746\u670820\u65e5\uff0c\u4ecd\u62d6\u6b20\u539f\u544a\u501f\u6b3e\u672c\u91d150000\u5143\u53ca\u5229\u606f2993.36\u5143\u3002 \u4e0a\u8ff0\u4e8b\u5b9e\uff0c\u6709\u539f\u544a\u7684\u9648\u8ff0\uff0c\u539f\u544a\u63d0\u4ea4\u7684\u300a\u501f\u6b3e\u5408\u540c\u300b\u3001\u300a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u501f\u6b3e\u51ed\u8bc1\u300b\u3001\u300a\u8054\u5408\u4fdd\u8bc1\u62c5\u4fdd\u627f\u8bfa\u4e66\u300b\u3001\u300a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u519c\u6237\u5c0f\u989d\u8d37\u6b3e\u4e1a\u52a1\u7533\u8bf7\u8868\u300b\u3001\u300a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u519c\u6237\u5c0f\u989d\u8d37\u6b3e\u9762\u8c08\u8bb0\u5f55\u300b\u3001\u300a\u672c\u606f\u6e05\u5355\u300b\u7b49\u8bc1\u636e\u4e88\u4ee5\u8bc1\u5b9e\uff0c\u4e0a\u8ff0\u8bc1\u636e\u7ecf\u5ead\u5ba1\u5ba1\u67e5\uff0c\u80fd\u76f8\u4e92\u5370\u8bc1\uff0c\u672c\u9662\u4e88\u4ee5\u786e\u8ba4\u3002 \u672c\u9662\u8ba4\u4e3a\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u5411\u539f\u544a\u519c\u884c\u5b89\u8fdc\u652f\u884c\u501f\u6b3e\uff0c\u53cc\u65b9\u7b7e\u8ba2\u4e86\u501f\u6b3e\u5408\u540c\uff0c\u539f\u544a\u4e5f\u4f9d\u7ea6\u5411\u88ab\u544a\u9b4f\u5764\u5143\u53d1\u653e\u4e86\u501f\u6b3e\uff0c\u7531\u6b64\u5f62\u6210\u7684\u501f\u6b3e\u5408\u540c\u5173\u7cfb\u5408\u6cd5\u6709\u6548\uff0c\u53d7\u6cd5\u5f8b\u4fdd\u62a4\u3002 \u501f\u6b3e\u5230\u671f\u540e\uff0c\u88ab\u544a\u9b4f\u5764\u5143\u5e94\u6e05\u507f\u501f\u6b3e\u672c\u91d1\u5e76\u4f9d\u7ea6\u652f\u4ed8\u5229\u606f\uff0c\u4f46\u5176\u81f3\u4eca\u672a\u8fd8\u6e05\u501f\u6b3e\u672c\u91d1\u53ca\u76f8\u5e94\u5229\u606f\uff0c\u5176\u884c\u4e3a\u663e\u5c5e\u8fdd\u7ea6\u3002 \u7531\u4e8e\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u4e09\u4eba\u7ec4\u6210\u8054\u4fdd\u5c0f\u7ec4\uff0c\u4e09\u88ab\u544a\u4e2d\u4efb\u4e00\u4eba\u501f\u6b3e\u5747\u7531\u5176\u4ed6\u4e8c\u88ab\u544a\u63d0\u4f9b\u8fde\u5e26\u8d23\u4efb\u4fdd\u8bc1\uff0c\u5373\u4e09\u88ab\u544a\u76f8\u4e92\u627f\u62c5\u8fde\u5e26\u4fdd\u8bc1\u8d23\u4efb\u3002 \u56e0\u6b64\uff0c\u88ab\u544a\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u4e8c\u4eba\u5e94\u4e0e\u503a\u52a1\u4eba\u88ab\u544a\u9b4f\u5764\u5143\u627f\u62c5\u8fde\u5e26\u507f\u8fd8\u8d23\u4efb\uff0c\u4f9d\u7ea6\u507f\u8fd8\u539f\u544a\u501f\u6b3e\u672c\u91d1\u53ca\u76f8\u5e94\u5229\u606f\u3002 \u7efc\u4e0a\uff0c\u4f9d\u7167\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u5408\u540c\u6cd5\u300b\u7b2c\u4e00\u767e\u96f6\u4e03\u6761\u3001\u7b2c\u4e8c\u767e\u96f6\u56db\u6761\u3001\u7b2c\u4e8c\u767e\u96f6\u4e94\u6761\u3001\u7b2c\u4e8c\u767e\u96f6\u4e03\u6761\uff0c\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u62c5\u4fdd\u6cd5\u300b\u7b2c\u5341\u4e8c\u6761\u3001\u7b2c\u5341\u516b\u6761\u3001\u7b2c\u4e8c\u5341\u4e00\u6761\uff0c\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u6c11\u4e8b\u8bc9\u8bbc\u6cd5\u300b\u7b2c\u4e00\u767e\u56db\u5341\u56db\u6761\u4e4b\u89c4\u5b9a\uff0c\u5224\u51b3\u5982\u4e0b\uff1a\u4e00\u3001\u88ab\u544a\u9b4f\u5764\u5143\u4e8e\u672c\u5224\u51b3\u751f\u6548\u540e\u4e09\u5341\u65e5\u5185\u507f\u8fd8\u539f\u544a\u4e2d\u56fd\u519c\u4e1a\u94f6\u884c\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5b89\u8fdc\u53bf\u652f\u884c\u501f\u6b3e\u672c\u91d150000\u5143\u53ca\u5229\u606f\uff08\u622a\u81f32017\u5e746\u670820\u65e5\u7684\u5229\u606f\u4e3a2993.36\u5143\uff0c2017\u5e746\u670820\u65e5\u4e4b\u540e\u7684\u5229\u606f\u6309\u7167\u5408\u540c\u7ea6\u5b9a\u7684\u7f5a\u606f\u5229\u7387\u8ba1\u7b97\uff09\u3002 \u4e8c\u3001\u88ab\u544a\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u5bf9\u4e0a\u8ff0\u6b3e\u9879\u627f\u62c5\u8fde\u5e26\u507f\u8fd8\u8d23\u4efb\u3002 \u5982\u679c\u672a\u6309\u672c\u5224\u51b3\u6307\u5b9a\u7684\u671f\u95f4\u5c65\u884c\u7ed9\u4ed8\u91d1\u94b1\u4e49\u52a1\uff0c\u5e94\u5f53\u4f9d\u7167\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u6c11\u4e8b\u8bc9\u8bbc\u6cd5\u300b\u7b2c\u4e8c\u767e\u4e94\u5341\u4e09\u6761\u4e4b\u89c4\u5b9a\uff0c\u52a0\u500d\u652f\u4ed8\u8fdf\u5ef6\u5c65\u884c\u671f\u95f4\u7684\u503a\u52a1\u5229\u606f\u3002 \u6848\u4ef6\u53d7\u7406\u8d391070\u5143\uff0c\u51cf\u534a\u6536\u53d6535\u5143\uff0c\u7531\u88ab\u544a\u9b4f\u5764\u5143\u3001\u9b4f\u677e\u5170\u3001\u9b4f\u78a7\u661f\u5171\u540c\u8d1f\u62c5\u3002 \u5982\u4e0d\u670d\u672c\u5224\u51b3\uff0c\u53ef\u5728\u5224\u51b3\u4e66\u9001\u8fbe\u4e4b\u65e5\u8d77\u5341\u4e94\u65e5\u5185\uff0c\u5411\u672c\u9662\u9012\u4ea4\u4e0a\u8bc9\u72b6\uff0c\u5e76\u6309\u5bf9\u65b9\u5f53\u4e8b\u4eba\u7684\u4eba\u6570\u63d0\u51fa\u526f\u672c\uff08\u5728\u9012\u4ea4\u4e0a\u8bc9\u72b6\u4e4b\u65e5\u8d77\u4e03\u65e5\u5185\u9884\u4ea4\u4e0a\u8bc9\u8d39\uff0c\u7f34\u4ea4\u4e0a\u8bc9\u8d39\u8d26\u53f7\uff1a99\u00d7\u00d7\u00d788\uff0c\u5f00\u6237\u884c\uff1a\u62db\u5546\u94f6\u884c\u8d63\u5dde\u957f\u5f81\u5927\u9053\u652f\u884c\uff0c\u6237\u540d\uff1a\u6c5f\u897f\u7701\u8d63\u5dde\u5e02\u4e2d\u7ea7\u4eba\u6c11\u6cd5\u9662\uff0c\u5907\u6ce8\u680f\u6ce8\u660e\u4e0a\u8bc9\u8d39\uff09\uff0c\u4e0a\u8bc9\u4e8e\u6c5f\u897f\u7701\u8d63\u5dde\u5e02\u4e2d\u7ea7\u4eba\u6c11\u6cd5\u9662\u3002 \uff08\u6cd5\u5f8b\u6587\u4e66\u751f\u6548\u540e\uff0c\u4e00\u65b9\u62d2\u7edd\u5c65\u884c\u7684\uff0c\u5bf9\u65b9\u5f53\u4e8b\u4eba\u5411\u672c\u9662\u7533\u8bf7\u6267\u884c\u7684\u671f\u9650\u662f\u4ece\u5224\u51b3\u4e66\u89c4\u5b9a\u7684\u5c65\u884c\u671f\u9650\u5c4a\u6ee1\u4e8c\u5e74\u5185\uff09\u5ba1\u5224\u5458\u3000\u3000\u5f90\u6d77\u5cf0 \u4e8c\u3007\u4e00\u4e03\u5e74\u4e5d\u6708\u5341\u4e00\u65e5 \u4e66\u8bb0\u5458\u3000\u3000\u674e\u9b41\u9e4f\u201d } HTTP response { \u201cresult\u201d: \u201c[SEP] [CLS] \u539f \u88ab \u544a \u7cfb \u501f \u6b3e \u5408 \u540c \u7ea0 \u7eb7 \u3002 \u539f \u544a \u63d0 \u51fa \u8bc9 \u8bbc \u8bf7 \u6c42 \uff1a \u88ab \u544a \u507f \u8fd8 \u539f \u544a \u8d37 \u6b3e \u53ca \u5229 \u606f \u3001 \u7f5a \u606f \uff1b \u4fdd \u8bc1 \u4eba \u627f \u62c5 \u8fde \u5e26 \u6e05 \u507f \u8d23 \u4efb \u3002 \u88ab \u544a \u672a \u7b54 \u8fa9 \u3002 \u7ecf \u5ba1 \u67e5 \uff0c \u539f \u544a \u4e0e \u88ab \u544a \u7b7e \u8ba2 \u7684 \u519c \u6237 \u8d37 \u6b3e \u501f \u6b3e \u53ca \u62c5 \u4fdd \u5408 \u540c \u5408 \u6cd5 \u6709 \u6548 \uff0c \u88ab \u544a \u5e94 \u5f53 \u6309 \u7167 \u5408 \u540c \u7ea6 \u5b9a \u5c65 \u884c \u507f \u8fd8 \u501f \u6b3e \u4e49 \u52a1 \uff0c \u5426 \u5219 \u539f \u544a \u5bf9 \u88ab \u544a \u62b5 \u62bc \u7269 \u4eab \u6709 \u4f18 \u5148 \u53d7 \u507f \u6743 \u3002 \u7efc \u4e0a \uff0c \u4f9d \u7167 \u300a \u4e2d \u534e \u4eba \u6c11 \u5171 \u548c \u56fd \u5408 \u540c \u6cd5 \u300b \u7b2c \u516d \u5341 \u6761 \u7b2c \u4e00 \u6b3e \u3001 \u7b2c \u4e00 \u767e \u4e5d \u5341 \u516d \u6761 \u3001 \u7b2c \u4e8c \u767e \u96f6 \u4e94 \u6761 \u3001 \u4e8c \u767e \u4e00 \u5341 \u4e00 \u6761 \u3001 \u300a \u62c5 \u4fdd \u6cd5 \u300b \u53ca \u300a \u6700 \u9ad8 \u4eba \u6c11 \u6cd5 \u9662 \u5173 \u4e8e \u9002 \u7528 \u82e5 \u5e72 \u95ee \u9898 \u7684 \u89e3 \u91ca \uff08 \u4e8c \uff09 \u300b \u7b2c \u4e8c \u5341 \u56db \u6761 \u53ca \u300a \u6c11 \u4e8b \u8bc9 \u8bbc \u6cd5 \u300b \u4e4b \u89c4 \u5b9a \uff0c \u5224 \u51b3 \u88ab \u544a \u7ed9 \u4ed8 \u539f \u544a \u519c \u6237 \u6700 \u9ad8 \u989d \u53ef \u5faa \u73af \u8d37 \u6b3e \u903e \u671f \u5229 \u606f \u53ca \u7f5a \u606f \u3002 [SEP]\u201d }","title":"CPT"},{"location":"developer/#gabsa","text":"Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment task uabsa The name of the task, selected from: [uabsa, aste, tasd, aope] dataset rest14 The name of the dataset, selected from: [laptop14, rest14, rest15, rest16] model_name_or_path t5-base Pretrained model name paradigm annotation The way to construct target sentence, selected from: [annotation, extraction] do_train True Whether to run training. do_eval False Whether to run eval on the dev/test set. do_batch_predict False Whether to run batch prediction. do_direct_eval False Whether to run direct eval on the dev/test set. do_direct_predict False Whether to run direct eval on the dev/test set. max_seq_length 128 Maximum sequence length train_batch_size 16 Batch train size eval_batch_size 16 Batch eval size gradient_accumulation_steps 1 Number of updates steps to accumulate before performing a backward/update pass. learning_rate 3e-4 Learning rate num_train_epochs 20 Number of train epochs seed 42 seed ckpoint_path /opt/ml/model/cktepoch=1.ckpt Checkpoint path weight_decay 0.0 Weight decay adam_epsilon 1e-8 Adam epsilon warmup_steps 0.0 Warmup steps Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train dataset Content format of train/validation/test file - Each row contains origin string####[(word, aspect, sentiment),\u2026], for example: The wine list is interesting and has many good values .####[('wine list', 'drinks style_options', 'positive'), ('wine list', 'drinks prices', 'positive')] Quickstart - deploy Environment variables Environment variable Default value Comment input_max_length 512 Maximum effective input length output_max_length 512 Maximum effective output length top_p 0.95 Top probability of output summary Quickstart - inference HTTP request { \"inputs\": \"The wine list is wonderful and the food reminds me of my recent trip to Italy .\" } HTTP response { \"result\": \"(wine list, drinks style_options, positive); (food, food quality, positive)\" }","title":"GABSA"},{"location":"developer/#paddlenlp","text":"Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment batch_size 16 Batch size learning_rate 1e-5 Learning rate train_path /opt/ml/input/data/dataset/train.txt Path of train file dev_path /opt/ml/input/data/dataset/dev.txt Path of dev file max_seq_len 512 Maximum sequence length num_epochs 100 Number of epochs seed 1000 seed logging_steps 10 Number of logging steps valid_steps 100 Number of validation steps device gpu CPU or GPU model uie-base Pretrained model name Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train dataset Content format of train/validation/test file - Each row contains json string with content, result_list, and prompt, for example: { \"content\": \"5\u67089\u65e5\u4ea4\u901a\u8d3929\u5143\u4ece\u5317\u82d1\u5230\u671b\u4eac\u641c\u540e\", \"result_list\": [{\"text\": \"5\u67089\u65e5\", \"start\": 0, \"end\": 4}], \"prompt\": \"\u65f6\u95f4\" } Quickstart - deploy Environment variables Environment variable Default value Comment device cpu CPU or GPU schema Schema to inference Quickstart - inference HTTP request { \"inputs\":\"\u4e0a\u6d77\u8679\u6865\u9ad8\u94c1\u5230\u676d\u5dde\u65f6\u95f4\u662f9\u670824\u65e5\u8d39\u7528\u662f73\u5143\" } HTTP response { \"result\": [ { \"\u51fa\u53d1\u5730\": [ { \"text\": \"\u4e0a\u6d77\", \"start\": 0, \"end\": 2, \"probability\": \"0.99601215\" } ], \"\u76ee\u7684\u5730\": [ { \"text\": \"\u676d\u5dde\", \"start\": 7, \"end\": 9, \"probability\": \"0.99965054\" } ], \"\u8d39\u7528\": [ { \"text\": \"73\u5143\", \"start\": 20, \"end\": 23, \"probability\": \"0.79425305\" } ], \"\u65f6\u95f4\": [ { \"text\": \"9\u670824\u65e5\", \"start\": 12, \"end\": 17, \"probability\": \"0.9998573\" } ] } ] }","title":"PaddleNLP"},{"location":"developer/#deberta","text":"Create industrial model Model extra information {} Quickstart - deploy Quickstart - inference HTTP request { \"inputs\": \"\u5982\u4f55\u6709\u6548\u5b66\u4e60\uff1f\", \"parameters\": { \"candidate_labels\": [ \"\u6c11\u751f\", \"\u6587\u5316\", \"\u5a31\u4e50\", \"\u4f53\u80b2\", \"\u8d22\u7ecf\", \"\u623f\u4ea7\", \"\u6c7d\u8f66\", \"\u6559\u80b2\", \"\u79d1\u6280\", \"\u519b\u4e8b\", \"\u65c5\u6e38\", \"\u56fd\u9645\", \"\u8bc1\u5238\", \"\u519c\u4e1a\", \"\u7535\u7ade\" ] } } HTTP response { \"sequence\": \"\u5982\u4f55\u6709\u6548\u5b66\u4e60\uff1f\", \"labels\": [ \"\u6559\u80b2\", \"\u6587\u5316\", \"\u79d1\u6280\", \"\u6c11\u751f\", \"\u56fd\u9645\", \"\u6c7d\u8f66\", \"\u519b\u4e8b\", \"\u7535\u7ade\", \"\u8bc1\u5238\", \"\u8d22\u7ecf\", \"\u519c\u4e1a\", \"\u4f53\u80b2\", \"\u623f\u4ea7\", \"\u5a31\u4e50\", \"\u65c5\u6e38\" ], \"scores\": [ 0.7116793990135193, 0.03544081375002861, 0.0295342355966568, 0.028479689732193947, 0.024489011615514755, 0.023759257048368454, 0.023078029975295067, 0.017534229904413223, 0.01741044595837593, 0.017365973442792892, 0.01681639440357685, 0.01475503295660019, 0.013634421862661839, 0.013062535785138607, 0.012960496358573437 ] }","title":"DeBERTa"},{"location":"developer/#keybert","text":"Create industrial model Model extra information {} Quickstart - deploy Environment variables Environment variable Default value Comment type default One of [sentence-transformer, huggingface-transformer, flair, spacy, universal-sentence-encoder, gensim, default] model - paraphrase-multilingual-MiniLM-L12-v2 when type is sentence-transformer - en_core_web_trf when type is Spacy - https://tfhub.dev/google/universal-sentence-encoder/4 when type is universal-sentence-encoder - fasttext-wiki-news-subwords-300 when type is gensim Model name huggingface_pipeline feature-extraction when type is huggingface-transformer HuggingFace pipeline mode - doc-embedding when type is flair - transformer when type is spacy - Use document embeddeding model or word embedding model when type is flair - Use non-transformer, transformer, transformer without GPU when type is spacy doc_embedding roberta-base when type is flair Document embedding word_embedding crawl when type is flair Word embedding keyphrase_ngram_start 1 Minimum length in words of generated keywords/keyphrases keyphrase_ngram_end 1 Maximum length in words of generated keywords/keyphrases stop_words english Stopwords to remove from the document top_n 5 Return the top n keywords/keyphrases min_df 1 Minimum document frequency of a word across all documents use_maxsum False Whether to use Max Sum Distance for the selection of keywords/keyphrases use_mmr False Whether to use Maximal Marginal Relevance (MMR) for the selection of keywords/keyphrases diversity 0.5 The diversity of the results between 0 and 1 if use_mmr is set to True nr_candidates 20 The number of candidates to consider if use_maxsum is set to True highlight False Whether to print the document and highlight its keywords/keyphrases Quickstart - inference HTTP request { \"inputs\": \"\u8fd1\u5e74\u6765,\u5d4c\u5165\u5f0f\u6280\u672f\u4e0e\u65e0\u7ebf\u7f51\u7edc\u6280\u672f\u6df1\u5ea6\u7ed3\u5408,\u50ac\u751f\u4e86\u53ef\u8ba1\u7b97RFID\u3001\u5d4c\u5165\u5f0f\u4f20\u611f\u7f51\u7b49\u65b0\u5174\u9886\u57df.\u8fd9\u4e9b\u7cfb\u7edf\u7531\u5927\u91cf\u5ec9\u4ef7\u7684\u8282\u70b9\u7ec4\u6210,\u5e94\u7528\u524d\u666f\u5e7f\u6cdb.\u5728\u4f20\u7edf\u8bbe\u8ba1\u4e2d,\u8fd9\u4e9b\u7cfb\u7edf\u901a\u5e38\u662f\u6839\u636e\u5e94\u7528\u5b9a\u5236\u7684.\u6839\u636e\u5e94\u7528\u5b9a\u5236\u7684\u7cfb\u7edf\u5177\u6709\u5f00\u53d1\u7b80\u4fbf\u3001\u8fd0\u884c\u9ad8\u6548\u7b49\u4f18\u70b9,\u4f46\u4e0d\u9002\u5408\u672a\u6765\u5927\u89c4\u6a21\u90e8\u7f72.\u8fd9\u662f\u56e0\u4e3a\u5982\u679c\u8fd9\u4e9b\u7cfb\u7edf\u8ddf\u5e94\u7528\u5bc6\u5207\u7ed1\u5b9a\u3001\u96be\u4ee5\u66f4\u65b0,\u90a3\u4e48\u7cfb\u7edf\u4e00\u7ecf\u90e8\u7f72\u5c31\u96be\u4ee5\u66f4\u65b0\u5176\u8f6f\u4ef6,\u4ece\u800c\u963b\u788d\u4e86\u8f6f\u4ef6\u521b\u65b0\u7684\u8fdb\u7a0b.\u8f6f\u4ef6\u5b9a\u4e49\u7684\u601d\u60f3\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u8be5\u95ee\u9898.\u5f53\u524d,\u8f6f\u4ef6\u5b9a\u4e49\u7f51\u7edc\u6210\u4e3a\u8ba1\u7b97\u673a\u7f51\u7edc\u4e2d\u4e00\u4e2a\u70ed\u95e8\u7684\u7814\u7a76\u9886\u57df.\u4f20\u611f\u5668\u7f51\u7edc\u7684\u8f6f\u4ef6\u8bbe\u8ba1\u4e0e\u56e0\u7279\u7f51\u7684\u8f6f\u4ef6\u8bbe\u8ba1\u5b58\u5728\u8bf8\u591a\u5dee\u5f02,\u5176\u6700\u5927\u7684\u5dee\u5f02\u5728\u4e8e,\u4f20\u611f\u5668\u7f51\u7edc\u4e3b\u8981\u4ee5\u4fe1\u606f\u7684\u91c7\u96c6\u4e3a\u6838\u5fc3,\u800c\u56e0\u7279\u7f51\u4e3b\u8981\u4ee5\u4fe1\u606f\u7684\u4f20\u8f93\u4e3a\u6838\u5fc3.\u6b64\u5916,\u4f20\u611f\u5668\u8282\u70b9\u8fd8\u5177\u6709\u4f53\u79ef\u5c0f\u3001\u7535\u6c60\u7eed\u822a\u80fd\u529b\u6709\u9650\u3001\u4ef7\u683c\u4f4e\u5ec9\u7b49\u7279\u70b9.\u6587\u4e2d\u4e3b\u8981\u8c03\u7814\u4e86\u8bbe\u8ba1\u8f6f\u4ef6\u5b9a\u4e49\u4f20\u611f\u5668\u7f51\u7edc(Software-DefinedSensorNetworks,SDSNs)\u67b6\u6784\u7684\u76f8\u5173\u5de5\u4f5c,\u5217\u4e3e\u4e86\u5728\u8bbe\u8ba1\u4e00\u4e2a\u901a\u7528\u3001\u9ad8\u6548\u7684\u8f6f\u4ef6\u5b9a\u4e49\u4f20\u611f\u5668\u7f51\u7edc\u67b6\u6784\u65f6\u53ef\u80fd\u9047\u5230\u7684\u6311\u6218,\u5e76\u56de\u987e\u4e86\u4e00\u4e9b\u6709\u7528\u7684\u6280\u672f.\u8fd9\u4e9b\u6280\u672f\u6709\u7684\u6765\u81ea\u4e8e\u73b0\u6709\u65b9\u6848,\u6709\u7684\u80fd\u591f\u76f4\u63a5\u88ab\u7528\u6765\u89e3\u51b3\u4e00\u90e8\u5206\u6311\u6218.\u6b64\u5916,\u6587\u4e2d\u8fd8\u4ece\u8f6f\u4ef6\u5b9a\u4e49\u529f\u80fd\u7684\u89d2\u5ea6,\u8fdb\u4e00\u6b65\u5730\u5bf9\u76ee\u524d\u901a\u7528\u3001\u9ad8\u6548\u7684\u8f6f\u4ef6\u5b9a\u4e49\u4f20\u611f\u5668\u7f51\u7edc\u67b6\u6784\u53ca\u5176\u91c7\u7528\u7684\u6280\u672f\u8fdb\u884c\u4e86\u5206\u7c7b.\u6211\u4eec\u8ba4\u4e3a,\u8f6f\u4ef6\u5b9a\u4e49\u4f20\u611f\u5668\u7f51\u7edc\u67b6\u6784\u5c06\u5728\u5df2\u90e8\u7f72\u7684\u7f51\u7edc\u4e2d\u8d77\u5230\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528,\u5e76\u5e26\u6765\u4e00\u573a\u65b0\u7684\u6280\u672f\u53d8\u9769.\" } HTTP response { \"result\": [ [ \"\u65e0\u7ebf\u7f51\u7edc\", 0.6223 ], [ \"\u8ba1\u7b97\u673a\u7f51\u7edc\", 0.447 ], [ \"definedsensornetworks\", 0.4356 ], [ \"\u6280\u672f\", 0.4297 ], [ \"\u56e0\u7279\u7f51\", 0.4001 ] ] }","title":"KeyBert"},{"location":"developer/#gluonts","text":"Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment algo-name DeepAR Algorithm name model-dir 8 /opt/ml/model output-dir 20 /opt/ml/output train 0.001 /opt/ml/input/data/dataset test 0.9 /opt/ml/input/data/dataset freq 1D frequence prediction-length 2*14 Prediction length context-length 20*14 Context length batch-size 2048 Batch size epochs 100 Number of epochs num-batches-per-epoc 2 Number of batches per epochs learning-rate 0.001 Learning rate learning-rate-decay-factor 0.5 Learning rate decay factor patience 10 Patience minimum-learning-rate 5e-5 Minimum learning rate clip-gradient 10 Clip gradient weight-decay 1e-8 Weight decay init xavier hybridize False use-feat-dynamic-real False use-feat-static-cat False use-past-feat-dynamic-real False cardinality use-log1p False Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train data Quickstart - deploy Environment variables Environment variable Default value Comment freq 1H target_quantile 0.5 use_log1p False Quickstart - inference HTTP request { \"inputs\": [ { \"target\": [ 12,28,12,0,56,12,8,12,28,4,24,8,12,4,4,8,16,4,24,12,16,16,4,24,12,12,16,24,8,16,12,40,12,32,24,8,8,8,20,20,32,20,16,16,8,24,32,12,16,4,4,28,12,24,20,12,44,32,36,20,24,28,40,84,52,20,20,64,36,44,28,24,32,12,44,72,50,15,35,80,75,24,60,42,12,18,60,54,72,49,72,88,24,88,90,33,22,9,54,88,117,136,99,80,50,110,88,44,44,36,63,72,108,63,60,55,66,33,120,55,12,100,80,117,72,135,55,77,120,66,121,132,72,0,60,77,50,136,40,88,99,77,275,168,26,80,110,130,140,130,187,110,204,220,144,204,60,36,156,220,154,279,297,374,132,192,182,266,140,156,247,228,360,270,209,104,247,364,420,255,240,225,300,338,352,429,273,336,270,390,570,544,765,208,336,405,434,364,416,256,368,493,408,666,1216,221,391,289,812,588,544,320,351,300,660,754,600,432,481,504,650,486,516,480,540,442,572,465,576,130,546,598,640,682,546,546,728,630,616,960,527,585,570,630,825,852,690,770,480,608,1072,1224,720,629,850,1037,988,767,935,900,1110,901,1560,2091,1008,833,1602,1785,1470,1365,1258,1152,1380,1332,2412,2320,1196,1350,1178,1136,117,363,846,595,1488,1691,2508,2992,725,1386,1701,1638,1548,1216,1360,1122,2180,1638,2814,2925,1363,902,1175,1320,1140,1292,1128,1134,1738 ], \"start\": \"1980-01-01 00:00:00\", \"item_id\": \"T234\", \"freq\": \"1M\", \"prediction_length\": 24 }, { \"target\": [ 12,28,12,0,56,12,8,12,28,4,24,8,12,4,4,8,16,4,24,12,16,16,4,24,12,12,16,24,8,16,12,40,12,32,24,8,8,8,20,20,32,20,16,16,8,24,32,12,16,4,4,28,12,24,20,12,44,32,36,20,24,28,40,84,52,20,20,64,36,44,28,24,32,12,44,72,50,15,35,80,75,24,60,42,12,18,60,54,72,49,72,88,24,88,90,33,22,9,54,88,117,136,99,80,50,110,88,44,44,36,63,72,108,63,60,55,66,33,120,55,12,100,80,117,72,135,55,77,120,66,121,132,72,0,60,77,50,136,40,88,99,77,275,168,26,80,110,130,140,130,187,110,204,220,144,204,60,36,156,220,154,279,297,374,132,192,182,266,140,156,247,228,360,270,209,104,247,364,420,255,240,225,300,338,352,429,273,336,270,390,570,544,765,208,336,405,434,364,416,256,368,493,408,666,1216,221,391,289,812,588,544,320,351,300,660,754,600,432,481,504,650,486,516,480,540,442,572,465,576,130,546,598,640,682,546,546,728,630,616,960,527,585,570,630,825,852,690,770,480,608,1072,1224,720,629,850,1037,988,767,935,900,1110,901,1560,2091,1008,833,1602,1785,1470,1365,1258,1152,1380,1332,2412,2320,1196,1350,1178,1136,117,363,846,595,1488,1691,2508,2992,725,1386,1701,1638,1548,1216,1360,1122,2180,1638,2814,2925,1363,902,1175,1320,1140,1292,1128,1134,1738,1564,3427,3325,1482,1584,1449,2222,1836,1332,1584,1680,1869,2002,3190,2652,1568,966,1380,1794,1350,1577,1104,1188,1495 ], \"start\":\"1980-01-01 00:00:00\", \"item_id\": \"T234\", \"freq\": \"1M\", \"prediction_length\": 24 } ] } HTTP response { \"result\": [ [ 1930.8326416015625, 2290.176025390625, 2243.770263671875, 1112.35888671875, 1216.8353271484375, 1300.52587890625, 1319.37451171875, 1104.0013427734375, 1231.51611328125, 1281.2568359375, 1306.0784912109375, 1798.2593994140625, 1773.2158203125, 2148.71142578125, 2055.391357421875, 1097.5042724609375, 1143.5330810546875, 1365.8883056640625, 1335.6077880859375, 1208.5709228515625, 1230.0604248046875, 1293.724853515625, 1298.18798828125, 1691.08056640625 ], [ 1820.448974609375, 2697.013916015625, 2449.663818359375, 1375.6854248046875, 1132.6513671875, 1368.69091796875, 1617.199951171875, 1349.854248046875, 1284.10986328125, 1291.0433349609375, 1288.84130859375, 1595.6607666015625, 1741.90185546875, 2308.14013671875, 2105.67529296875, 1253.835205078125, 1139.4034423828125, 1357.335205078125, 1589.59228515625, 1372.781982421875, 1298.3154296875, 1244.7462158203125, 1267.4632568359375, 1574.6981201171875 ] ] }","title":"GluonTS"},{"location":"developer/#stylegan","text":"Create industrial model Model extra information {} Quickstart - train Hyperparameters Hyperparameter Default value Comment gpus 1 Num of GPUS snap 50 Number of GPUs to use [default: 1] metrics fid50k_full Comma-separated list or \"none\" [default: fid50k_full] seed 0 Random seed data Training data (directory or zip) cond false Train conditional model based on dataset labels [default: false] subset all 'Train with only N images mirror false Enable dataset x-flips config auto Base config, one of 'auto', 'stylegan2', 'paper256', 'paper512', 'paper1024', 'cifar' gamma Override R1 gamma kimg Override training duration batch Override batch size aug ada Augmentation mode, one of 'noaug', 'ada', 'fixed' p Augmentation probability for --aug=fixed target ADA target value for --aug=ada augpipe bgc Augmentation pipeline resume noresume Resume training freezed 0 Freezed layers fp32 Disable mixed-precision training nhwc Use NHWC memory format with FP16 nobench Disable cuDNN benchmarking allow-tf32 Allow PyTorch to use TF32 internally workers Override number of DataLoader workers Input data configuration Channel name Mandatory Comment dataset Yes S3 URI of train data Quickstart - deploy Environment variables Environment variable Default value Comment network Pre-trianed network URL Quickstart - inference HTTP request { \"inputs\": { \"trunc\": \"0.7325021066422363\", \"seeds\": \"9,206,870,370\" } } HTTP response [ \"s3://sagemaker-ap-east-1-034068151705/stylegan/inference/outputseed0370.png\", \"s3://sagemaker-ap-east-1-034068151705/stylegan/inference/outputseed0009.png\", \"s3://sagemaker-ap-east-1-034068151705/stylegan/inference/outputseed0870.png\", \"s3://sagemaker-ap-east-1-034068151705/stylegan/inference/outputseed0206.png\" ]","title":"StyleGAN"},{"location":"developer/#yolov5paddleocr","text":"Create industrial model Model extra information {} Quickstart - inference","title":"Yolov5PaddleOCR"},{"location":"developer/#stable-diffusion-webui","text":"Create industrial model It will be created by default if you have started stable-diffusion-webui once. Alternative you can create it explicitly. Note industrial model of stable-diffusion-webui is unique within one all-in-one-ai app and with name 'stable-diffusion-webui' by design. Quickstart - train Basically we support 3 train approach instable-diffusion-webui: embedding, hypernetwork, and dreambooth which can be used to train person, object, style. Strongly recommend that you start the training job inside of stable-diffusion-webui since it is already supported with more friendely user interface. Alternative you start the training job explicitly. Hyperparameters Hyperparameter Default value Comment region Current region name AWS region name embeddings-s3uri s3://[sagemaker-default-bucket]/stable-diffusion-webui/embeddings/ S3 URI of embeddings, only applicable for embedding or hypernetwork training hypernetwork-s3uri s3://[sagemaker-default-bucket]/stable-diffusion-webui/hypernetwork/ S3 URI of hypernetwork, only applicable for embedding or hypernetwork training train-task embedding One of embedding, hypernetwork, dreambooth api-endpoint REST API Gateway of all-in-one-ai REST API Gateway db-models-s3uri s3://[sagemaker-default-bucket]/stable-diffusion-webui/dreambooth/ S3 URI of dreambooth model S3 URI, only applicable for dreambooth training sd-models-s3uri s3://[sagemaker-default-bucket]/stable-diffusion-webui/models/ stable diffusion models S3 URI, only applicable for dreambooth training train-args train-args which is up to train-task dreambooth-config-id dreambooth config id which is used to identify the dreambooth config in s3://[sagemaker-default-bucket]/stable-diffusion-webui/dreambooth-config/ train-args example for train dreambooth {\\\"train_dreambooth_settings\\\": {\\\"db_create_new_db_model\\\": true, \\\"db_new_model_name\\\": \\\"my-awsdogtoy-model-002\\\", \\\"db_new_model_src\\\": \\\"768-v-ema.ckpt\\\", \\\"db_new_model_scheduler\\\": \\\"ddim\\\", \\\"db_create_from_hub\\\": false, \\\"db_new_model_url\\\": \\\"\\\", \\\"db_new_model_token\\\": \\\"\\\", \\\"db_new_model_extract_ema\\\": false, \\\"db_model_name\\\": \\\"\\\", \\\"db_lora_model_name\\\": \\\"\\\", \\\"db_lora_weight\\\": 1, \\\"db_lora_txt_weight\\\": 1, \\\"db_train_imagic_only\\\": false, \\\"db_use_subdir\\\": false, \\\"db_custom_model_name\\\": \\\"\\\", \\\"db_train_wizard_person\\\": false, \\\"db_train_wizard_object\\\": true, \\\"db_performance_wizard\\\": true}} dreambooth-config example for train dreambooth \"\"\" model_name: str = \"\", adam_beta1: float = 0.9, adam_beta2: float = 0.999, adam_epsilon: float = 1e-8, adam_weight_decay: float = 0.01, attention: str = \"default\", center_crop: bool = True, concepts_path: str = \"\", custom_model_name: str = \"\", epoch_pause_frequency: int = 0, epoch_pause_time: int = 0, gradient_accumulation_steps: int = 1, gradient_checkpointing: bool = True, half_model: bool = False, has_ema: bool = False, hflip: bool = False, learning_rate: float = 0.00000172, lora_learning_rate: float = 1e-4, lora_txt_learning_rate: float = 5e-5, lr_scheduler: str = 'constant', lr_warmup_steps: int = 0, max_token_length: int = 75, max_train_steps: int = 1000, mixed_precision: str = \"fp16\", model_path: str = \"\", not_cache_latents=False, num_train_epochs: int = 1, pad_tokens: bool = True, pretrained_vae_name_or_path: str = \"\", prior_loss_weight: float = 1.0, resolution: int = 512, revision: int = 0, sample_batch_size: int = 1, save_class_txt: bool = False, save_embedding_every: int = 500, save_preview_every: int = 500, save_use_global_counts: bool = False, save_use_epochs: bool = False, scale_lr: bool = False, scheduler: str = \"ddim\", src: str = \"\", shuffle_tags: bool = False, train_batch_size: int = 1, train_text_encoder: bool = True, use_8bit_adam: bool = True, use_concepts: bool = False, use_cpu: bool = False, use_ema: bool = True, use_lora: bool = False, v2: bool = False, c1_class_data_dir: str = \"\", c1_class_guidance_scale: float = 7.5, c1_class_infer_steps: int = 60, c1_class_negative_prompt: str = \"\", c1_class_prompt: str = \"\", c1_class_token: str = \"\", c1_instance_data_dir: str = \"\", c1_instance_prompt: str = \"\", c1_instance_token: str = \"\", c1_max_steps: int = -1, c1_n_save_sample: int = 1, c1_num_class_images: int = 0, c1_sample_seed: int = -1, c1_save_guidance_scale: float = 7.5, c1_save_infer_steps: int = 60, c1_save_sample_negative_prompt: str = \"\", c1_save_sample_prompt: str = \"\", c1_save_sample_template: str = \"\", c2_class_data_dir: str = \"\", c2_class_guidance_scale: float = 7.5, c2_class_infer_steps: int = 60, c2_class_negative_prompt: str = \"\", c2_class_prompt: str = \"\", c2_class_token: str = \"\", c2_instance_data_dir: str = \"\", c2_instance_prompt: str = \"\", c2_instance_token: str = \"\", c2_max_steps: int = -1, c2_n_save_sample: int = 1, c2_num_class_images: int = 0, c2_sample_seed: int = -1, c2_save_guidance_scale: float = 7.5, c2_save_infer_steps: int = 60, c2_save_sample_negative_prompt: str = \"\", c2_save_sample_prompt: str = \"\", c2_save_sample_template: str = \"\", c3_class_data_dir: str = \"\", c3_class_guidance_scale: float = 7.5, c3_class_infer_steps: int = 60, c3_class_negative_prompt: str = \"\", c3_class_prompt: str = \"\", c3_class_token: str = \"\", c3_instance_data_dir: str = \"\", c3_instance_prompt: str = \"\", c3_instance_token: str = \"\", c3_max_steps: int = -1, c3_n_save_sample: int = 1, c3_num_class_images: int = 0, c3_sample_seed: int = -1, c3_save_guidance_scale: float = 7.5, c3_save_infer_steps: int = 60, c3_save_sample_negative_prompt: str = \"\", c3_save_sample_prompt: str = \"\", c3_save_sample_template: str = \"\", concepts_list=None \"\"\" [ \"\", 0.9, 0.999, 1e-08, 0.01, \"default\", False, \"\", \"\", 0.0, 60.0, 1, True, False, \"\", True, 2e-06, 0.0002, 0.0002, \"constant\", 500, 75, 0, \"no\", \"\", True, 100, True, \"\", 1, 512, \"\", 1, True, 500, 500, True, False, False, \"\", \"\", False, 1, True, False, False, False, False, False, \"\", \"\", 7.5, 40, \"\", \"\", \"photo of dog\", \"/opt/ml/input/data/concepts/images\", \"\", \"photo of awsdogtoy dog\", -1, 1, 0, -1, 7.5, 40, \"\", \"\", \"\", \"\", 7.5, 40, \"\", \"\", \"\", \"\", \"\", \"\", -1, 1, 0, -1, 7.5, 40, \"\", \"\", \"\", \"\", 7.5, 40, \"\", \"\", \"\", \"\", \"\", \"\", -1, 1, 0, -1, 7.5, 40, \"\", \"\", \"\" ] Input data configuration Channel name Mandatory Comment images Yes S3 URI of images models No S3 URI of stable diffusion models embedding No S3 URI of embeddings hypernetwork No S3 URI of hypernetwork lora No S3 URI of lora models dreambooth No S3 URI of dreambooth models Quickstart - deploy Environment variables Environment variable Default value Comment api_endpoint REST API Gateway of all-in-one-ai REST API Gateway endpoint_name Name of SageMaker Endpoint which is be used to host stable diffusion models and generate images Setup stable-diffusion-webui Signin or Signup Choose user tab and then signin or signup firstly. Note you won't be able to perform any GPU related actions unless you are logined via either signin or signup. Configure your SageMaker endpoint and your stable diffusion models Select your SageMaker endpoint firstly from dropdown list of avaiable SageMaker endpoints list. You may refresh the available SageMaker endpoints list by clicking refresh button right after SageMaker endpoints dropdown list. Then refresh stable diffusion models by clicking refresh button right after stable diffusion models and choose your stable diffusion model. Quickstart - Inference - Text to Image HTTP request payload = { 'enable_hr': False, 'denoising_strength': 0.7, 'firstphase_width': 0, 'firstphase_height': 0, 'prompt': \"dog\", 'styles': ['None', 'None'], 'seed': -1, 'subseed': -1, 'subseed_strength': 0.0, 'seed_resize_from_h': 0, 'seed_resize_from_w': 0, 'sampler_name': None, 'batch_size': 1, 'n_iter':1, 'steps': 20, 'cfg_scale': 7.0, 'width': 768, 'height': 768, 'restore_faces': False, 'tiling': False, 'negative_prompt': '', 'eta': 1.0, 's_churn': 0.0, 's_tmax': None, 's_tmin': 0.0, 's_noise': 1.0, 'override_settings': {}, 'script_args': '[0, false, false, false, \"\", 1, \"\", 0, \"\", true, false, false]', 'sampler_index': 'Euler a' } inputs = { 'task': 'text-to-image', 'txt2img_payload': payload, 'username': 'e' } HTTP response { \"images\" : [ [base64 encoded images], ..., [base64 encoded images] ] } Quickstart - Inference - Image to Image HTTP request payload = { 'init_images': [image_encoded_in_base64], 'resize_mode': 0, 'denoising_strength': 0.75, 'mask': None, 'mask_blur': 4, 'inpainting_fill': 1, 'inpaint_full_res': False, 'inpaint_full_res_padding': 32, 'inpainting_mask_invert': 0, 'prompt': 'cat', 'styles': ['None', 'None'], 'seed': -1, 'subseed': -1, 'subseed_strength': 0.0, 'seed_resize_from_h': 0, 'seed_resize_from_w': 0, 'sampler_name': None, 'batch_size': 1, 'n_iter': 1, 'steps': 20, 'cfg_scale': 7.0, 'width': 768, 'height': 768, 'restore_faces': False, 'tiling': False, 'negative_prompt': '', 'eta': 1.0, 's_churn': 0.0, 's_tmax': None, 's_tmin': 0.0, 's_noise': 1.0, 'override_settings': {}, 'script_args': '[0, \"<ul>\\\\n<li><code>CFG Scale</code> should be 2 or lower.</li>\\\\n</ul>\\\\n\", true, true, \"\", \"\", true, 50, true, 1, 0, false, 4, 1, \"<p style=\\\\\"margin-bottom:0.75em\\\\\">Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8</p>\", 128, 8, [\"left\", \"right\", \"up\", \"down\"], 1, 0.05, 128, 4, 0, [\"left\", \"right\", \"up\", \"down\"], false, false, false, \"\", \"<p style=\\\\\"margin-bottom:0.75em\\\\\">Will upscale the image to twice the dimensions; use width and height sliders to set tile size</p>\", 64, 0, 1, \"\", 0, \"\", true, false, false]', 'sampler_index': 'Euler a', 'include_init_images': False } inputs = { 'task': 'image-to-image', 'img2img_payload': payload, 'username': 'e' } HTTP response { \"images\" : [ [base64 encoded images], ..., [base64 encoded images] ] }","title":"stable-diffusion-webui"}]}