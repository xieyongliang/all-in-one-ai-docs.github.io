<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Stable diffusion webui - All-In-One AI Documentation</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Stable diffusion webui";
        var mkdocs_page_input_path = "stable-diffusion-webui.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> All-In-One AI Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">About All-In-One AI</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../builder/">Builder Guide</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../deployment/">Deployment Guide</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../developer/">Developer Guide</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">Stable diffusion webui</a>
    <ul class="current">
    </ul>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">All-In-One AI Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" alt="Docs"></a> &raquo;</li>
      <li>Stable diffusion webui</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 id="toolkits-to-be-prepared-prior-to-build-and-deploy">Toolkits to be prepared prior to build and deploy</h2>
<ul>
<li>git</li>
<li>awscli</li>
<li>zip</li>
<li>python3</li>
<li>pip3</li>
<li>docker</li>
<li>jq</li>
</ul>
<h2 id="build-stable-diffusion-webui-fully">Build stable-diffusion-webui (Fully)</h2>
<p>Change directory to [path-to-all-in-one-ai]/deployment and run the following commands to package python codes and build docker image for web portal and then upload assets to S3 and push docker image to ECR which region is the same AWS region as where CloudFormation stack. It will may take 15-30 minutes. Parameters s3uri and aws-region are mandatory while parameter algorithm is optional to specify which algorithm will be built-in and if it is not presented, all of algorithms will be built-in.</p>
<pre><code>cd [path-to-all-in-one-ai]/deployment

./build_and_deploy.sh [s3uri] [aws-region] stable-diffusion-webui
</code></pre>
<h2 id="build-stable-diffusion-webui-partially">Build stable-diffusion-webui (Partially)</h2>
<p>Go to sagemaker/stable-diffusion-webui and run the following command.</p>
<pre><code>cd [path-to-all-in-one-ai]/sagemaker/stable-diffusion-webui

run ./build_and_push.sh [region-name]
</code></pre>
<p>Note: It is a partial step of build_and_deploy.sh and it is only used to partially update stable-diffusion-webui or run Jupyter Notebooks of stable-diffusion-webui directly.</p>
<h2 id="deploy-stable-diffusion-webui">Deploy stable-diffusion-webui</h2>
<ol>
<li>
<p>Launch CloudFormation stack template by clicking <a href="https://console.aws.amazon.com/cloudformation/home?#/stacks/create/template"><img alt="Launch CloudFormation stack" src="../assets/images/launch.png" /></a> , and input Amazon S3 URL with HTTP URI of all-in-one-ai-webui-main.yaml.</p>
<p><img alt="stable-difffusion-webui CloudFormation step 1" src="../assets/images/stable-diffusion-webui-01.png" /></p>
</li>
<li>
<p>Specify stack details. Please select at least 2 availability zone, Certificate, DomainName, input S3 bucket/key information of your stack template, input CognitoRegion, UserPool, UserPoolClient, UserPoolDomain if Cognito authentication is enabled and customize other parameters if needed. Choose Next.</p>
<p><img alt="stable-difffusion-webui CloudFormation step 2" src="../assets/images/stable-diffusion-webui-02.png" /></p>
<p><img alt="stable-difffusion-webui CloudFormation step 2" src="../assets/images/stable-diffusion-webui-03.png" />    </p>
<p><img alt="stable-difffusion-webui CloudFormation step 3" src="../assets/images/stable-diffusion-webui-04.png" /></p>
</li>
<li>
<p>Configure stack options. Keep everything as default and choose Next.</p>
<p><img alt="stable-difffusion-webui CloudFormation step 3" src="../assets/images/stable-diffusion-webui-05.png" /></p>
<p><img alt="stable-difffusion-webui CloudFormation step 4" src="../assets/images/stable-diffusion-webui-06.png" /></p>
</li>
<li>
<p>Review stack all-in-one-ai. Check the 1 check boxes in the bottom. Choose Create Stack.</p>
<p><img alt="stable-difffusion-webui CloudFormation step 4" src="../assets/images/stable-diffusion-webui-07.png" /></p>
<p><img alt="stable-difffusion-webui CloudFormation step 5" src="../assets/images/stable-diffusion-webui-08.png" /></p>
<p><img alt="stable-difffusion-webui CloudFormation step 5" src="../assets/images/stable-diffusion-webui-09.png" /></p>
<p><img alt="stable-difffusion-webui CloudFormation step 5" src="../assets/images/stable-diffusion-webui-10.png" /></p>
<p><img alt="stable-difffusion-webui CloudFormation step 5" src="../assets/images/stable-diffusion-webui-11.png" /></p>
</li>
<li>
<p>Wait for around 15 minutes to get the stack launched and check the stack outpus.</p>
<p><img alt="stable-difffusion-webui CloudFormation step 5" src="../assets/images/stable-diffusion-webui-12.png" /></p>
</li>
</ol>
<h3 id="prepare-sd-models">Prepare SD models</h3>
<ul>
<li>
<p>SD v2.1</p>
<p><a href="https://huggingface.co/stabilityai/stable-diffusion-2-1/blob/main/v2-1_768-ema-pruned.ckpt">768-v-ema.ckpt</a></p>
<p><a href="https://github.com/Stability-AI/stablediffusion/blob/main/configs/stable-diffusion/v2-inference-v.yaml">stable-diffusion/v2-inference-v.yaml</a></p>
</li>
<li>
<p>SD v2.0</p>
<p><a href="https://huggingface.co/stabilityai/stable-diffusion-2/blob/main/768-v-ema.ckpt">768-v-ema.ckpt</a></p>
<p><a href="https://github.com/Stability-AI/stablediffusion/blob/main/configs/stable-diffusion/v2-inference-v.yaml">stable-diffusion/v2-inference-v.yaml</a></p>
</li>
<li>
<p>SD v1.5</p>
<p><a href="https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned-emaonly.ckpt">v1-5-pruned-emaonly.ckpt</a></p>
<p><a href="https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned.ckpt">v1-5-pruned.ckpt</a></p>
</li>
<li>
<p>SD v1.4</p>
<p><a href="https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/blob/main/sd-v1-4-full-ema.ckpt">sd-v1-4-full-ema.ckpt</a></p>
<p><a href="https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/blob/main/sd-v1-4.ckpt">sd-v1-4.ckpt</a></p>
</li>
</ul>
<p>You could pick up all your interested SD models and download them into one directory and then run </p>
<pre><code>python3 prepare.py [path-to-sd-models-directory]
</code></pre>
<p>This script will help to generate model.tar.gz and push s3://[sagemaker-default-bucket]/assets/, push the whole model directory to s3://[sagemaker-default-bucket]/models/.</p>
<p>For instance, the following diagram shows the contents at the model files at s3://[sagemaker-default-bucket]/models/.</p>
<p><img alt="stable-difffusion-webui models" src="../assets/images/stable-diffusion-webui-00.png" /></p>
<p>Note:</p>
<ul>
<li>
<p>For SD v2.0, please keep the filename consistent, e.g. 768-v-ema.ckpt and 768-v-ema.yaml.</p>
</li>
<li>
<p>Only English versions of SD 2.x and SD 1.x are supported. Chinese versions (e.g. Taiyi) are not supported yet.</p>
</li>
</ul>
<h2 id="launch-stable-diffusion-webui">Launch stable-diffusion-webui</h2>
<ul>
<li>Wait 10 minutes until the stable-diffusion-webui server pass the health check and then check the stack outputs of all-in-one-ai-webui and then launch the stable-diffusion-webui.</li>
</ul>
<p><img alt="stable-difffusion-webui" src="../assets/images/stable-diffusion-webui-13.png" /></p>
<h2 id="setup-stable-diffusion-webui">Setup stable-diffusion-webui</h2>
<ul>
<li>
<p>Signin or Signup</p>
<p>Choose user tab and then signin or signup firstly. Note you won't be able to perform any GPU related actions unless you are logined via either signin or signup.</p>
<p><img alt="Signin or Signup stable-diffusion-webui " src="../assets/images/stable_diffusion_webui_setup_user.png" />    </p>
</li>
<li>
<p>Configure your SageMaker endpoint and your stable diffusion models</p>
<p>Select your SageMaker endpoint firstly from dropdown list of avaiable SageMaker endpoints list. You may refresh the available SageMaker endpoints list by clicking refresh button right after SageMaker endpoints dropdown list. Then refresh stable diffusion models by clicking refresh button right after stable diffusion models and choose your stable diffusion model.</p>
<p><img alt="Setup stable-diffusion-webui " src="../assets/images/stable_diffusion_webui_setup_sagemaker_endpoint.png" /></p>
<p><img alt="Setup stable-diffusion-webui " src="../assets/images/stable_diffusion_webui_setup_sd_model.png" /></p>
</li>
</ul>
<h2 id="quickstart">Quickstart</h2>
<h3 id="create-industrial-model">Create industrial model</h3>
<p>It will be created by default if you have started stable-diffusion-webui once. Alternative you can create it explicitly. Note industrial model of stable-diffusion-webui is unique within one all-in-one-ai app and with name 'stable-diffusion-webui' by design.</p>
<p><img alt="Create industrial model based stable-diffusion-webui" src="../assets/images/industrial_model_stable_diffusion_webui.png" /></p>
<h3 id="quickstart-train">Quickstart - train</h3>
<p>Basically we support 3 train approach instable-diffusion-webui: embedding, hypernetwork, and dreambooth which can be used to train person, object, style.</p>
<p>Strongly recommend that you start the training job inside of stable-diffusion-webui since it is already supported with more friendely user interface. </p>
<p><img alt="Train inside of stable-diffusion-webui" src="../assets/images/quickstart_train_stable_diffusion_webui_dreambooth_1.png" /></p>
<p><img alt="Train inside of stable-diffusion-webui" src="../assets/images/quickstart_train_stable_diffusion_webui_dreambooth_2.png" /></p>
<p><img alt="Train inside of stable-diffusion-webui" src="../assets/images/quickstart_train_stable_diffusion_webui_dreambooth_3.png" /></p>
<p>Alternative you start the training job explicitly. </p>
<p><img alt="Train outside of stable-diffusion-webui" src="../assets/images/quickstart_train_stable_diffusion_webui.png" /></p>
<p><strong>Hyperparameters</strong></p>
<table>
<thead>
<tr>
<th>Hyperparameter</th>
<th>Default value</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>region</td>
<td>Current region name</td>
<td>AWS region name</td>
</tr>
<tr>
<td>embeddings-s3uri</td>
<td>s3://[sagemaker-default-bucket]/stable-diffusion-webui/embeddings/</td>
<td>S3 URI of embeddings, only applicable for embedding or hypernetwork training</td>
</tr>
<tr>
<td>hypernetwork-s3uri</td>
<td>s3://[sagemaker-default-bucket]/stable-diffusion-webui/hypernetwork/</td>
<td>S3 URI of hypernetwork, only applicable for embedding or hypernetwork training</td>
</tr>
<tr>
<td>train-task</td>
<td>embedding</td>
<td>One of embedding, hypernetwork, dreambooth</td>
</tr>
<tr>
<td>api-endpoint</td>
<td>REST API Gateway of all-in-one-ai</td>
<td>REST API Gateway</td>
</tr>
<tr>
<td>db-models-s3uri</td>
<td>s3://[sagemaker-default-bucket]/stable-diffusion-webui/dreambooth/</td>
<td>S3 URI of dreambooth model S3 URI, only applicable for dreambooth training</td>
</tr>
<tr>
<td>sd-models-s3uri</td>
<td>s3://[sagemaker-default-bucket]/stable-diffusion-webui/models/</td>
<td>stable diffusion models S3 URI, only applicable for dreambooth training</td>
</tr>
<tr>
<td>train-args</td>
<td>train-args which is up to train-task</td>
<td></td>
</tr>
<tr>
<td>dreambooth-config-id</td>
<td>dreambooth config id which is used to identify the dreambooth config in s3://[sagemaker-default-bucket]/stable-diffusion-webui/dreambooth-config/</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>train-args example for train dreambooth</strong></p>
<pre><code>{\"train_dreambooth_settings\": {\"db_create_new_db_model\": true, \"db_new_model_name\": \"my-awsdogtoy-model-002\", \"db_new_model_src\": \"768-v-ema.ckpt\", \"db_new_model_scheduler\": \"ddim\", \"db_create_from_hub\": false, \"db_new_model_url\": \"\", \"db_new_model_token\": \"\", \"db_new_model_extract_ema\": false, \"db_model_name\": \"\", \"db_lora_model_name\": \"\", \"db_lora_weight\": 1, \"db_lora_txt_weight\": 1, \"db_train_imagic_only\": false, \"db_use_subdir\": false, \"db_custom_model_name\": \"\", \"db_train_wizard_person\": false, \"db_train_wizard_object\": true, \"db_performance_wizard\": true}}
</code></pre>
<p><strong>dreambooth-config example for train dreambooth</strong></p>
<pre><code>"""
model_name: str = "",
adam_beta1: float = 0.9,
adam_beta2: float = 0.999,
adam_epsilon: float = 1e-8,
adam_weight_decay: float = 0.01,
attention: str = "default",
center_crop: bool = True,
concepts_path: str = "",
custom_model_name: str = "",
epoch_pause_frequency: int = 0,
epoch_pause_time: int = 0,
gradient_accumulation_steps: int = 1,
gradient_checkpointing: bool = True,
half_model: bool = False,
has_ema: bool = False,
hflip: bool = False,
learning_rate: float = 0.00000172,
lora_learning_rate: float = 1e-4,
lora_txt_learning_rate: float = 5e-5,
lr_scheduler: str = 'constant',
lr_warmup_steps: int = 0,
max_token_length: int = 75,
max_train_steps: int = 1000,
mixed_precision: str = "fp16",
model_path: str = "",
not_cache_latents=False,
num_train_epochs: int = 1,
pad_tokens: bool = True,
pretrained_vae_name_or_path: str = "",
prior_loss_weight: float = 1.0,
resolution: int = 512,
revision: int = 0,
sample_batch_size: int = 1,
save_class_txt: bool = False,
save_embedding_every: int = 500,
save_preview_every: int = 500,
save_use_global_counts: bool = False,
save_use_epochs: bool = False,
scale_lr: bool = False,
scheduler: str = "ddim",
src: str = "",
shuffle_tags: bool = False,
train_batch_size: int = 1,
train_text_encoder: bool = True,
use_8bit_adam: bool = True,
use_concepts: bool = False,
use_cpu: bool = False,
use_ema: bool = True,
use_lora: bool = False,
v2: bool = False,
c1_class_data_dir: str = "",
c1_class_guidance_scale: float = 7.5,
c1_class_infer_steps: int = 60,
c1_class_negative_prompt: str = "",
c1_class_prompt: str = "",
c1_class_token: str = "",
c1_instance_data_dir: str = "",
c1_instance_prompt: str = "",
c1_instance_token: str = "",
c1_max_steps: int = -1,
c1_n_save_sample: int = 1,
c1_num_class_images: int = 0,
c1_sample_seed: int = -1,
c1_save_guidance_scale: float = 7.5,
c1_save_infer_steps: int = 60,
c1_save_sample_negative_prompt: str = "",
c1_save_sample_prompt: str = "",
c1_save_sample_template: str = "",
c2_class_data_dir: str = "",
c2_class_guidance_scale: float = 7.5,
c2_class_infer_steps: int = 60,
c2_class_negative_prompt: str = "",
c2_class_prompt: str = "",
c2_class_token: str = "",
c2_instance_data_dir: str = "",
c2_instance_prompt: str = "",
c2_instance_token: str = "",
c2_max_steps: int = -1,
c2_n_save_sample: int = 1,
c2_num_class_images: int = 0,
c2_sample_seed: int = -1,
c2_save_guidance_scale: float = 7.5,
c2_save_infer_steps: int = 60,
c2_save_sample_negative_prompt: str = "",
c2_save_sample_prompt: str = "",
c2_save_sample_template: str = "",
c3_class_data_dir: str = "",
c3_class_guidance_scale: float = 7.5,
c3_class_infer_steps: int = 60,
c3_class_negative_prompt: str = "",
c3_class_prompt: str = "",
c3_class_token: str = "",
c3_instance_data_dir: str = "",
c3_instance_prompt: str = "",
c3_instance_token: str = "",
c3_max_steps: int = -1,
c3_n_save_sample: int = 1,
c3_num_class_images: int = 0,
c3_sample_seed: int = -1,
c3_save_guidance_scale: float = 7.5,
c3_save_infer_steps: int = 60,
c3_save_sample_negative_prompt: str = "",
c3_save_sample_prompt: str = "",
c3_save_sample_template: str = "",
concepts_list=None
"""

[
    "",
    0.9,
    0.999,
    1e-08,
    0.01,
    "default",
    False,
    "",
    "",
    0.0,
    60.0,
    1,
    True,
    False,
    "",
    True,
    2e-06,
    0.0002,
    0.0002,
    "constant",
    500,
    75,
    0,
    "no",
    "",
    True,
    100,
    True,
    "",
    1,
    512,
    "",
    1,
    True,
    500,
    500,
    True,
    False,
    False,
    "",
    "",
    False,
    1,
    True,
    False,
    False,
    False,
    False,
    False,
    "",
    "",
    7.5,
    40,
    "",
    "",
    "photo of dog",
    "/opt/ml/input/data/concepts/images",
    "",
    "photo of awsdogtoy dog",
    -1,
    1,
    0,
    -1,
    7.5,
    40,
    "",
    "",
    "",
    "",
    7.5,
    40,
    "",
    "",
    "",
    "",
    "",
    "",
    -1,
    1,
    0,
    -1,
    7.5,
    40,
    "",
    "",
    "",
    "",
    7.5,
    40,
    "",
    "",
    "",
    "",
    "",
    "",
    -1,
    1,
    0,
    -1,
    7.5,
    40,
    "",
    "",
    ""
]
</code></pre>
<p><strong>Input data configuration</strong></p>
<table>
<thead>
<tr>
<th>Channel name</th>
<th>Mandatory</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>images</td>
<td>Yes</td>
<td>S3 URI of images</td>
</tr>
<tr>
<td>models</td>
<td>No</td>
<td>S3 URI of stable diffusion models</td>
</tr>
<tr>
<td>embedding</td>
<td>No</td>
<td>S3 URI of embeddings</td>
</tr>
<tr>
<td>hypernetwork</td>
<td>No</td>
<td>S3 URI of hypernetwork</td>
</tr>
<tr>
<td>lora</td>
<td>No</td>
<td>S3 URI of lora models</td>
</tr>
<tr>
<td>dreambooth</td>
<td>No</td>
<td>S3 URI of dreambooth models</td>
</tr>
</tbody>
</table>
<h3 id="quickstart-deploy">Quickstart - deploy</h3>
<p><img alt="Quickstart deploy - stable-diffusion-webui" src="../assets/images/quickstart_deploy_stable_diffusion_webui.png" /></p>
<p><strong>Environment variables</strong></p>
<table>
<thead>
<tr>
<th>Environment variable</th>
<th>Default value</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>api_endpoint</td>
<td>REST API Gateway of all-in-one-ai</td>
<td>REST API Gateway</td>
</tr>
<tr>
<td>endpoint_name</td>
<td></td>
<td>Name of SageMaker Endpoint which is be used to host stable diffusion models and generate images</td>
</tr>
</tbody>
</table>
<p><img alt="Deploy stable-diffusion-webui" src="../assets/images/quickstart_deploy_stable_diffusion_webui.png" /></p>
<h3 id="quickstart-inference-text-to-image">Quickstart - Inference - Text to Image</h3>
<p><strong>HTTP request</strong></p>
<pre><code>payload = {
    'enable_hr': False, 
    'denoising_strength': 0.7, 
    'firstphase_width': 0, 
    'firstphase_height': 0, 
    'prompt': "dog", 
    'styles': ['None', 'None'], 
    'seed': -1, 
    'subseed': -1, 
    'subseed_strength': 0.0, 
    'seed_resize_from_h': 0, 
    'seed_resize_from_w': 0, 
    'sampler_name': None, 
    'batch_size': 1, 
    'n_iter':1, 
    'steps': 20, 
    'cfg_scale': 7.0, 
    'width': 768, 
    'height': 768, 
    'restore_faces': False, 
    'tiling': False, 
    'negative_prompt': '', 
    'eta': 1.0, 
    's_churn': 0.0, 
    's_tmax': None, 
    's_tmin': 0.0, 
    's_noise': 1.0, 
    'override_settings': {}, 
    'script_args': '[0, false, false, false, "", 1, "", 0, "", true, false, false]', 
    'sampler_index': 'Euler a'
}

inputs = {
    'task': 'text-to-image',
    'txt2img_payload': payload,
    'username': 'e'
}
</code></pre>
<p><strong>HTTP response</strong></p>
<pre><code>{
    "images" : [
        [base64 encoded images],
        ...,
        [base64 encoded images]
    ]
}
</code></pre>
<p><img alt="Inference stable-diffusion-webui text-to-image" src="../assets/images/quickstart_inference_stable_diffusion_webui_text_to_image.png" /></p>
<h3 id="quickstart-inference-image-to-image">Quickstart - Inference - Image to Image</h3>
<p><strong>HTTP request</strong></p>
<pre><code>payload = {
    'init_images': [image_encoded_in_base64],
    'resize_mode': 0, 
    'denoising_strength': 0.75, 
    'mask': None, 
    'mask_blur': 4, 
    'inpainting_fill': 1, 
    'inpaint_full_res': False, 
    'inpaint_full_res_padding': 32, 
    'inpainting_mask_invert': 0, 
    'prompt': 'cat', 
    'styles': ['None', 'None'], 
    'seed': -1, 
    'subseed': -1, 
    'subseed_strength': 0.0, 
    'seed_resize_from_h': 0, 
    'seed_resize_from_w': 0, 
    'sampler_name': None, 
    'batch_size': 1, 
    'n_iter': 1, 
    'steps': 20, 
    'cfg_scale': 7.0, 
    'width': 768, 
    'height': 768, 
    'restore_faces': False, 
    'tiling': False, 
    'negative_prompt': '', 
    'eta': 1.0, 
    's_churn': 0.0, 
    's_tmax': None, 
    's_tmin': 0.0, 
    's_noise': 1.0, 
    'override_settings': {}, 
    'script_args': '[0, "&lt;ul&gt;\\n&lt;li&gt;&lt;code&gt;CFG Scale&lt;/code&gt; should be 2 or lower.&lt;/li&gt;\\n&lt;/ul&gt;\\n", true, true, "", "", true, 50, true, 1, 0, false, 4, 1, "&lt;p style=\\"margin-bottom:0.75em\\"&gt;Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8&lt;/p&gt;", 128, 8, ["left", "right", "up", "down"], 1, 0.05, 128, 4, 0, ["left", "right", "up", "down"], false, false, false, "", "&lt;p style=\\"margin-bottom:0.75em\\"&gt;Will upscale the image to twice the dimensions; use width and height sliders to set tile size&lt;/p&gt;", 64, 0, 1, "", 0, "", true, false, false]', 
    'sampler_index': 'Euler a', 
    'include_init_images': False
}

inputs = {
    'task': 'image-to-image',
    'img2img_payload': payload,
    'username': 'e'
}
</code></pre>
<p><strong>HTTP response</strong></p>
<pre><code>{
    "images" : [
        [base64 encoded images],
        ...,
        [base64 encoded images]
    ]
}
</code></pre>
<p><img alt="Inference stable-diffusion-webui image-to-image" src="../assets/images/quickstart_inference_stable_diffusion_webui_image_to_image.png" /></p>
<h2 id="resource-cleanup">Resource Cleanup</h2>
<ul>
<li>
<p>The resource created by CloudFormation will be deleted automatically when you delete CloudFormation stack. Before you delete CloudFormation stack, please make sure the following resources created dynamically are deleted.</p>
</li>
<li>
<p>Go to <a href="https://console.aws.amazon.com/sagemaker/home">AWS SageMaker Console</a>, make sure all of model, endpoint config, and endpoint which were dynamically created are deleted.</p>
</li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../developer/" class="btn btn-neutral float-left" title="Developer Guide"><span class="icon icon-circle-arrow-left"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../developer/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
